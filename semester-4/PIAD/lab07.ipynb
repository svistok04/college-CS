{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mode\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KDTree, KNeighborsClassifier\n",
    "from sklearn.datasets import make_classification, make_regression, load_iris, fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zad 2.1-2.3\n",
    "class knn:\n",
    "    def __init__(self, n_neighbors=1, use_KDTree=False, mode='classification'):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.use_KDTree = use_KDTree\n",
    "        self.KDTree = None\n",
    "        self.mode = mode\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X = np.array(X)\n",
    "        self.y = np.array(y)\n",
    "        if self.use_KDTree:\n",
    "            self.KDTree = KDTree(self.X)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        self.decisions = []\n",
    "        X_test = np.array(X_test)\n",
    "        if self.use_KDTree:\n",
    "            _, ind = self.KDTree.query(X_test, k=self.n_neighbors)\n",
    "        else:\n",
    "            # find the indices of the nearest (with the smallest distance) k points for each point\n",
    "            ind = [np.argsort(np.sqrt(((self.X - x)**2).sum(axis=1)))[:self.n_neighbors] for x in X_test]  \n",
    "        if self.mode == 'classification':\n",
    "            for neighbors_idx in ind:\n",
    "                nearest_labels = self.y[neighbors_idx] \n",
    "                unique_labels, counts = np.unique(nearest_labels, return_counts=True) # counts of unique labels\n",
    "                most_common = unique_labels[counts.argmax()] # the label with the highest counts\n",
    "                self.decisions.append(most_common)\n",
    "        elif self.mode == 'regression':\n",
    "            for neighbors_idx in ind:\n",
    "                nearest_values = self.X[neighbors_idx] # the values of neighbors\n",
    "                average_value = np.mean(nearest_values, axis=0)\n",
    "                self.decisions.append(average_value)\n",
    "            # for x in X_test:\n",
    "            #     distances = np.sqrt(((self.X - x)**2).sum(axis=1)) # calculate distances to all points\n",
    "            #     nearest_indices = np.argsort(distances)[:self.n_neighbors] # find indices of least distance\n",
    "            #     nearest_labels = self.y[nearest_indices]\n",
    "            #     unique_labels, counts = np.unique(nearest_labels, return_counts=True) # counts of labels\n",
    "            #     most_common = unique_labels[counts.argmax()] # most common label\n",
    "            #     self.decisions.append(most_common)\n",
    "        return np.array(self.decisions)\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        X_test = np.array(X_test)\n",
    "        y_test = np.array(y_test)\n",
    "        predictions = self.predict(X_test)\n",
    "        if self.mode == 'classification':\n",
    "            hits = np.sum(predictions == y_test)\n",
    "            number_of_predictions = len(y_test)\n",
    "            return hits / number_of_predictions\n",
    "        elif self.mode == 'regression':\n",
    "            mse = np.mean((X_test - predictions)**2) # mean squared error\n",
    "            return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zad 3.1\n",
    "X, y = make_classification(\n",
    "    n_samples = 100,\n",
    "    n_features = 2,\n",
    "    n_informative = 2,\n",
    "    n_redundant = 0,\n",
    "    n_repeated = 0,\n",
    "    random_state = 3\n",
    ")\n",
    "# zad 3.2\n",
    "knn_random = knn(5, True)\n",
    "knn_random.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X[:,0][y == 0], X[:, 1][y == 0], 'o')\n",
    "plt.plot(X[:,0][y == 1], X[:, 1][y == 1], 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zad 3.3\n",
    "x_min, x_max = X[:, 0].min(), X[:, 0].max()\n",
    "y_min, y_max = X[:, 1].min(), X[:, 1].max()\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 500), np.linspace(y_min, y_max, 500))\n",
    "Z = knn_random.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=20)\n",
    "plt.contour(xx, yy, Z)\n",
    "plt.title('random data predicted borders')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zad 3.3\n",
    "x_min, x_max = X[:, 0].min(), X[:, 0].max()\n",
    "y_min, y_max = X[:, 1].min(), X[:, 1].max()\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 500), np.linspace(y_min, y_max, 500))\n",
    "from scipy.interpolate import griddata\n",
    "Z = griddata(X, y, (xx, yy), method='nearest')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=20)\n",
    "plt.contour(xx, yy, Z, levels=1)\n",
    "plt.title('random data original borders')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zbior testowy\n",
    "X_value_samples = 21\n",
    "X_value1 = np.array([[np.random.uniform(np.min(X[:,0])*0.8, np.max(X[:, 0])*0.8)] for x in range(X_value_samples)])\n",
    "X_value2 = np.array([[np.random.uniform(np.min(X[:,1])*0.8, np.max(X[:, 1])*0.8)] for x in range(X_value_samples)])\n",
    "X_value = np.hstack((X_value1, X_value2))\n",
    "y_value = np.random.randint(0, 2, X_value_samples)\n",
    "x_min, x_max = X_value[:, 0].min(), X_value[:, 0].max()\n",
    "y_min, y_max = X_value[:, 1].min(), X_value[:, 1].max()\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 500), np.linspace(y_min, y_max, 500))\n",
    "knn_random.fit(X_value, y_value)\n",
    "Z = knn_random.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.scatter(X_value[:, 0], X_value[:, 1], c=y_value, s=20)\n",
    "plt.contour(xx, yy, Z)\n",
    "plt.title('random data v2 predicted borders')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zad 3.4\n",
    "iris = load_iris()\n",
    "X_train = iris.data\n",
    "y_train = iris.target\n",
    "knn_iris = knn(5, True)\n",
    "knn_iris.fit(X_train, y_train)\n",
    "knn_iris.score(X_train, y_train)\n",
    "# zad 3.5\n",
    "# a\n",
    "pca = PCA(n_components=2)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "x_min, x_max = X_train[:, 0].min(), X_train[:, 0].max()\n",
    "y_min, y_max = X_train[:, 1].min(), X_train[:, 1].max()\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                     np.arange(y_min, y_max, 0.1))\n",
    "grid_2d = np.c_[xx.ravel(), yy.ravel()]\n",
    "# b\n",
    "grid_4d = pca.inverse_transform(grid_2d)\n",
    "Z = knn_iris.predict(grid_4d)\n",
    "# c\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train)\n",
    "plt.contour(xx, yy, Z, levels=4) \n",
    "plt.title('iris')\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zad 3.6\n",
    "X, y = make_classification(\n",
    "    n_samples = 100,\n",
    "    n_features = 2,\n",
    "    n_informative = 2,\n",
    "    n_redundant = 0,\n",
    "    n_repeated = 0,\n",
    "    random_state = 3\n",
    ")\n",
    "k_neighbors = range(1, 21)\n",
    "n_splits = len(X)\n",
    "test_size = int(len(X) / n_splits)\n",
    "for i in k_neighbors:\n",
    "    knn_accuracy_test = knn(i, True, 'classification')\n",
    "    scores = []\n",
    "    for j in range(n_splits):\n",
    "        X_train = np.concatenate([X[j+test_size:], X[:j]])\n",
    "        y_train = np.concatenate([y[j+test_size:], y[:j]])\n",
    "        X_test = X[j:j+test_size]\n",
    "        y_test = y[j:j+test_size]\n",
    "        knn_accuracy_test.fit(X_train, y_train)\n",
    "        score = knn_accuracy_test.score(X_test, y_test)\n",
    "        scores.append(score)\n",
    "    print('liczba sąsiedzi', i) \n",
    "    print(f'średnia dokładność: {np.mean(scores):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zad 3.7\n",
    "X, y = make_classification(\n",
    "    n_samples = 5000,\n",
    "    n_features = 2,\n",
    "    n_informative = 2,\n",
    "    n_redundant = 0,\n",
    "    n_repeated = 0,\n",
    "    random_state = 3\n",
    ")\n",
    "knn_kdtree = knn(5, True)\n",
    "knn_nokdtree = knn(5)\n",
    "knn_kdtree.fit(X, y)\n",
    "start_time = time.time()\n",
    "_ = knn_kdtree.predict(X)\n",
    "kdtree_time = time.time() - start_time\n",
    "knn_nokdtree.fit(X, y)\n",
    "start_time = time.time()\n",
    "_ = knn_nokdtree.predict(X)\n",
    "nokdtree_time = time.time() - start_time\n",
    "\n",
    "print(\"czas z KD-Tree: {:.4f} sekund\".format(kdtree_time))\n",
    "print(\"cza bez KD-Tree: {:.4f} sekund\".format(nokdtree_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zad 4.1\n",
    "X, y = make_regression(\n",
    "    n_samples = 100,\n",
    "    n_features = 2,\n",
    "    n_informative = 2,\n",
    "    random_state = 3\n",
    ")\n",
    "# zad 4.2\n",
    "knn4 = knn(3, mode='regression')\n",
    "knn4.fit(X, y)\n",
    "print('mean square error = ', knn4.score(X, y))\n",
    "X_predicted = knn4.predict(X)\n",
    "# zad 4.3\n",
    "plt.scatter(X[:, 0], X[:, 1], label='training data')\n",
    "plt.scatter(X_predicted[:, 0], X_predicted[:, 1], label='prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, ssl \n",
    "# if (not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None)):      \n",
    "#     ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# zad 4.4\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing.data, housing.target\n",
    "\n",
    "k_neighbors = 5\n",
    "n_splits = 10\n",
    "test_size = int(len(X) / n_splits)\n",
    "for i in range(k_neighbors):\n",
    "    knn_mse_test = knn(i + 1, True, 'regression')\n",
    "    mses = []\n",
    "    for j in range(n_splits):\n",
    "        X_train = np.concatenate([X[j+test_size:], X[:j]])\n",
    "        y_train = np.concatenate([y[j+test_size:], y[:j]])\n",
    "        X_test = X[j:j+test_size]\n",
    "        y_test = y[j:j+test_size]\n",
    "        knn_mse_test.fit(X_train, y_train)\n",
    "        mse = knn_mse_test.score(X_test, y_test)\n",
    "        # print(mse)\n",
    "        mses.append(mse)\n",
    "    print('iteracja nr ', i) \n",
    "    print(f'średni błąd dopasowania: {np.mean(mses):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

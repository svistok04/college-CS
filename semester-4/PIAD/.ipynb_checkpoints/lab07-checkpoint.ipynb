{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mode\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KDTree, KNeighborsClassifier\n",
    "from sklearn import datasets\n",
    "from collections import Counter \n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zad 2.1\n",
    "class knn:\n",
    "    def __init__(self, n_neighbors=1, use_KDTree=False):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.use_KDTree = use_KDTree\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.decision = []\n",
    "        for x in X:\n",
    "            distances = np.sqrt(((self.X - x)**2).sum(axis=1)) # calculate distances to all points\n",
    "            if np.any(distances == 0):\n",
    "                distances[distances == 0] = np.inf\n",
    "            nearest_indices = np.argsort(distances)[:self.n_neighbors] # find indices of least distance\n",
    "            nearest_labels = self.y[nearest_indices]\n",
    "            unique_labels, counts = np.unique(nearest_labels, return_counts=True) # counts of labels\n",
    "            most_common = unique_labels[counts.argmax()] # most common label\n",
    "            self.decision.append(most_common)\n",
    "        return self.decision \n",
    "\n",
    "    def score(self, X):\n",
    "        X = np.array(X)\n",
    "        y = np.array(self.y)\n",
    "        predictions = self.predict(X)\n",
    "        hits = np.sum(predictions == y)\n",
    "        number_of_predictions = len(y)\n",
    "        return hits / number_of_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zad 3.1\n",
    "X, y = datasets.make_classification(\n",
    "    n_samples = 100,\n",
    "    n_features = 2,\n",
    "    n_informative = 2,\n",
    "    n_redundant = 0,\n",
    "    n_repeated = 0,\n",
    "    random_state = 3\n",
    ")\n",
    "# zad 3.2\n",
    "knn1 = knn(5)\n",
    "knn1.fit(X, y)\n",
    "print(knn1.score(X))\n",
    "knn2 = KNeighborsClassifier(5)\n",
    "knn2.fit(X, y)\n",
    "print(knn2.score(X, y))\n",
    "# plt.scatter(X[:, 0], X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X[:,0][y == 0], X[:, 1][y == 0], 'o')\n",
    "plt.plot(X[:,0][y == 1], X[:, 1][y == 1], 'ro')\n",
    "plt.plot(X[:,0][y == 2], X[:, 1][y == 2], 'go')\n",
    "plt.show()\n",
    "\n",
    "X_value_samples = 21\n",
    "X_value1 = np.array([[np.random.uniform(np.min(X[:,0])*0.8, np.max(X[:, 0])*0.8)] for x in range(X_value_samples)])\n",
    "X_value2 = np.array([[np.random.uniform(np.min(X[:,1])*0.8, np.max(X[:, 1])*0.8)] for x in range(X_value_samples)])\n",
    "X_value = np.hstack((X_value1, X_value2))\n",
    "y_value = np.random.randint(0, 2, X_value_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

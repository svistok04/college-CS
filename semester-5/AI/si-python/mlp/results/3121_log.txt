EXPERIMENT 3121 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 64, 32], activation_name=sigmoid, targets_activation_name=linear, 
initialization_name=uniform, algo_name=sgd_momentum, learning_rate=0.0001, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 10753]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 1.6197437009973044, loss after: 1.614453948025102]
[epoch 1/1000, batch 11/100 -> loss before: 0.5971949165993526, loss after: 0.5873926943830325]
[epoch 1/1000, batch 21/100 -> loss before: 0.26790609457270975, loss after: 0.25957446812516444]
[epoch 1/1000, batch 31/100 -> loss before: 0.580050324069938, loss after: 0.5742017081517727]
[epoch 1/1000, batch 41/100 -> loss before: 0.296908094263661, loss after: 0.2913885273174472]
[epoch 1/1000, batch 51/100 -> loss before: 0.7498997454067226, loss after: 0.7391872392707037]
[epoch 1/1000, batch 61/100 -> loss before: 0.49409224962385484, loss after: 0.49341596610101746]
[epoch 1/1000, batch 71/100 -> loss before: 0.40523619516732967, loss after: 0.40597351113541824]
[epoch 1/1000, batch 81/100 -> loss before: 0.17523956753844608, loss after: 0.17418656067016788]
[epoch 1/1000, batch 91/100 -> loss before: 0.3941029393517471, loss after: 0.3942990168232347]
ENDING EPOCH 1/1000 [loss before: 0.7227142221308361, loss after: 0.2897832350684083; epoch time: 0.030799388885498047 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.36688626077205433, loss after: 0.3666652157135769]
[epoch 101/1000, batch 11/100 -> loss before: 0.14479232767919062, loss after: 0.14480371334729228]
[epoch 101/1000, batch 21/100 -> loss before: 0.10144634982454796, loss after: 0.10142481195303095]
[epoch 101/1000, batch 31/100 -> loss before: 0.18660505355034623, loss after: 0.18663176882956994]
[epoch 101/1000, batch 41/100 -> loss before: 0.526551332128968, loss after: 0.526624934073388]
[epoch 101/1000, batch 51/100 -> loss before: 0.1965244742887197, loss after: 0.19648204942428607]
[epoch 101/1000, batch 61/100 -> loss before: 0.22960465334367447, loss after: 0.2295679299033404]
[epoch 101/1000, batch 71/100 -> loss before: 0.2465799943715012, loss after: 0.2465740538502894]
[epoch 101/1000, batch 81/100 -> loss before: 0.280633829039906, loss after: 0.28086574426096994]
[epoch 101/1000, batch 91/100 -> loss before: 0.34764738597769, loss after: 0.347502217257336]
ENDING EPOCH 101/1000 [loss before: 0.27984752218294023, loss after: 0.2799667987714481; epoch time: 0.030582427978515625 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.1717233471457959, loss after: 0.17160877136618718]
[epoch 201/1000, batch 11/100 -> loss before: 0.23625089960667398, loss after: 0.23616638256744787]
[epoch 201/1000, batch 21/100 -> loss before: 0.19319461808491584, loss after: 0.19302472577682675]
[epoch 201/1000, batch 31/100 -> loss before: 0.22105169782687906, loss after: 0.22102261799037332]
[epoch 201/1000, batch 41/100 -> loss before: 0.3711804911200321, loss after: 0.3711435661171505]
[epoch 201/1000, batch 51/100 -> loss before: 0.43870696467661763, loss after: 0.4386243620322746]
[epoch 201/1000, batch 61/100 -> loss before: 0.3782383888838986, loss after: 0.37819165183513437]
[epoch 201/1000, batch 71/100 -> loss before: 0.1467638696766698, loss after: 0.14659089056244698]
[epoch 201/1000, batch 81/100 -> loss before: 0.2245008403955199, loss after: 0.2243591687331195]
[epoch 201/1000, batch 91/100 -> loss before: 0.12810865290045717, loss after: 0.1281126209909052]
ENDING EPOCH 201/1000 [loss before: 0.277940960963825, loss after: 0.27794361854343097; epoch time: 0.040734291076660156 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.18185381724329086, loss after: 0.18197161335296422]
[epoch 301/1000, batch 11/100 -> loss before: 0.4691867001793148, loss after: 0.4692881691923943]
[epoch 301/1000, batch 21/100 -> loss before: 0.172716260074877, loss after: 0.17240294858812377]
[epoch 301/1000, batch 31/100 -> loss before: 0.2123983840068077, loss after: 0.2123524571552374]
[epoch 301/1000, batch 41/100 -> loss before: 0.12436600725487779, loss after: 0.12433012812318826]
[epoch 301/1000, batch 51/100 -> loss before: 0.3046476536698909, loss after: 0.3044710153329414]
[epoch 301/1000, batch 61/100 -> loss before: 0.22815385323489085, loss after: 0.22810947938757228]
[epoch 301/1000, batch 71/100 -> loss before: 0.36152887274883955, loss after: 0.36172673611379047]
[epoch 301/1000, batch 81/100 -> loss before: 0.12251659613488894, loss after: 0.12250667778894513]
[epoch 301/1000, batch 91/100 -> loss before: 0.3316822145534715, loss after: 0.33160793844406167]
ENDING EPOCH 301/1000 [loss before: 0.27597790686761947, loss after: 0.2759067267980126; epoch time: 0.032514095306396484 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.41741477638538393, loss after: 0.41742096993827876]
[epoch 401/1000, batch 11/100 -> loss before: 0.3356838180936127, loss after: 0.3356803884770646]
[epoch 401/1000, batch 21/100 -> loss before: 0.3106910738914759, loss after: 0.3107566531039082]
[epoch 401/1000, batch 31/100 -> loss before: 0.3176752364011489, loss after: 0.31715846892195754]
[epoch 401/1000, batch 41/100 -> loss before: 0.1626919675330437, loss after: 0.1625967232949317]
[epoch 401/1000, batch 51/100 -> loss before: 0.40539615978781346, loss after: 0.40542507077952505]
[epoch 401/1000, batch 61/100 -> loss before: 0.14232912777178322, loss after: 0.14235961182040324]
[epoch 401/1000, batch 71/100 -> loss before: 0.2583558737974786, loss after: 0.258183717117799]
[epoch 401/1000, batch 81/100 -> loss before: 0.3580978894444865, loss after: 0.3584382015388282]
[epoch 401/1000, batch 91/100 -> loss before: 0.23599788515528397, loss after: 0.23602130745815106]
ENDING EPOCH 401/1000 [loss before: 0.2738548154899521, loss after: 0.2738247745566234; epoch time: 0.030333995819091797 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.21432855903919115, loss after: 0.21462906324171888]
[epoch 501/1000, batch 11/100 -> loss before: 0.3318551089638534, loss after: 0.3318628368592504]
[epoch 501/1000, batch 21/100 -> loss before: 0.12763728733246443, loss after: 0.12759195408959437]
[epoch 501/1000, batch 31/100 -> loss before: 0.1763875434771705, loss after: 0.17636065673267903]
[epoch 501/1000, batch 41/100 -> loss before: 0.2431173794317706, loss after: 0.24282004409932156]
[epoch 501/1000, batch 51/100 -> loss before: 0.1615952597891559, loss after: 0.16161581893538046]
[epoch 501/1000, batch 61/100 -> loss before: 0.15421177640640413, loss after: 0.1536726617013272]
[epoch 501/1000, batch 71/100 -> loss before: 0.21767999794918608, loss after: 0.21764389582585278]
[epoch 501/1000, batch 81/100 -> loss before: 0.2332222000766886, loss after: 0.2331273857982239]
[epoch 501/1000, batch 91/100 -> loss before: 0.3377257815891023, loss after: 0.3378103683737435]
ENDING EPOCH 501/1000 [loss before: 0.27188322856421815, loss after: 0.27187703156414217; epoch time: 0.032377004623413086 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.30725133241680563, loss after: 0.30735708136612205]
[epoch 601/1000, batch 11/100 -> loss before: 0.1770726674126442, loss after: 0.17700086988515135]
[epoch 601/1000, batch 21/100 -> loss before: 0.5151452512516095, loss after: 0.5151022412109622]
[epoch 601/1000, batch 31/100 -> loss before: 0.20114745565660436, loss after: 0.20122625976180658]
[epoch 601/1000, batch 41/100 -> loss before: 0.24132068005078455, loss after: 0.2412558260632985]
[epoch 601/1000, batch 51/100 -> loss before: 0.260547152899708, loss after: 0.2604884263400907]
[epoch 601/1000, batch 61/100 -> loss before: 0.4187914405910312, loss after: 0.418609401038911]
[epoch 601/1000, batch 71/100 -> loss before: 0.3420583071066351, loss after: 0.3420497639091783]
[epoch 601/1000, batch 81/100 -> loss before: 0.14142531353141669, loss after: 0.14116510758501952]
[epoch 601/1000, batch 91/100 -> loss before: 0.19072023527967882, loss after: 0.1902100327723212]
ENDING EPOCH 601/1000 [loss before: 0.27024669958695713, loss after: 0.27035639692059044; epoch time: 0.03893542289733887 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.2910984118389356, loss after: 0.29109086907958737]
[epoch 701/1000, batch 11/100 -> loss before: 0.282817229204324, loss after: 0.28253489549414784]
[epoch 701/1000, batch 21/100 -> loss before: 0.2736601267232922, loss after: 0.27364380811986017]
[epoch 701/1000, batch 31/100 -> loss before: 0.24459695067417062, loss after: 0.24438255576573864]
[epoch 701/1000, batch 41/100 -> loss before: 0.1728284614863949, loss after: 0.17284425553670246]
[epoch 701/1000, batch 51/100 -> loss before: 0.37398192201320424, loss after: 0.37397911216409935]
[epoch 701/1000, batch 61/100 -> loss before: 0.11972807420578832, loss after: 0.11971696412634589]
[epoch 701/1000, batch 71/100 -> loss before: 0.23603834756573455, loss after: 0.23598854721672588]
[epoch 701/1000, batch 81/100 -> loss before: 0.28054012153036034, loss after: 0.28038897479568015]
[epoch 701/1000, batch 91/100 -> loss before: 0.3294475806821438, loss after: 0.3294160317224887]
ENDING EPOCH 701/1000 [loss before: 0.2690874794138227, loss after: 0.2690151151302964; epoch time: 0.03168082237243652 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.41610177598867815, loss after: 0.41590244777073443]
[epoch 801/1000, batch 11/100 -> loss before: 0.27388749508826227, loss after: 0.27380313059800027]
[epoch 801/1000, batch 21/100 -> loss before: 0.4654700863249214, loss after: 0.4649887938217062]
[epoch 801/1000, batch 31/100 -> loss before: 0.19550106324245559, loss after: 0.1955243868638366]
[epoch 801/1000, batch 41/100 -> loss before: 0.3309808549197453, loss after: 0.3309523565122662]
[epoch 801/1000, batch 51/100 -> loss before: 0.28129151791602663, loss after: 0.28128341592863393]
[epoch 801/1000, batch 61/100 -> loss before: 0.22902045879782795, loss after: 0.2287918214094808]
[epoch 801/1000, batch 71/100 -> loss before: 0.29161815196601537, loss after: 0.2916234840966408]
[epoch 801/1000, batch 81/100 -> loss before: 0.34415830673550646, loss after: 0.3440087113871274]
[epoch 801/1000, batch 91/100 -> loss before: 0.14131820265643955, loss after: 0.14109367348696497]
ENDING EPOCH 801/1000 [loss before: 0.26861480077810324, loss after: 0.26829183586220084; epoch time: 0.030187368392944336 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.33645956098392277, loss after: 0.3364908985826165]
[epoch 901/1000, batch 11/100 -> loss before: 0.4454424701099584, loss after: 0.44529245466977885]
[epoch 901/1000, batch 21/100 -> loss before: 0.1960032044409323, loss after: 0.19592685879128918]
[epoch 901/1000, batch 31/100 -> loss before: 0.2586669544959051, loss after: 0.2587798090717518]
[epoch 901/1000, batch 41/100 -> loss before: 0.09730516276175813, loss after: 0.09729363828441802]
[epoch 901/1000, batch 51/100 -> loss before: 0.2630405306714703, loss after: 0.2630533212621168]
[epoch 901/1000, batch 61/100 -> loss before: 0.2883698449019886, loss after: 0.2883759646009826]
[epoch 901/1000, batch 71/100 -> loss before: 0.2788935832209395, loss after: 0.27866686123953227]
[epoch 901/1000, batch 81/100 -> loss before: 0.24350200649302822, loss after: 0.24348430436255458]
[epoch 901/1000, batch 91/100 -> loss before: 0.18125582796765724, loss after: 0.1810804314405962]
ENDING EPOCH 901/1000 [loss before: 0.267831923260227, loss after: 0.2678834538837705; epoch time: 0.029850482940673828 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.12274508265896733, loss after: 0.12288390835906385]
[epoch 1000/1000, batch 11/100 -> loss before: 0.25833705747721586, loss after: 0.25839927889969944]
[epoch 1000/1000, batch 21/100 -> loss before: 0.14208522726937584, loss after: 0.14211676336979284]
[epoch 1000/1000, batch 31/100 -> loss before: 0.21652371493100947, loss after: 0.21669783837511916]
[epoch 1000/1000, batch 41/100 -> loss before: 0.2618828117911298, loss after: 0.26183135442083116]
[epoch 1000/1000, batch 51/100 -> loss before: 0.3115649017050508, loss after: 0.3115301264029765]
[epoch 1000/1000, batch 61/100 -> loss before: 0.2180437111608117, loss after: 0.21798482672035605]
[epoch 1000/1000, batch 71/100 -> loss before: 0.36038096757148774, loss after: 0.3604913693173363]
[epoch 1000/1000, batch 81/100 -> loss before: 0.3621553962791757, loss after: 0.3621138813972137]
[epoch 1000/1000, batch 91/100 -> loss before: 0.38763307524296486, loss after: 0.3874807738818256]
ENDING EPOCH 1000/1000 [loss before: 0.2676375114164538, loss after: 0.26759293216555136; epoch time: 0.032530784606933594 s]
FIT DONE. [time: 26.830289125442505 s]
LOSS TRAIN (MSE): 0.26759293216555136
LOSS TEST (MSE): 0.26188390630511665
R^2 TRAIN: 0.05470305549990617
R^2 TEST: 0.056377465214309086
EXPERIMENT DONE

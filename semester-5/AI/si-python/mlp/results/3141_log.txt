EXPERIMENT 3141 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 64, 32], activation_name=sigmoid, targets_activation_name=linear, 
initialization_name=uniform, algo_name=adam, learning_rate=0.0001, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 10753]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 1.6197437009973044, loss after: 1.603878559215563]
[epoch 1/1000, batch 11/100 -> loss before: 0.5670313273425829, loss after: 0.557206107100231]
[epoch 1/1000, batch 21/100 -> loss before: 0.25082030595567006, loss after: 0.24391554447783698]
[epoch 1/1000, batch 31/100 -> loss before: 0.573992027006993, loss after: 0.5689123310176976]
[epoch 1/1000, batch 41/100 -> loss before: 0.2973897233906133, loss after: 0.29227068493101904]
[epoch 1/1000, batch 51/100 -> loss before: 0.7573317932977202, loss after: 0.7469049903608974]
[epoch 1/1000, batch 61/100 -> loss before: 0.49592922604838224, loss after: 0.4951999462469322]
[epoch 1/1000, batch 71/100 -> loss before: 0.40593488972212716, loss after: 0.4067631441432812]
[epoch 1/1000, batch 81/100 -> loss before: 0.17349853336991367, loss after: 0.17231008205434628]
[epoch 1/1000, batch 91/100 -> loss before: 0.3952766602925585, loss after: 0.3955615998876395]
ENDING EPOCH 1/1000 [loss before: 0.7227142221308361, loss after: 0.28794575756867136; epoch time: 0.05030417442321777 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.2687212505803577, loss after: 0.2683460103650416]
[epoch 101/1000, batch 11/100 -> loss before: 0.12098818589735257, loss after: 0.12108434586599488]
[epoch 101/1000, batch 21/100 -> loss before: 0.12410035911986728, loss after: 0.12408805171577733]
[epoch 101/1000, batch 31/100 -> loss before: 0.20667698609562496, loss after: 0.20682817250143543]
[epoch 101/1000, batch 41/100 -> loss before: 0.5271401325459883, loss after: 0.5273424509036844]
[epoch 101/1000, batch 51/100 -> loss before: 0.20244412602696826, loss after: 0.20229097600547444]
[epoch 101/1000, batch 61/100 -> loss before: 0.2933297170129562, loss after: 0.29279704918780075]
[epoch 101/1000, batch 71/100 -> loss before: 0.22993269532029242, loss after: 0.2299316475326576]
[epoch 101/1000, batch 81/100 -> loss before: 0.2791337482678499, loss after: 0.279807928916314]
[epoch 101/1000, batch 91/100 -> loss before: 0.3425971140326272, loss after: 0.3422299584098367]
ENDING EPOCH 101/1000 [loss before: 0.2672729743929566, loss after: 0.269564234411407; epoch time: 0.049819231033325195 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.18138535361734154, loss after: 0.1810073224086413]
[epoch 201/1000, batch 11/100 -> loss before: 0.20927483771277017, loss after: 0.2084705338178993]
[epoch 201/1000, batch 21/100 -> loss before: 0.1886464887693156, loss after: 0.18834096500068234]
[epoch 201/1000, batch 31/100 -> loss before: 0.2567323695270955, loss after: 0.25656270542668147]
[epoch 201/1000, batch 41/100 -> loss before: 0.32647820225089863, loss after: 0.3264703355187774]
[epoch 201/1000, batch 51/100 -> loss before: 0.39705841435931755, loss after: 0.3966015978666953]
[epoch 201/1000, batch 61/100 -> loss before: 0.36275771240053023, loss after: 0.3626004882763332]
[epoch 201/1000, batch 71/100 -> loss before: 0.1415848104970468, loss after: 0.1411783795251363]
[epoch 201/1000, batch 81/100 -> loss before: 0.17476146798930098, loss after: 0.17421814583535647]
[epoch 201/1000, batch 91/100 -> loss before: 0.13759515370563805, loss after: 0.13758241377387057]
ENDING EPOCH 201/1000 [loss before: 0.2651007125242255, loss after: 0.2653153838059577; epoch time: 0.04397416114807129 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.18405117382943745, loss after: 0.18427614224012684]
[epoch 301/1000, batch 11/100 -> loss before: 0.4709895634038337, loss after: 0.4712308142327892]
[epoch 301/1000, batch 21/100 -> loss before: 0.19743059792575884, loss after: 0.19705457537242474]
[epoch 301/1000, batch 31/100 -> loss before: 0.18872141411016835, loss after: 0.18848104414329975]
[epoch 301/1000, batch 41/100 -> loss before: 0.08410134374979668, loss after: 0.0840482992974875]
[epoch 301/1000, batch 51/100 -> loss before: 0.29333819882890094, loss after: 0.29304419369258194]
[epoch 301/1000, batch 61/100 -> loss before: 0.18806401844699264, loss after: 0.18786950885185144]
[epoch 301/1000, batch 71/100 -> loss before: 0.28730176813714803, loss after: 0.28786042647623916]
[epoch 301/1000, batch 81/100 -> loss before: 0.14481426831769836, loss after: 0.14474313956124352]
[epoch 301/1000, batch 91/100 -> loss before: 0.2808323465040795, loss after: 0.2799595589082517]
ENDING EPOCH 301/1000 [loss before: 0.2530562823007857, loss after: 0.25280892751457434; epoch time: 0.04572868347167969 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.40454294943940505, loss after: 0.40462670807296924]
[epoch 401/1000, batch 11/100 -> loss before: 0.28815393167577896, loss after: 0.2881960769076003]
[epoch 401/1000, batch 21/100 -> loss before: 0.19055214106630186, loss after: 0.1905144984004272]
[epoch 401/1000, batch 31/100 -> loss before: 0.41158584130305015, loss after: 0.4095422047248829]
[epoch 401/1000, batch 41/100 -> loss before: 0.12778708840745287, loss after: 0.12768799667147418]
[epoch 401/1000, batch 51/100 -> loss before: 0.36360350550056253, loss after: 0.3633448459830076]
[epoch 401/1000, batch 61/100 -> loss before: 0.1578573050827911, loss after: 0.15797214647278368]
[epoch 401/1000, batch 71/100 -> loss before: 0.21618282813628015, loss after: 0.2161371550805277]
[epoch 401/1000, batch 81/100 -> loss before: 0.28187026669390397, loss after: 0.28225772601026067]
[epoch 401/1000, batch 91/100 -> loss before: 0.19812056599475478, loss after: 0.19812818713243724]
ENDING EPOCH 401/1000 [loss before: 0.23527095565925601, loss after: 0.23490329664190243; epoch time: 0.043016672134399414 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.23204065138556557, loss after: 0.23268818145282508]
[epoch 501/1000, batch 11/100 -> loss before: 0.25394849749492543, loss after: 0.25393032395202236]
[epoch 501/1000, batch 21/100 -> loss before: 0.13582129815072252, loss after: 0.13557714209516267]
[epoch 501/1000, batch 31/100 -> loss before: 0.16819568754029937, loss after: 0.16805336166813437]
[epoch 501/1000, batch 41/100 -> loss before: 0.20678636162299852, loss after: 0.20580866396547473]
[epoch 501/1000, batch 51/100 -> loss before: 0.19009630909587535, loss after: 0.18973069254502845]
[epoch 501/1000, batch 61/100 -> loss before: 0.1526982331298217, loss after: 0.15127642456991738]
[epoch 501/1000, batch 71/100 -> loss before: 0.2041723146358903, loss after: 0.20405929119474972]
[epoch 501/1000, batch 81/100 -> loss before: 0.24149551951711762, loss after: 0.2413786736224813]
[epoch 501/1000, batch 91/100 -> loss before: 0.3792406509612634, loss after: 0.3794161009748386]
ENDING EPOCH 501/1000 [loss before: 0.23266461965771612, loss after: 0.2326482216145106; epoch time: 0.04525113105773926 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.31435277642241155, loss after: 0.314439289228296]
[epoch 601/1000, batch 11/100 -> loss before: 0.16562124481180193, loss after: 0.16541306367438954]
[epoch 601/1000, batch 21/100 -> loss before: 0.5278532649591827, loss after: 0.5274094387278295]
[epoch 601/1000, batch 31/100 -> loss before: 0.1097724814834348, loss after: 0.10991251280289009]
[epoch 601/1000, batch 41/100 -> loss before: 0.12727354898032475, loss after: 0.12704789628185412]
[epoch 601/1000, batch 51/100 -> loss before: 0.24894783934845136, loss after: 0.2489831215993828]
[epoch 601/1000, batch 61/100 -> loss before: 0.37540115357876486, loss after: 0.3748351236779605]
[epoch 601/1000, batch 71/100 -> loss before: 0.3308290294281987, loss after: 0.3308641254754715]
[epoch 601/1000, batch 81/100 -> loss before: 0.08080774581167445, loss after: 0.08085046201751903]
[epoch 601/1000, batch 91/100 -> loss before: 0.09341585398111177, loss after: 0.09302064743009517]
ENDING EPOCH 601/1000 [loss before: 0.23174522918400628, loss after: 0.23202807874142234; epoch time: 0.04536128044128418 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.20402880792655181, loss after: 0.2040462885788224]
[epoch 701/1000, batch 11/100 -> loss before: 0.23152093531736256, loss after: 0.23119197899497176]
[epoch 701/1000, batch 21/100 -> loss before: 0.2105938575540764, loss after: 0.21051586160980396]
[epoch 701/1000, batch 31/100 -> loss before: 0.11066443236292889, loss after: 0.11057364380281456]
[epoch 701/1000, batch 41/100 -> loss before: 0.1809689042732458, loss after: 0.18083429630859923]
[epoch 701/1000, batch 51/100 -> loss before: 0.3281843393449649, loss after: 0.3278198700774573]
[epoch 701/1000, batch 61/100 -> loss before: 0.07231962866260057, loss after: 0.0720544029609181]
[epoch 701/1000, batch 71/100 -> loss before: 0.18754753773064453, loss after: 0.1875786392320189]
[epoch 701/1000, batch 81/100 -> loss before: 0.2874847738498143, loss after: 0.2872501978627272]
[epoch 701/1000, batch 91/100 -> loss before: 0.2501530053149074, loss after: 0.2500571157952777]
ENDING EPOCH 701/1000 [loss before: 0.23019449895951166, loss after: 0.2300015892742469; epoch time: 0.04160666465759277 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.38207189625018095, loss after: 0.38229669984881626]
[epoch 801/1000, batch 11/100 -> loss before: 0.18064450963866177, loss after: 0.1806339527658069]
[epoch 801/1000, batch 21/100 -> loss before: 0.40440550833011546, loss after: 0.40367486338529607]
[epoch 801/1000, batch 31/100 -> loss before: 0.17673825327062911, loss after: 0.17669507085559505]
[epoch 801/1000, batch 41/100 -> loss before: 0.21736954982401419, loss after: 0.21746334125361638]
[epoch 801/1000, batch 51/100 -> loss before: 0.27372928284981446, loss after: 0.2735692595199143]
[epoch 801/1000, batch 61/100 -> loss before: 0.2269680130393307, loss after: 0.2261876162081466]
[epoch 801/1000, batch 71/100 -> loss before: 0.17569339402149, loss after: 0.17590108146365346]
[epoch 801/1000, batch 81/100 -> loss before: 0.29892167074246084, loss after: 0.2985061596905461]
[epoch 801/1000, batch 91/100 -> loss before: 0.12820068768040346, loss after: 0.12795842588375186]
ENDING EPOCH 801/1000 [loss before: 0.2249621220879472, loss after: 0.22383209336219198; epoch time: 0.048369646072387695 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.21888246742576722, loss after: 0.2190358036868322]
[epoch 901/1000, batch 11/100 -> loss before: 0.3069709543214454, loss after: 0.3067587636625221]
[epoch 901/1000, batch 21/100 -> loss before: 0.12800230473382276, loss after: 0.12769797359704457]
[epoch 901/1000, batch 31/100 -> loss before: 0.14294381168961298, loss after: 0.14313373129155654]
[epoch 901/1000, batch 41/100 -> loss before: 0.02964840771816371, loss after: 0.029598596210597912]
[epoch 901/1000, batch 51/100 -> loss before: 0.2688938631088259, loss after: 0.26870151815108967]
[epoch 901/1000, batch 61/100 -> loss before: 0.24456248505498093, loss after: 0.24460408514938994]
[epoch 901/1000, batch 71/100 -> loss before: 0.11007333185002488, loss after: 0.10998154681985839]
[epoch 901/1000, batch 81/100 -> loss before: 0.19431336703595428, loss after: 0.19457418875958954]
[epoch 901/1000, batch 91/100 -> loss before: 0.068853328449235, loss after: 0.0684909060834881]
ENDING EPOCH 901/1000 [loss before: 0.21058270951071995, loss after: 0.21049144290648927; epoch time: 0.0635073184967041 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.07924364125421929, loss after: 0.079358073795047]
[epoch 1000/1000, batch 11/100 -> loss before: 0.22381513679846457, loss after: 0.22395805638668254]
[epoch 1000/1000, batch 21/100 -> loss before: 0.17245328817683367, loss after: 0.17250095227485968]
[epoch 1000/1000, batch 31/100 -> loss before: 0.17116871489483895, loss after: 0.17095278881394066]
[epoch 1000/1000, batch 41/100 -> loss before: 0.2541184981838442, loss after: 0.253585126689102]
[epoch 1000/1000, batch 51/100 -> loss before: 0.23516810422683623, loss after: 0.23561510044655298]
[epoch 1000/1000, batch 61/100 -> loss before: 0.16530033097256794, loss after: 0.1653775616478846]
[epoch 1000/1000, batch 71/100 -> loss before: 0.1888122259150914, loss after: 0.1888499559486796]
[epoch 1000/1000, batch 81/100 -> loss before: 0.2754420466001846, loss after: 0.27521299866346005]
[epoch 1000/1000, batch 91/100 -> loss before: 0.27658361624450967, loss after: 0.27642617658701607]
ENDING EPOCH 1000/1000 [loss before: 0.20187145097822679, loss after: 0.20160062728985761; epoch time: 0.046096086502075195 s]
FIT DONE. [time: 44.70187163352966 s]
LOSS TRAIN (MSE): 0.20160062728985761
LOSS TEST (MSE): 0.1947468714339968
R^2 TRAIN: 0.2878270160420252
R^2 TEST: 0.2982862557043633
EXPERIMENT DONE

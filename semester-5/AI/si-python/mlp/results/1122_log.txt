EXPERIMENT 1122 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 128, 64, 64, 32, 32], activation_name=sigmoid, targets_activation_name=linear, 
initialization_name=uniform, algo_name=sgd_momentum, learning_rate=0.01, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 32481]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 0.26392389365226554, loss after: 0.26382396752347137]
[epoch 1/1000, batch 11/100 -> loss before: 0.34156167378716146, loss after: 0.2528959681375358]
[epoch 1/1000, batch 21/100 -> loss before: 0.32446608035634605, loss after: 0.30119907167615667]
[epoch 1/1000, batch 31/100 -> loss before: 0.3413342500497877, loss after: 0.3410650631088432]
[epoch 1/1000, batch 41/100 -> loss before: 0.2918374114819794, loss after: 0.29101930414746535]
[epoch 1/1000, batch 51/100 -> loss before: 0.12278591578821327, loss after: 0.14570591343007025]
[epoch 1/1000, batch 61/100 -> loss before: 0.22747251002357555, loss after: 0.21700806863374314]
[epoch 1/1000, batch 71/100 -> loss before: 0.4007932876955781, loss after: 0.4308815558646151]
[epoch 1/1000, batch 81/100 -> loss before: 0.3823242167587309, loss after: 0.3774632973834352]
[epoch 1/1000, batch 91/100 -> loss before: 0.3168643662818379, loss after: 0.32043454645629044]
ENDING EPOCH 1/1000 [loss before: 0.2838936199301506, loss after: 0.31090407498237504; epoch time: 0.07985687255859375 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.3052738156140216, loss after: 0.3050047908919667]
[epoch 101/1000, batch 11/100 -> loss before: 0.2425974737412354, loss after: 0.24266391119214856]
[epoch 101/1000, batch 21/100 -> loss before: 0.28112245045945367, loss after: 0.2811283273680236]
[epoch 101/1000, batch 31/100 -> loss before: 0.1407958564318736, loss after: 0.1405936683646507]
[epoch 101/1000, batch 41/100 -> loss before: 0.368879469846741, loss after: 0.36840960810408774]
[epoch 101/1000, batch 51/100 -> loss before: 0.16186616775432044, loss after: 0.1613806022426133]
[epoch 101/1000, batch 61/100 -> loss before: 0.16278056333298604, loss after: 0.16276615453572607]
[epoch 101/1000, batch 71/100 -> loss before: 0.3635238182362503, loss after: 0.3623892919717933]
[epoch 101/1000, batch 81/100 -> loss before: 0.3140951774502353, loss after: 0.31133308014664973]
[epoch 101/1000, batch 91/100 -> loss before: 0.3633368046089818, loss after: 0.36163225191485704]
ENDING EPOCH 101/1000 [loss before: 0.28309349082629737, loss after: 0.2933425787110316; epoch time: 0.07754063606262207 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.5727227343507828, loss after: 0.5733417467772407]
[epoch 201/1000, batch 11/100 -> loss before: 0.45769265129702336, loss after: 0.4576930901033392]
[epoch 201/1000, batch 21/100 -> loss before: 0.370490157047966, loss after: 0.37053904447721386]
[epoch 201/1000, batch 31/100 -> loss before: 0.2727262926273589, loss after: 0.2735467618220499]
[epoch 201/1000, batch 41/100 -> loss before: 0.26957660398491573, loss after: 0.26849699641893704]
[epoch 201/1000, batch 51/100 -> loss before: 0.386855187111484, loss after: 0.3870858987111971]
[epoch 201/1000, batch 61/100 -> loss before: 0.3173693219227326, loss after: 0.31570051567976315]
[epoch 201/1000, batch 71/100 -> loss before: 0.17517070366052384, loss after: 0.17555290903287118]
[epoch 201/1000, batch 81/100 -> loss before: 0.2900323784926805, loss after: 0.28355624601334206]
[epoch 201/1000, batch 91/100 -> loss before: 0.4515496965986319, loss after: 0.45019597916466775]
ENDING EPOCH 201/1000 [loss before: 0.28325189432514103, loss after: 0.29251813889249517; epoch time: 0.062033891677856445 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.16645129333532305, loss after: 0.16416219834371235]
[epoch 301/1000, batch 11/100 -> loss before: 0.10847067006672632, loss after: 0.1061888062236687]
[epoch 301/1000, batch 21/100 -> loss before: 0.43112116378299187, loss after: 0.42864856075659163]
[epoch 301/1000, batch 31/100 -> loss before: 0.28000629868694416, loss after: 0.2804494171274048]
[epoch 301/1000, batch 41/100 -> loss before: 0.3306909697960057, loss after: 0.33073419442783014]
[epoch 301/1000, batch 51/100 -> loss before: 0.3232136863354608, loss after: 0.3221615885567664]
[epoch 301/1000, batch 61/100 -> loss before: 0.1753901037913566, loss after: 0.17526139836796345]
[epoch 301/1000, batch 71/100 -> loss before: 0.19549377777721963, loss after: 0.19142522591174088]
[epoch 301/1000, batch 81/100 -> loss before: 0.2734941636108027, loss after: 0.27504336281031794]
[epoch 301/1000, batch 91/100 -> loss before: 0.3929183783195411, loss after: 0.3858594768108196]
ENDING EPOCH 301/1000 [loss before: 0.2877850009485837, loss after: 0.29073641192137656; epoch time: 0.06828832626342773 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.5595837499830107, loss after: 0.5547789827693909]
[epoch 401/1000, batch 11/100 -> loss before: 0.24043231129714138, loss after: 0.24018251759295195]
[epoch 401/1000, batch 21/100 -> loss before: 0.2105167585808636, loss after: 0.20249144864664018]
[epoch 401/1000, batch 31/100 -> loss before: 0.28940599810330536, loss after: 0.28836886586918664]
[epoch 401/1000, batch 41/100 -> loss before: 0.2015779465395474, loss after: 0.20118498294849135]
[epoch 401/1000, batch 51/100 -> loss before: 0.31421243765807394, loss after: 0.311376491106644]
[epoch 401/1000, batch 61/100 -> loss before: 0.29181498037678105, loss after: 0.29057796644843653]
[epoch 401/1000, batch 71/100 -> loss before: 0.2884696461752121, loss after: 0.28255615230030323]
[epoch 401/1000, batch 81/100 -> loss before: 0.47444051226941786, loss after: 0.4675895888501299]
[epoch 401/1000, batch 91/100 -> loss before: 0.154220638089735, loss after: 0.15401185640533158]
ENDING EPOCH 401/1000 [loss before: 0.28311954445929055, loss after: 0.2851385492097724; epoch time: 0.07366943359375 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.2869568172183842, loss after: 0.2853752123707512]
[epoch 501/1000, batch 11/100 -> loss before: 0.3987986386096116, loss after: 0.3978305939797559]
[epoch 501/1000, batch 21/100 -> loss before: 0.6239937328328375, loss after: 0.624883956711278]
[epoch 501/1000, batch 31/100 -> loss before: 0.11198860991626174, loss after: 0.11281525710410742]
[epoch 501/1000, batch 41/100 -> loss before: 0.36047784415268824, loss after: 0.34206081394082316]
[epoch 501/1000, batch 51/100 -> loss before: 0.20530419766769215, loss after: 0.2051515501164077]
[epoch 501/1000, batch 61/100 -> loss before: 0.5107379535498427, loss after: 0.5048051602018891]
[epoch 501/1000, batch 71/100 -> loss before: 0.2647552130175467, loss after: 0.2641837268648957]
[epoch 501/1000, batch 81/100 -> loss before: 0.5073777374327769, loss after: 0.5068223434942526]
[epoch 501/1000, batch 91/100 -> loss before: 0.276190102111174, loss after: 0.27847935860319395]
ENDING EPOCH 501/1000 [loss before: 0.2830781162480688, loss after: 0.2896388098240489; epoch time: 0.06504702568054199 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.27795943001570783, loss after: 0.2782922885364031]
[epoch 601/1000, batch 11/100 -> loss before: 0.4472063434902978, loss after: 0.43596752236412895]
[epoch 601/1000, batch 21/100 -> loss before: 0.6129461639024238, loss after: 0.6089914977841094]
[epoch 601/1000, batch 31/100 -> loss before: 0.12913901608067824, loss after: 0.1294189521959995]
[epoch 601/1000, batch 41/100 -> loss before: 0.353552977563738, loss after: 0.3545350055352844]
[epoch 601/1000, batch 51/100 -> loss before: 0.30516077545560827, loss after: 0.30529406506803725]
[epoch 601/1000, batch 61/100 -> loss before: 0.16973809038429538, loss after: 0.16958747244907332]
[epoch 601/1000, batch 71/100 -> loss before: 0.2067433747491733, loss after: 0.20747907301308405]
[epoch 601/1000, batch 81/100 -> loss before: 0.3169008717712748, loss after: 0.314720259836188]
[epoch 601/1000, batch 91/100 -> loss before: 0.5278843330697354, loss after: 0.5276060477777046]
ENDING EPOCH 601/1000 [loss before: 0.29033337423063615, loss after: 0.28546683423335584; epoch time: 0.05926108360290527 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.2611491117748386, loss after: 0.2639306045773206]
[epoch 701/1000, batch 11/100 -> loss before: 0.3801463566592006, loss after: 0.3791163267757769]
[epoch 701/1000, batch 21/100 -> loss before: 0.37214701340178047, loss after: 0.3622944767992188]
[epoch 701/1000, batch 31/100 -> loss before: 0.26098282868255024, loss after: 0.2630980271367848]
[epoch 701/1000, batch 41/100 -> loss before: 0.12609768350814018, loss after: 0.1268125520520888]
[epoch 701/1000, batch 51/100 -> loss before: 0.2897601832858339, loss after: 0.2920861924436453]
[epoch 701/1000, batch 61/100 -> loss before: 0.318891159247771, loss after: 0.3191122631853851]
[epoch 701/1000, batch 71/100 -> loss before: 0.12381880914658364, loss after: 0.115492056309176]
[epoch 701/1000, batch 81/100 -> loss before: 0.34885876461418547, loss after: 0.34551855733169956]
[epoch 701/1000, batch 91/100 -> loss before: 0.30699925765299774, loss after: 0.31238291839672716]
ENDING EPOCH 701/1000 [loss before: 0.28905319026303744, loss after: 0.28858980535217266; epoch time: 0.06071639060974121 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.24974472701709055, loss after: 0.24953930344513423]
[epoch 801/1000, batch 11/100 -> loss before: 0.30084769913640663, loss after: 0.30122270231482046]
[epoch 801/1000, batch 21/100 -> loss before: 0.2275303289129896, loss after: 0.22422926065374424]
[epoch 801/1000, batch 31/100 -> loss before: 0.18169145365067388, loss after: 0.17716420664009142]
[epoch 801/1000, batch 41/100 -> loss before: 0.2873858248385843, loss after: 0.2856568828648354]
[epoch 801/1000, batch 51/100 -> loss before: 0.2058731745871464, loss after: 0.20447829905753562]
[epoch 801/1000, batch 61/100 -> loss before: 0.36553706615550985, loss after: 0.36589458155756077]
[epoch 801/1000, batch 71/100 -> loss before: 0.28431380062701306, loss after: 0.2839969657935993]
[epoch 801/1000, batch 81/100 -> loss before: 0.19021081620247118, loss after: 0.19026977289269395]
[epoch 801/1000, batch 91/100 -> loss before: 0.32942589640026254, loss after: 0.32942150181119834]
ENDING EPOCH 801/1000 [loss before: 0.29082809954583966, loss after: 0.2832046824642319; epoch time: 0.06103515625 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.2511474396965006, loss after: 0.24447420931574318]
[epoch 901/1000, batch 11/100 -> loss before: 0.28784738525919507, loss after: 0.28764368043624905]
[epoch 901/1000, batch 21/100 -> loss before: 0.09882060873794915, loss after: 0.10100596929739161]
[epoch 901/1000, batch 31/100 -> loss before: 0.23852024685613538, loss after: 0.2341463247823178]
[epoch 901/1000, batch 41/100 -> loss before: 0.2962929718965871, loss after: 0.2955404814055226]
[epoch 901/1000, batch 51/100 -> loss before: 0.31560568001531364, loss after: 0.31315622140491983]
[epoch 901/1000, batch 61/100 -> loss before: 0.31623384669478816, loss after: 0.31451780197281287]
[epoch 901/1000, batch 71/100 -> loss before: 0.42288127015848753, loss after: 0.42050793905406375]
[epoch 901/1000, batch 81/100 -> loss before: 0.2213488083660314, loss after: 0.21520900269985938]
[epoch 901/1000, batch 91/100 -> loss before: 0.4328979735708865, loss after: 0.4399011579162475]
ENDING EPOCH 901/1000 [loss before: 0.2971659079114059, loss after: 0.2875927302584171; epoch time: 0.05608105659484863 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.35785616981171253, loss after: 0.35856363232473115]
[epoch 1000/1000, batch 11/100 -> loss before: 0.25641607896937907, loss after: 0.2573457391677648]
[epoch 1000/1000, batch 21/100 -> loss before: 0.23292474807409597, loss after: 0.22514092388905022]
[epoch 1000/1000, batch 31/100 -> loss before: 0.3588988391708223, loss after: 0.356865882264923]
[epoch 1000/1000, batch 41/100 -> loss before: 0.2896800527921808, loss after: 0.28784161592090224]
[epoch 1000/1000, batch 51/100 -> loss before: 0.19827433660360733, loss after: 0.1982711120118542]
[epoch 1000/1000, batch 61/100 -> loss before: 0.2341652223101162, loss after: 0.23550338459818762]
[epoch 1000/1000, batch 71/100 -> loss before: 0.24586391934978838, loss after: 0.24679525596850677]
[epoch 1000/1000, batch 81/100 -> loss before: 0.35299546329007675, loss after: 0.353083604841327]
[epoch 1000/1000, batch 91/100 -> loss before: 0.43220863271954413, loss after: 0.4308138871745578]
ENDING EPOCH 1000/1000 [loss before: 0.29006081216516577, loss after: 0.28400904691727247; epoch time: 0.10731029510498047 s]
FIT DONE. [time: 56.544901609420776 s]
LOSS TRAIN (MSE): 0.28400904691727247
LOSS TEST (MSE): 0.27939080860014337
R^2 TRAIN: -0.003288398122510028
R^2 TEST: -0.006703568488584555
EXPERIMENT DONE

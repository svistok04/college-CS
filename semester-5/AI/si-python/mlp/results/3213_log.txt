EXPERIMENT 3213 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[64, 64, 64, 64, 64, 32, 32, 32, 32, 32, 16, 16, 16, 16, 16, 8, 8, 8, 8, 8], activation_name=relu, targets_activation_name=linear, 
initialization_name=uniform, algo_name=sgd_simple, learning_rate=0.0001, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 25185]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 0.18318931763552243, loss after: 0.18237280906184747]
[epoch 1/1000, batch 11/100 -> loss before: 0.33704919879110556, loss after: 0.3349727555797365]
[epoch 1/1000, batch 21/100 -> loss before: 0.36721747853075487, loss after: 0.36049107760471644]
[epoch 1/1000, batch 31/100 -> loss before: 0.3874408911608953, loss after: 0.38534114428397476]
[epoch 1/1000, batch 41/100 -> loss before: 0.19100543192709535, loss after: 0.1886622214003117]
[epoch 1/1000, batch 51/100 -> loss before: 0.2419460134793448, loss after: 0.2394199515276684]
[epoch 1/1000, batch 61/100 -> loss before: 0.46372474626412963, loss after: 0.4634344417107193]
[epoch 1/1000, batch 71/100 -> loss before: 0.2987494212187829, loss after: 0.2951512570000229]
[epoch 1/1000, batch 81/100 -> loss before: 0.3835899460383113, loss after: 0.38254756305068915]
[epoch 1/1000, batch 91/100 -> loss before: 0.3178163854407964, loss after: 0.31731797144343327]
ENDING EPOCH 1/1000 [loss before: 0.2899884218128069, loss after: 0.277550181747172; epoch time: 0.07455921173095703 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.20065019816566934, loss after: 0.2003622036045075]
[epoch 101/1000, batch 11/100 -> loss before: 0.16652820716450642, loss after: 0.1659253792010285]
[epoch 101/1000, batch 21/100 -> loss before: 0.16032924706882418, loss after: 0.15886393738747445]
[epoch 101/1000, batch 31/100 -> loss before: 0.27680823972688035, loss after: 0.2712250750284025]
[epoch 101/1000, batch 41/100 -> loss before: 0.5232540276677267, loss after: 0.5216555826139228]
[epoch 101/1000, batch 51/100 -> loss before: 0.23207809383976538, loss after: 0.23176231778392956]
[epoch 101/1000, batch 61/100 -> loss before: 0.5261842306122602, loss after: 0.5259793686442462]
[epoch 101/1000, batch 71/100 -> loss before: 0.15829668834977476, loss after: 0.15800573480259955]
[epoch 101/1000, batch 81/100 -> loss before: 0.28383661011640793, loss after: 0.28345382431870203]
[epoch 101/1000, batch 91/100 -> loss before: 0.21873894339570815, loss after: 0.21858818514924092]
ENDING EPOCH 101/1000 [loss before: 0.23123186726018047, loss after: 0.23414734674654503; epoch time: 0.07743215560913086 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.07901354436275415, loss after: 0.07899813230766713]
[epoch 201/1000, batch 11/100 -> loss before: 0.20403000136625854, loss after: 0.20366861788634857]
[epoch 201/1000, batch 21/100 -> loss before: 0.23391187136305266, loss after: 0.23326200664168534]
[epoch 201/1000, batch 31/100 -> loss before: 0.37858458162738645, loss after: 0.3784673833333305]
[epoch 201/1000, batch 41/100 -> loss before: 0.26878563391874716, loss after: 0.2685030520559256]
[epoch 201/1000, batch 51/100 -> loss before: 0.20545316906107183, loss after: 0.20544548428931547]
[epoch 201/1000, batch 61/100 -> loss before: 0.5045640131643389, loss after: 0.5043259124614898]
[epoch 201/1000, batch 71/100 -> loss before: 0.40771270035158275, loss after: 0.40770909766331725]
[epoch 201/1000, batch 81/100 -> loss before: 0.13577753245249846, loss after: 0.13149020647844373]
[epoch 201/1000, batch 91/100 -> loss before: 0.061068033878222364, loss after: 0.06059951889473668]
ENDING EPOCH 201/1000 [loss before: 0.23084078037312494, loss after: 0.23105109602226861; epoch time: 0.0771632194519043 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.18768514558713428, loss after: 0.18767710446784935]
[epoch 301/1000, batch 11/100 -> loss before: 0.039740595601740265, loss after: 0.03938882078538486]
[epoch 301/1000, batch 21/100 -> loss before: 0.264004901752581, loss after: 0.26044715197284457]
[epoch 301/1000, batch 31/100 -> loss before: 0.1994720617602836, loss after: 0.19936676374688503]
[epoch 301/1000, batch 41/100 -> loss before: 0.19005974335772313, loss after: 0.1897881241540606]
[epoch 301/1000, batch 51/100 -> loss before: 0.2869990014759032, loss after: 0.28696439420559433]
[epoch 301/1000, batch 61/100 -> loss before: 0.28505495930938934, loss after: 0.2849323444942094]
[epoch 301/1000, batch 71/100 -> loss before: 0.2508337634678038, loss after: 0.2505851710249404]
[epoch 301/1000, batch 81/100 -> loss before: 0.33129128059892465, loss after: 0.3312234680249588]
[epoch 301/1000, batch 91/100 -> loss before: 0.2583503546331163, loss after: 0.2578301164142989]
ENDING EPOCH 301/1000 [loss before: 0.23173435871343553, loss after: 0.23075486751888188; epoch time: 0.0787348747253418 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.2816991335767471, loss after: 0.28169458277256615]
[epoch 401/1000, batch 11/100 -> loss before: 0.16177069502888125, loss after: 0.16175473847559452]
[epoch 401/1000, batch 21/100 -> loss before: 0.22432374787925294, loss after: 0.22384082179915876]
[epoch 401/1000, batch 31/100 -> loss before: 0.1656528647973225, loss after: 0.16371764030954764]
[epoch 401/1000, batch 41/100 -> loss before: 0.1567841591212428, loss after: 0.15640941927243313]
[epoch 401/1000, batch 51/100 -> loss before: 0.13610490770819755, loss after: 0.1329306079606445]
[epoch 401/1000, batch 61/100 -> loss before: 0.1658067341383276, loss after: 0.16511502871114622]
[epoch 401/1000, batch 71/100 -> loss before: 0.17826301605950554, loss after: 0.178062245424299]
[epoch 401/1000, batch 81/100 -> loss before: 0.16438856225290305, loss after: 0.16403629228827374]
[epoch 401/1000, batch 91/100 -> loss before: 0.20683938241309363, loss after: 0.20672164551888544]
ENDING EPOCH 401/1000 [loss before: 0.230877497938541, loss after: 0.23166350879242537; epoch time: 0.07546091079711914 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.17210453815588111, loss after: 0.1701083146357657]
[epoch 501/1000, batch 11/100 -> loss before: 0.42691504544465725, loss after: 0.42689942652391455]
[epoch 501/1000, batch 21/100 -> loss before: 0.2992533477380374, loss after: 0.2992119288665904]
[epoch 501/1000, batch 31/100 -> loss before: 0.23130078152535746, loss after: 0.23117914545564805]
[epoch 501/1000, batch 41/100 -> loss before: 0.3181339586454389, loss after: 0.31810872990264427]
[epoch 501/1000, batch 51/100 -> loss before: 0.11684545379216335, loss after: 0.1119808423609014]
[epoch 501/1000, batch 61/100 -> loss before: 0.10808348449416494, loss after: 0.1075746909818381]
[epoch 501/1000, batch 71/100 -> loss before: 0.13786161552807433, loss after: 0.13596084890207238]
[epoch 501/1000, batch 81/100 -> loss before: 0.20908001407355975, loss after: 0.20894364154459436]
[epoch 501/1000, batch 91/100 -> loss before: 0.1713534506372118, loss after: 0.17131734081774583]
ENDING EPOCH 501/1000 [loss before: 0.23085399835654202, loss after: 0.23066254969815997; epoch time: 0.07963275909423828 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.3604069848659104, loss after: 0.3602526834058481]
[epoch 601/1000, batch 11/100 -> loss before: 0.15245531930171785, loss after: 0.15134959918173987]
[epoch 601/1000, batch 21/100 -> loss before: 0.19144961894695856, loss after: 0.19120120228301465]
[epoch 601/1000, batch 31/100 -> loss before: 0.117484317501701, loss after: 0.11702673299900475]
[epoch 601/1000, batch 41/100 -> loss before: 0.33387730948856315, loss after: 0.3334814149277573]
[epoch 601/1000, batch 51/100 -> loss before: 0.3169817195945873, loss after: 0.31648324753745916]
[epoch 601/1000, batch 61/100 -> loss before: 0.10510191443046361, loss after: 0.10175673136909688]
[epoch 601/1000, batch 71/100 -> loss before: 0.3219153510346774, loss after: 0.3202430489005737]
[epoch 601/1000, batch 81/100 -> loss before: 0.30198066915507715, loss after: 0.3015100187076397]
[epoch 601/1000, batch 91/100 -> loss before: 0.252396502340902, loss after: 0.25200519101327556]
ENDING EPOCH 601/1000 [loss before: 0.23062338470815372, loss after: 0.2308013191350217; epoch time: 0.07606768608093262 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.11346912831020566, loss after: 0.11230914316479208]
[epoch 701/1000, batch 11/100 -> loss before: 0.22831806512114805, loss after: 0.2272984002657669]
[epoch 701/1000, batch 21/100 -> loss before: 0.20079049212675226, loss after: 0.20035455239892513]
[epoch 701/1000, batch 31/100 -> loss before: 0.22502774188048047, loss after: 0.2238482352093511]
[epoch 701/1000, batch 41/100 -> loss before: 0.13423257678157713, loss after: 0.13421299537648337]
[epoch 701/1000, batch 51/100 -> loss before: 0.3136688417310899, loss after: 0.31172551950109006]
[epoch 701/1000, batch 61/100 -> loss before: 0.15073466494623555, loss after: 0.15060130939577726]
[epoch 701/1000, batch 71/100 -> loss before: 0.19522853851643118, loss after: 0.19489737282047676]
[epoch 701/1000, batch 81/100 -> loss before: 0.21785678146507187, loss after: 0.21776139193552072]
[epoch 701/1000, batch 91/100 -> loss before: 0.3456348296241623, loss after: 0.34554414666184174]
ENDING EPOCH 701/1000 [loss before: 0.23117123086092226, loss after: 0.2306131816769141; epoch time: 0.07736444473266602 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.1983161400611704, loss after: 0.19776383751526433]
[epoch 801/1000, batch 11/100 -> loss before: 0.11677404332826011, loss after: 0.11676544766159905]
[epoch 801/1000, batch 21/100 -> loss before: 0.24274634005534684, loss after: 0.2414402632016547]
[epoch 801/1000, batch 31/100 -> loss before: 0.15869875809831102, loss after: 0.15860482124564013]
[epoch 801/1000, batch 41/100 -> loss before: 0.2956686919391869, loss after: 0.2953433629263741]
[epoch 801/1000, batch 51/100 -> loss before: 0.14191432043982424, loss after: 0.14127190131709344]
[epoch 801/1000, batch 61/100 -> loss before: 0.25440304526029367, loss after: 0.25434705954618203]
[epoch 801/1000, batch 71/100 -> loss before: 0.2863982924712637, loss after: 0.28583165079987016]
[epoch 801/1000, batch 81/100 -> loss before: 0.17241735290810156, loss after: 0.1721507302436713]
[epoch 801/1000, batch 91/100 -> loss before: 0.23676965742364722, loss after: 0.23654808016063272]
ENDING EPOCH 801/1000 [loss before: 0.2311180267736093, loss after: 0.23081093635594066; epoch time: 0.07208013534545898 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.08358635510904286, loss after: 0.08274508176675896]
[epoch 901/1000, batch 11/100 -> loss before: 0.29549686428743727, loss after: 0.29534798121190997]
[epoch 901/1000, batch 21/100 -> loss before: 0.15176543500429643, loss after: 0.15088244946987486]
[epoch 901/1000, batch 31/100 -> loss before: 0.14150926454062504, loss after: 0.14147828763404327]
[epoch 901/1000, batch 41/100 -> loss before: 0.27044338651700517, loss after: 0.2699192188692665]
[epoch 901/1000, batch 51/100 -> loss before: 0.24630174340749514, loss after: 0.24508743954795792]
[epoch 901/1000, batch 61/100 -> loss before: 0.4139743072480838, loss after: 0.41392654681406016]
[epoch 901/1000, batch 71/100 -> loss before: 0.15969299175447382, loss after: 0.1584721846186745]
[epoch 901/1000, batch 81/100 -> loss before: 0.4225949957424149, loss after: 0.4222038926277216]
[epoch 901/1000, batch 91/100 -> loss before: 0.1994779529954574, loss after: 0.19933244760276364]
ENDING EPOCH 901/1000 [loss before: 0.23058952409288036, loss after: 0.23073305352411705; epoch time: 0.07694125175476074 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.23336762989618806, loss after: 0.23325997507901733]
[epoch 1000/1000, batch 11/100 -> loss before: 0.08668802452281621, loss after: 0.08644467412971321]
[epoch 1000/1000, batch 21/100 -> loss before: 0.19566188004221655, loss after: 0.19527938832170363]
[epoch 1000/1000, batch 31/100 -> loss before: 0.24572285704644678, loss after: 0.2456342640436226]
[epoch 1000/1000, batch 41/100 -> loss before: 0.3466649050382051, loss after: 0.3457858452227654]
[epoch 1000/1000, batch 51/100 -> loss before: 0.1767382233258385, loss after: 0.17528427610106742]
[epoch 1000/1000, batch 61/100 -> loss before: 0.18523745671236458, loss after: 0.1850322462221927]
[epoch 1000/1000, batch 71/100 -> loss before: 0.3686764711774746, loss after: 0.368495442601106]
[epoch 1000/1000, batch 81/100 -> loss before: 0.0985701333905399, loss after: 0.0984504244043647]
[epoch 1000/1000, batch 91/100 -> loss before: 0.34043801370004984, loss after: 0.3403978850921251]
ENDING EPOCH 1000/1000 [loss before: 0.23072504863347063, loss after: 0.23058189579324426; epoch time: 0.07913541793823242 s]
FIT DONE. [time: 72.6251003742218 s]
LOSS TRAIN (MSE): 0.23058189579324426
LOSS TEST (MSE): 0.21927658352762136
R^2 TRAIN: 0.18544798703598553
R^2 TEST: 0.20990056820670822
EXPERIMENT DONE

EXPERIMENT 3232 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 128, 64, 64, 32, 32], activation_name=relu, targets_activation_name=linear, 
initialization_name=uniform, algo_name=rmsprop, learning_rate=0.0001, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 32481]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 0.87553713426397, loss after: 0.6182687706552262]
[epoch 1/1000, batch 11/100 -> loss before: 0.5194547799769448, loss after: 0.15986802911813885]
[epoch 1/1000, batch 21/100 -> loss before: 0.30289998768982046, loss after: 0.24277886471740584]
[epoch 1/1000, batch 31/100 -> loss before: 0.3423466774242029, loss after: 0.2570293609313631]
[epoch 1/1000, batch 41/100 -> loss before: 0.2590440448232424, loss after: 0.20898491810545755]
[epoch 1/1000, batch 51/100 -> loss before: 0.1735729060818649, loss after: 0.09769359545721452]
[epoch 1/1000, batch 61/100 -> loss before: 0.1888223376457334, loss after: 0.14131352508984227]
[epoch 1/1000, batch 71/100 -> loss before: 0.5582903621744749, loss after: 0.3998784038326497]
[epoch 1/1000, batch 81/100 -> loss before: 0.3473835886796137, loss after: 0.31680010785094426]
[epoch 1/1000, batch 91/100 -> loss before: 0.2769167336037686, loss after: 0.19248717875033478]
ENDING EPOCH 1/1000 [loss before: 1.102092538201909, loss after: 0.294832559508518; epoch time: 0.07278084754943848 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.207618607851941, loss after: 0.18339201228137791]
[epoch 101/1000, batch 11/100 -> loss before: 0.16429108911826723, loss after: 0.1434553630945918]
[epoch 101/1000, batch 21/100 -> loss before: 0.17962994063586307, loss after: 0.1299399804993465]
[epoch 101/1000, batch 31/100 -> loss before: 0.09266671696880228, loss after: 0.07867723635738874]
[epoch 101/1000, batch 41/100 -> loss before: 0.12155686414484879, loss after: 0.091486635179613]
[epoch 101/1000, batch 51/100 -> loss before: 0.09674568925659097, loss after: 0.07508209415165983]
[epoch 101/1000, batch 61/100 -> loss before: 0.11764213998984355, loss after: 0.08069039578649354]
[epoch 101/1000, batch 71/100 -> loss before: 0.2600065244755202, loss after: 0.2271611515924576]
[epoch 101/1000, batch 81/100 -> loss before: 0.24042708885327788, loss after: 0.17120537607200847]
[epoch 101/1000, batch 91/100 -> loss before: 0.22367086109836515, loss after: 0.19010836273599607]
ENDING EPOCH 101/1000 [loss before: 0.17616391120785382, loss after: 0.17550819989136085; epoch time: 0.07211828231811523 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.32480833747226556, loss after: 0.29031581968917003]
[epoch 201/1000, batch 11/100 -> loss before: 0.22272839231468486, loss after: 0.13651354285879544]
[epoch 201/1000, batch 21/100 -> loss before: 0.2102337504345785, loss after: 0.09711855314343958]
[epoch 201/1000, batch 31/100 -> loss before: 0.1491655862634789, loss after: 0.08637656626674656]
[epoch 201/1000, batch 41/100 -> loss before: 0.11887576460873935, loss after: 0.055329429034466415]
[epoch 201/1000, batch 51/100 -> loss before: 0.13998172852871835, loss after: 0.10039865532219092]
[epoch 201/1000, batch 61/100 -> loss before: 0.12985244826006728, loss after: 0.09048292983216288]
[epoch 201/1000, batch 71/100 -> loss before: 0.050741482276369154, loss after: 0.020956951746803783]
[epoch 201/1000, batch 81/100 -> loss before: 0.30107564350020444, loss after: 0.16933204885202086]
[epoch 201/1000, batch 91/100 -> loss before: 0.09163649006474937, loss after: 0.07692926284420346]
ENDING EPOCH 201/1000 [loss before: 0.1324292936415291, loss after: 0.12610156190977284; epoch time: 0.07023453712463379 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.01794926888363204, loss after: 0.012876689488884156]
[epoch 301/1000, batch 11/100 -> loss before: 0.027688165358076017, loss after: 0.009241490697087273]
[epoch 301/1000, batch 21/100 -> loss before: 0.0685370266329737, loss after: 0.03841627969544979]
[epoch 301/1000, batch 31/100 -> loss before: 0.04886328954489021, loss after: 0.03468621356926606]
[epoch 301/1000, batch 41/100 -> loss before: 0.15757567565190106, loss after: 0.09358491579949538]
[epoch 301/1000, batch 51/100 -> loss before: 0.06328768621818996, loss after: 0.04755948850955163]
[epoch 301/1000, batch 61/100 -> loss before: 0.07609671393239309, loss after: 0.06228142329760774]
[epoch 301/1000, batch 71/100 -> loss before: 0.07665707483586309, loss after: 0.055700703864441314]
[epoch 301/1000, batch 81/100 -> loss before: 0.03682154242853751, loss after: 0.017446437576167293]
[epoch 301/1000, batch 91/100 -> loss before: 0.04748203178381295, loss after: 0.02648676132489574]
ENDING EPOCH 301/1000 [loss before: 0.10048410643179181, loss after: 0.10376816911728744; epoch time: 0.07095193862915039 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.24323321927385128, loss after: 0.23046445403114113]
[epoch 401/1000, batch 11/100 -> loss before: 0.11191965248493599, loss after: 0.06485595873600111]
[epoch 401/1000, batch 21/100 -> loss before: 0.029346503580113675, loss after: 0.01706694635488578]
[epoch 401/1000, batch 31/100 -> loss before: 0.06285568389998436, loss after: 0.04750536340860757]
[epoch 401/1000, batch 41/100 -> loss before: 0.036810451943504206, loss after: 0.0276298441855317]
[epoch 401/1000, batch 51/100 -> loss before: 0.254243065452362, loss after: 0.13627713701608585]
[epoch 401/1000, batch 61/100 -> loss before: 0.04105821400131076, loss after: 0.030942194832347225]
[epoch 401/1000, batch 71/100 -> loss before: 0.11763679783094572, loss after: 0.08509290169598241]
[epoch 401/1000, batch 81/100 -> loss before: 0.10834987140862391, loss after: 0.06811054792646483]
[epoch 401/1000, batch 91/100 -> loss before: 0.08676019241632871, loss after: 0.0623352261838386]
ENDING EPOCH 401/1000 [loss before: 0.08173858438553336, loss after: 0.08505638755780687; epoch time: 0.07563900947570801 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.0398364112350543, loss after: 0.017496576284049895]
[epoch 501/1000, batch 11/100 -> loss before: 0.0723669889769188, loss after: 0.02835186188325443]
[epoch 501/1000, batch 21/100 -> loss before: 0.1089086698374209, loss after: 0.0836381181166079]
[epoch 501/1000, batch 31/100 -> loss before: 0.06113907387774893, loss after: 0.022653461277294014]
[epoch 501/1000, batch 41/100 -> loss before: 0.030769613739415096, loss after: 0.02535604900728372]
[epoch 501/1000, batch 51/100 -> loss before: 0.1265915483766841, loss after: 0.08155995753404217]
[epoch 501/1000, batch 61/100 -> loss before: 0.045518999350290454, loss after: 0.02086297482843771]
[epoch 501/1000, batch 71/100 -> loss before: 0.029626840149232447, loss after: 0.022606080017775036]
[epoch 501/1000, batch 81/100 -> loss before: 0.1369860222181558, loss after: 0.09683102827204304]
[epoch 501/1000, batch 91/100 -> loss before: 0.12348851896238355, loss after: 0.05088490023717009]
ENDING EPOCH 501/1000 [loss before: 0.07703070161120647, loss after: 0.06514095132714409; epoch time: 0.0756230354309082 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.03156380735491636, loss after: 0.009414447770071619]
[epoch 601/1000, batch 11/100 -> loss before: 0.0416056165264735, loss after: 0.011214674915916416]
[epoch 601/1000, batch 21/100 -> loss before: 0.1359861884968402, loss after: 0.0768900115301032]
[epoch 601/1000, batch 31/100 -> loss before: 0.09715371750445709, loss after: 0.0461379915125775]
[epoch 601/1000, batch 41/100 -> loss before: 0.09706579616364473, loss after: 0.02997654137583088]
[epoch 601/1000, batch 51/100 -> loss before: 0.0783682926510835, loss after: 0.03347575065123948]
[epoch 601/1000, batch 61/100 -> loss before: 0.08895837752185345, loss after: 0.06255266221289393]
[epoch 601/1000, batch 71/100 -> loss before: 0.06163963386558091, loss after: 0.0440383253192319]
[epoch 601/1000, batch 81/100 -> loss before: 0.05512516682880179, loss after: 0.03585100708104051]
[epoch 601/1000, batch 91/100 -> loss before: 0.036136838897024334, loss after: 0.018425804983426764]
ENDING EPOCH 601/1000 [loss before: 0.05087379952871032, loss after: 0.06101683683474131; epoch time: 0.07941007614135742 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.07644649463319234, loss after: 0.04052773789688864]
[epoch 701/1000, batch 11/100 -> loss before: 0.05249221051524552, loss after: 0.013917270622033476]
[epoch 701/1000, batch 21/100 -> loss before: 0.03161544852514974, loss after: 0.009854030495303506]
[epoch 701/1000, batch 31/100 -> loss before: 0.05757377225240976, loss after: 0.0266844711348594]
[epoch 701/1000, batch 41/100 -> loss before: 0.02165766756967023, loss after: 0.007673719394384502]
[epoch 701/1000, batch 51/100 -> loss before: 0.028709222141134177, loss after: 0.00762554397891313]
[epoch 701/1000, batch 61/100 -> loss before: 0.027755896973169984, loss after: 0.005764108096587989]
[epoch 701/1000, batch 71/100 -> loss before: 0.03599186535118323, loss after: 0.016265531289964406]
[epoch 701/1000, batch 81/100 -> loss before: 0.02987654427948565, loss after: 0.012312644991354135]
[epoch 701/1000, batch 91/100 -> loss before: 0.025741015986741334, loss after: 0.009665123175117899]
ENDING EPOCH 701/1000 [loss before: 0.05512409779106156, loss after: 0.03931812116091984; epoch time: 0.0733635425567627 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.00857312428324018, loss after: 0.0026510516066356217]
[epoch 801/1000, batch 11/100 -> loss before: 0.009871963170048624, loss after: 0.005422116914564463]
[epoch 801/1000, batch 21/100 -> loss before: 0.03546598765755069, loss after: 0.009450415632797127]
[epoch 801/1000, batch 31/100 -> loss before: 0.01314938030619823, loss after: 0.006602011106548261]
[epoch 801/1000, batch 41/100 -> loss before: 0.04796019784696251, loss after: 0.028053968324579175]
[epoch 801/1000, batch 51/100 -> loss before: 0.0397983752479907, loss after: 0.015532833862006512]
[epoch 801/1000, batch 61/100 -> loss before: 0.16287987218406053, loss after: 0.04379401137766088]
[epoch 801/1000, batch 71/100 -> loss before: 0.10422863826596714, loss after: 0.05510993201237753]
[epoch 801/1000, batch 81/100 -> loss before: 0.03824313299145058, loss after: 0.01710669725683093]
[epoch 801/1000, batch 91/100 -> loss before: 0.05100658075458249, loss after: 0.05173048794814378]
ENDING EPOCH 801/1000 [loss before: 0.037548255429257014, loss after: 0.06044424604393726; epoch time: 0.07560300827026367 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.016198304060197878, loss after: 0.00702015128694265]
[epoch 901/1000, batch 11/100 -> loss before: 0.03916638049765149, loss after: 0.03881442077864212]
[epoch 901/1000, batch 21/100 -> loss before: 0.005131377838586211, loss after: 0.0019117048383181338]
[epoch 901/1000, batch 31/100 -> loss before: 0.011411544679711342, loss after: 0.002487593720478867]
[epoch 901/1000, batch 41/100 -> loss before: 0.049224887426286904, loss after: 0.02284223953743394]
[epoch 901/1000, batch 51/100 -> loss before: 0.122349401522775, loss after: 0.04635787075897481]
[epoch 901/1000, batch 61/100 -> loss before: 0.015447945462297935, loss after: 0.005166344350993309]
[epoch 901/1000, batch 71/100 -> loss before: 0.01070490514053959, loss after: 0.004338654955242626]
[epoch 901/1000, batch 81/100 -> loss before: 0.09372707028619323, loss after: 0.15760558761006804]
[epoch 901/1000, batch 91/100 -> loss before: 0.03871350873528638, loss after: 0.010086762346410979]
ENDING EPOCH 901/1000 [loss before: 0.02883768095165008, loss after: 0.08136311265312975; epoch time: 0.08018231391906738 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.045606203341856597, loss after: 0.03252827757563885]
[epoch 1000/1000, batch 11/100 -> loss before: 0.020018099762081153, loss after: 0.0353395124733338]
[epoch 1000/1000, batch 21/100 -> loss before: 0.006535518543919529, loss after: 0.0013958549137638558]
[epoch 1000/1000, batch 31/100 -> loss before: 0.029349077206843162, loss after: 0.018317727071702088]
[epoch 1000/1000, batch 41/100 -> loss before: 0.05065928090006927, loss after: 0.008404392773885595]
[epoch 1000/1000, batch 51/100 -> loss before: 0.043919049329087446, loss after: 0.026003435466378323]
[epoch 1000/1000, batch 61/100 -> loss before: 0.02308468599766681, loss after: 0.007353013058362906]
[epoch 1000/1000, batch 71/100 -> loss before: 0.006307059618669829, loss after: 0.003650411247471068]
[epoch 1000/1000, batch 81/100 -> loss before: 0.011888061918435906, loss after: 0.006693064034196822]
[epoch 1000/1000, batch 91/100 -> loss before: 0.0939582575395285, loss after: 0.04282607933965503]
ENDING EPOCH 1000/1000 [loss before: 0.02929618605402223, loss after: 0.029996051308904738; epoch time: 0.0766444206237793 s]
FIT DONE. [time: 68.7609441280365 s]
LOSS TRAIN (MSE): 0.029996051308904738
LOSS TEST (MSE): 0.04299528394631755
R^2 TRAIN: 0.89403615626203
R^2 TEST: 0.8450789917041115
EXPERIMENT DONE

EXPERIMENT 2231 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 64, 32], activation_name=relu, targets_activation_name=linear, 
initialization_name=uniform, algo_name=rmsprop, learning_rate=0.001, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 10753]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 20.679362556386955, loss after: 4.738388326499038]
[epoch 1/1000, batch 11/100 -> loss before: 0.4410663400535436, loss after: 0.29697500861758386]
[epoch 1/1000, batch 21/100 -> loss before: 0.09642839819850449, loss after: 0.08422825987486095]
[epoch 1/1000, batch 31/100 -> loss before: 0.6272410517451642, loss after: 0.4322844333579984]
[epoch 1/1000, batch 41/100 -> loss before: 0.25615099324896623, loss after: 0.22545657695242394]
[epoch 1/1000, batch 51/100 -> loss before: 0.24463925766309882, loss after: 0.20523879987955768]
[epoch 1/1000, batch 61/100 -> loss before: 0.5436073129171348, loss after: 0.3466301983107076]
[epoch 1/1000, batch 71/100 -> loss before: 0.7695512318998265, loss after: 0.3327366465166091]
[epoch 1/1000, batch 81/100 -> loss before: 0.08995360501338227, loss after: 0.08060925717648422]
[epoch 1/1000, batch 91/100 -> loss before: 0.6222185965573533, loss after: 0.5559098209699487]
ENDING EPOCH 1/1000 [loss before: 18.773492598911375, loss after: 0.2890311107303012; epoch time: 0.03289031982421875 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.15935570179962083, loss after: 0.15397367266230802]
[epoch 101/1000, batch 11/100 -> loss before: 0.05821442235578935, loss after: 0.032695910350087384]
[epoch 101/1000, batch 21/100 -> loss before: 0.14763529810375908, loss after: 0.11602621849895918]
[epoch 101/1000, batch 31/100 -> loss before: 0.03859600112504026, loss after: 0.026647745532073625]
[epoch 101/1000, batch 41/100 -> loss before: 0.3779593308443988, loss after: 0.32041354667182514]
[epoch 101/1000, batch 51/100 -> loss before: 0.08062528326160148, loss after: 0.018327393384728875]
[epoch 101/1000, batch 61/100 -> loss before: 0.07263005613636142, loss after: 0.04233223569851631]
[epoch 101/1000, batch 71/100 -> loss before: 0.21816292824301425, loss after: 0.1743611810536283]
[epoch 101/1000, batch 81/100 -> loss before: 0.21552839646321065, loss after: 0.1793146760722491]
[epoch 101/1000, batch 91/100 -> loss before: 0.03061610751072994, loss after: 0.020035682062404536]
ENDING EPOCH 101/1000 [loss before: 0.12405225342684423, loss after: 0.15122000829695215; epoch time: 0.03595304489135742 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.04871016619630316, loss after: 0.029569500403928296]
[epoch 201/1000, batch 11/100 -> loss before: 0.1210832160334974, loss after: 0.06779030208459602]
[epoch 201/1000, batch 21/100 -> loss before: 0.2563269697267706, loss after: 0.1780792555315745]
[epoch 201/1000, batch 31/100 -> loss before: 0.05286120065524859, loss after: 0.03420904135926695]
[epoch 201/1000, batch 41/100 -> loss before: 0.1966146612106721, loss after: 0.15648144595238275]
[epoch 201/1000, batch 51/100 -> loss before: 0.14758782205895912, loss after: 0.11575901163775688]
[epoch 201/1000, batch 61/100 -> loss before: 0.09655526306616383, loss after: 0.03465902244692699]
[epoch 201/1000, batch 71/100 -> loss before: 0.08975027389794202, loss after: 0.05975164185778237]
[epoch 201/1000, batch 81/100 -> loss before: 0.0706481979974921, loss after: 0.04344672779885781]
[epoch 201/1000, batch 91/100 -> loss before: 0.14177714781384695, loss after: 0.06273564047144839]
ENDING EPOCH 201/1000 [loss before: 0.1025319973196265, loss after: 0.09334484375205579; epoch time: 0.02100372314453125 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.06014918300231389, loss after: 0.038212896995479556]
[epoch 301/1000, batch 11/100 -> loss before: 0.06993867544556619, loss after: 0.055856618122392364]
[epoch 301/1000, batch 21/100 -> loss before: 0.06286723082640587, loss after: 0.04061791446466283]
[epoch 301/1000, batch 31/100 -> loss before: 0.07922820103008317, loss after: 0.04362221906002227]
[epoch 301/1000, batch 41/100 -> loss before: 0.03339142674844446, loss after: 0.018590072460544622]
[epoch 301/1000, batch 51/100 -> loss before: 0.055184012686006235, loss after: 0.01729875400864747]
[epoch 301/1000, batch 61/100 -> loss before: 0.15734162368921087, loss after: 0.12310221942704043]
[epoch 301/1000, batch 71/100 -> loss before: 0.13931744774275306, loss after: 0.07525891182989368]
[epoch 301/1000, batch 81/100 -> loss before: 0.061442097138436604, loss after: 0.04781385042168099]
[epoch 301/1000, batch 91/100 -> loss before: 0.0259104489263549, loss after: 0.007605093469526478]
ENDING EPOCH 301/1000 [loss before: 0.08413092120184802, loss after: 0.07889595705747274; epoch time: 0.0215606689453125 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.025761828921823337, loss after: 0.006192008551667455]
[epoch 401/1000, batch 11/100 -> loss before: 0.07077849085592892, loss after: 0.04644462646306829]
[epoch 401/1000, batch 21/100 -> loss before: 0.04623226820812436, loss after: 0.00814784733839846]
[epoch 401/1000, batch 31/100 -> loss before: 0.03699738881459445, loss after: 0.05278252263335541]
[epoch 401/1000, batch 41/100 -> loss before: 0.04305958912042192, loss after: 0.028300014646451828]
[epoch 401/1000, batch 51/100 -> loss before: 0.16752911560655853, loss after: 0.0637215120880156]
[epoch 401/1000, batch 61/100 -> loss before: 0.04846017396770104, loss after: 0.027363506465213787]
[epoch 401/1000, batch 71/100 -> loss before: 0.06246953117891255, loss after: 0.036934396851284676]
[epoch 401/1000, batch 81/100 -> loss before: 0.042427418736522275, loss after: 0.03169819254534233]
[epoch 401/1000, batch 91/100 -> loss before: 0.12072768917910122, loss after: 0.06409998742946404]
ENDING EPOCH 401/1000 [loss before: 0.05774102657212839, loss after: 0.04352167875128894; epoch time: 0.02199578285217285 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.03329960403220715, loss after: 0.0072426897763759185]
[epoch 501/1000, batch 11/100 -> loss before: 0.04656962435112962, loss after: 0.013479528271104985]
[epoch 501/1000, batch 21/100 -> loss before: 0.03363714540038211, loss after: 0.022653825460353296]
[epoch 501/1000, batch 31/100 -> loss before: 0.031119194112277704, loss after: 0.07150058897361619]
[epoch 501/1000, batch 41/100 -> loss before: 0.048289872522504954, loss after: 0.019275254878934618]
[epoch 501/1000, batch 51/100 -> loss before: 0.025637493659464734, loss after: 0.00738451309631]
[epoch 501/1000, batch 61/100 -> loss before: 0.06729345543887763, loss after: 0.013686484988459455]
[epoch 501/1000, batch 71/100 -> loss before: 0.023262143046063555, loss after: 0.012445972902662968]
[epoch 501/1000, batch 81/100 -> loss before: 0.06136616993725982, loss after: 0.0170508363135363]
[epoch 501/1000, batch 91/100 -> loss before: 0.11519018219856389, loss after: 0.06904698037943993]
ENDING EPOCH 501/1000 [loss before: 0.04429935040337825, loss after: 0.03795504535471525; epoch time: 0.03650188446044922 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.057958973130421684, loss after: 0.024588385233222685]
[epoch 601/1000, batch 11/100 -> loss before: 0.02254673198466128, loss after: 0.009938804464879858]
[epoch 601/1000, batch 21/100 -> loss before: 0.01621188227485898, loss after: 0.0073264768400352785]
[epoch 601/1000, batch 31/100 -> loss before: 0.042811844214404635, loss after: 0.015432111050850775]
[epoch 601/1000, batch 41/100 -> loss before: 0.011004581829302995, loss after: 0.0037397763072117484]
[epoch 601/1000, batch 51/100 -> loss before: 0.024545507813863682, loss after: 0.011400544979343197]
[epoch 601/1000, batch 61/100 -> loss before: 0.030564320058840338, loss after: 0.031497218671367774]
[epoch 601/1000, batch 71/100 -> loss before: 0.1342227526816275, loss after: 0.022935789800106406]
[epoch 601/1000, batch 81/100 -> loss before: 0.027067205310329745, loss after: 0.019935634033598215]
[epoch 601/1000, batch 91/100 -> loss before: 0.02181104575862087, loss after: 0.012943591007065696]
ENDING EPOCH 601/1000 [loss before: 0.03437717482828845, loss after: 0.037939123462427136; epoch time: 0.040247440338134766 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.0052494334893147185, loss after: 0.0027931711393425285]
[epoch 701/1000, batch 11/100 -> loss before: 0.011764243252282756, loss after: 0.0059237350005408845]
[epoch 701/1000, batch 21/100 -> loss before: 0.008373993813886612, loss after: 0.002282107508431261]
[epoch 701/1000, batch 31/100 -> loss before: 0.005385308572268689, loss after: 0.0029486359996731097]
[epoch 701/1000, batch 41/100 -> loss before: 0.04119576247169435, loss after: 0.03197053203587484]
[epoch 701/1000, batch 51/100 -> loss before: 0.01260172497985582, loss after: 0.0067674736870010025]
[epoch 701/1000, batch 61/100 -> loss before: 0.026010142267080462, loss after: 0.0047038628660261515]
[epoch 701/1000, batch 71/100 -> loss before: 0.0371255368318667, loss after: 0.010043924602015976]
[epoch 701/1000, batch 81/100 -> loss before: 0.028092618001440472, loss after: 0.011335278859885528]
[epoch 701/1000, batch 91/100 -> loss before: 0.0481308128168728, loss after: 0.015817627861930732]
ENDING EPOCH 701/1000 [loss before: 0.026549180550611524, loss after: 0.035262154893479745; epoch time: 0.04228377342224121 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.03601778483772324, loss after: 0.05290100055400786]
[epoch 801/1000, batch 11/100 -> loss before: 0.04649409095822777, loss after: 0.01060749112686744]
[epoch 801/1000, batch 21/100 -> loss before: 0.036807605188407956, loss after: 0.01596832646537456]
[epoch 801/1000, batch 31/100 -> loss before: 0.015703333125532775, loss after: 0.007168041522440745]
[epoch 801/1000, batch 41/100 -> loss before: 0.04942600132409534, loss after: 0.028590637991548085]
[epoch 801/1000, batch 51/100 -> loss before: 0.020119481797143512, loss after: 0.023683206237734403]
[epoch 801/1000, batch 61/100 -> loss before: 0.009770664184456154, loss after: 0.0074319629457777455]
[epoch 801/1000, batch 71/100 -> loss before: 0.005879531561139205, loss after: 0.0036157623317395805]
[epoch 801/1000, batch 81/100 -> loss before: 0.011929916809700071, loss after: 0.008433030074290936]
[epoch 801/1000, batch 91/100 -> loss before: 0.012897176920807968, loss after: 0.00404955412305175]
ENDING EPOCH 801/1000 [loss before: 0.05773101717258065, loss after: 0.022986267353480628; epoch time: 0.033056020736694336 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.00678319448767196, loss after: 0.0033299848037471997]
[epoch 901/1000, batch 11/100 -> loss before: 0.02732312551517218, loss after: 0.010941626635984168]
[epoch 901/1000, batch 21/100 -> loss before: 0.022117881105006468, loss after: 0.01283422288641096]
[epoch 901/1000, batch 31/100 -> loss before: 0.12645509491454476, loss after: 0.07260573187369511]
[epoch 901/1000, batch 41/100 -> loss before: 0.019903751096463234, loss after: 0.002764091428085565]
[epoch 901/1000, batch 51/100 -> loss before: 0.05181880966689754, loss after: 0.016169575251657558]
[epoch 901/1000, batch 61/100 -> loss before: 0.09326031357948787, loss after: 0.0381272481949949]
[epoch 901/1000, batch 71/100 -> loss before: 0.016536264238452482, loss after: 0.004570679560243482]
[epoch 901/1000, batch 81/100 -> loss before: 0.03335623543162303, loss after: 0.013879964488517646]
[epoch 901/1000, batch 91/100 -> loss before: 0.018028776516261856, loss after: 0.004839826618423655]
ENDING EPOCH 901/1000 [loss before: 0.027269907631641544, loss after: 0.023606380805792356; epoch time: 0.03138375282287598 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.016063594898737116, loss after: 0.006535283064735828]
[epoch 1000/1000, batch 11/100 -> loss before: 0.005707401134221865, loss after: 0.0036592982533875072]
[epoch 1000/1000, batch 21/100 -> loss before: 0.027155203914852537, loss after: 0.015033166638319023]
[epoch 1000/1000, batch 31/100 -> loss before: 0.035758680156610004, loss after: 0.017652174187745583]
[epoch 1000/1000, batch 41/100 -> loss before: 0.023624446728946723, loss after: 0.021300388862353366]
[epoch 1000/1000, batch 51/100 -> loss before: 0.0579558897506575, loss after: 0.03166313599339004]
[epoch 1000/1000, batch 61/100 -> loss before: 0.007629464136017351, loss after: 0.0022151849987212717]
[epoch 1000/1000, batch 71/100 -> loss before: 0.018782528638283023, loss after: 0.007593074623525477]
[epoch 1000/1000, batch 81/100 -> loss before: 0.013215890637290197, loss after: 0.007941174934218993]
[epoch 1000/1000, batch 91/100 -> loss before: 0.09598064748668013, loss after: 0.07906424520827735]
ENDING EPOCH 1000/1000 [loss before: 0.019854570195946504, loss after: 0.020377692287074957; epoch time: 0.04217243194580078 s]
FIT DONE. [time: 31.70800232887268 s]
LOSS TRAIN (MSE): 0.020377692287074957
LOSS TEST (MSE): 0.028940842496901258
R^2 TRAIN: 0.9280139049299789
R^2 TEST: 0.8957200862738702
EXPERIMENT DONE

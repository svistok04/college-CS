EXPERIMENT 2131 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 64, 32], activation_name=sigmoid, targets_activation_name=linear, 
initialization_name=uniform, algo_name=rmsprop, learning_rate=0.001, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 10753]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 1.6197437009973044, loss after: 0.9645151156412523]
[epoch 1/1000, batch 11/100 -> loss before: 0.19449842376811705, loss after: 0.18856683017969506]
[epoch 1/1000, batch 21/100 -> loss before: 0.11119457702516788, loss after: 0.08382070895281862]
[epoch 1/1000, batch 31/100 -> loss before: 0.44978077248028664, loss after: 0.4485182306176636]
[epoch 1/1000, batch 41/100 -> loss before: 0.16837091126016343, loss after: 0.1673161620783394]
[epoch 1/1000, batch 51/100 -> loss before: 0.33226873293114934, loss after: 0.2655782099536931]
[epoch 1/1000, batch 61/100 -> loss before: 0.5128888111494957, loss after: 0.49123110664841524]
[epoch 1/1000, batch 71/100 -> loss before: 0.45878695892998006, loss after: 0.3990270714390697]
[epoch 1/1000, batch 81/100 -> loss before: 0.14593070194113272, loss after: 0.13681034041243206]
[epoch 1/1000, batch 91/100 -> loss before: 0.38930506316388097, loss after: 0.38368319210721036]
ENDING EPOCH 1/1000 [loss before: 0.7227142221308361, loss after: 0.2787237793643834; epoch time: 0.037775516510009766 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.15278275696030777, loss after: 0.15086691198711966]
[epoch 101/1000, batch 11/100 -> loss before: 0.09264021133307489, loss after: 0.0837029353570021]
[epoch 101/1000, batch 21/100 -> loss before: 0.0900801921236758, loss after: 0.08919681589016364]
[epoch 101/1000, batch 31/100 -> loss before: 0.11307588059727769, loss after: 0.11265154744011577]
[epoch 101/1000, batch 41/100 -> loss before: 0.4198033532265287, loss after: 0.39096977421672185]
[epoch 101/1000, batch 51/100 -> loss before: 0.12077798662355199, loss after: 0.1165585734952258]
[epoch 101/1000, batch 61/100 -> loss before: 0.16132238527826312, loss after: 0.15502172897673133]
[epoch 101/1000, batch 71/100 -> loss before: 0.22651037877201857, loss after: 0.22443948020618665]
[epoch 101/1000, batch 81/100 -> loss before: 0.2735885726558582, loss after: 0.25953901895356213]
[epoch 101/1000, batch 91/100 -> loss before: 0.13353583541327088, loss after: 0.12093291657532831]
ENDING EPOCH 101/1000 [loss before: 0.19622797362367095, loss after: 0.19625841427913032; epoch time: 0.03484630584716797 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.17706287463232978, loss after: 0.1628575974465228]
[epoch 201/1000, batch 11/100 -> loss before: 0.12265669171898594, loss after: 0.10127252041051205]
[epoch 201/1000, batch 21/100 -> loss before: 0.1901549428371111, loss after: 0.18125739716209283]
[epoch 201/1000, batch 31/100 -> loss before: 0.06452516562900065, loss after: 0.05844146599207397]
[epoch 201/1000, batch 41/100 -> loss before: 0.34161192790827666, loss after: 0.33232464926590916]
[epoch 201/1000, batch 51/100 -> loss before: 0.15158312095617993, loss after: 0.13657753228193958]
[epoch 201/1000, batch 61/100 -> loss before: 0.13448290114443873, loss after: 0.12956554680586488]
[epoch 201/1000, batch 71/100 -> loss before: 0.12475048333915743, loss after: 0.10948520498876776]
[epoch 201/1000, batch 81/100 -> loss before: 0.08974884963188745, loss after: 0.07607070347474729]
[epoch 201/1000, batch 91/100 -> loss before: 0.10410501956296425, loss after: 0.09249293869315102]
ENDING EPOCH 201/1000 [loss before: 0.14396677185727327, loss after: 0.14070338917028544; epoch time: 0.037528276443481445 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.03633885107567529, loss after: 0.008320527324502896]
[epoch 301/1000, batch 11/100 -> loss before: 0.11402636849249077, loss after: 0.10762760674734732]
[epoch 301/1000, batch 21/100 -> loss before: 0.10346616185406536, loss after: 0.06958854856027753]
[epoch 301/1000, batch 31/100 -> loss before: 0.08501501638285434, loss after: 0.0708889359028215]
[epoch 301/1000, batch 41/100 -> loss before: 0.06468622509172045, loss after: 0.05713400070166168]
[epoch 301/1000, batch 51/100 -> loss before: 0.06400362902626067, loss after: 0.05081814728593255]
[epoch 301/1000, batch 61/100 -> loss before: 0.17327065063779062, loss after: 0.16301128855723643]
[epoch 301/1000, batch 71/100 -> loss before: 0.20058692590134325, loss after: 0.15874283122198204]
[epoch 301/1000, batch 81/100 -> loss before: 0.06065911865428669, loss after: 0.05378525183980219]
[epoch 301/1000, batch 91/100 -> loss before: 0.027514907502894297, loss after: 0.021326413759031597]
ENDING EPOCH 301/1000 [loss before: 0.10538186070823996, loss after: 0.09894338223584018; epoch time: 0.0336301326751709 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.01971353353601816, loss after: 0.012398639373414216]
[epoch 401/1000, batch 11/100 -> loss before: 0.18411178841352038, loss after: 0.17818765193581848]
[epoch 401/1000, batch 21/100 -> loss before: 0.08114733550828362, loss after: 0.06764085342015597]
[epoch 401/1000, batch 31/100 -> loss before: 0.045269600840628255, loss after: 0.021420160276325366]
[epoch 401/1000, batch 41/100 -> loss before: 0.08795509759538021, loss after: 0.07917906835296337]
[epoch 401/1000, batch 51/100 -> loss before: 0.1869496505002719, loss after: 0.16833775122217337]
[epoch 401/1000, batch 61/100 -> loss before: 0.05104745605342487, loss after: 0.03747466072914325]
[epoch 401/1000, batch 71/100 -> loss before: 0.11750993265673867, loss after: 0.0922483467413833]
[epoch 401/1000, batch 81/100 -> loss before: 0.050594144775651606, loss after: 0.04663403322483996]
[epoch 401/1000, batch 91/100 -> loss before: 0.08557502269684644, loss after: 0.08167589498167922]
ENDING EPOCH 401/1000 [loss before: 0.081944561227659, loss after: 0.07840636834905422; epoch time: 0.046021223068237305 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.026846730888584656, loss after: 0.017001443482085606]
[epoch 501/1000, batch 11/100 -> loss before: 0.07501827519212631, loss after: 0.0676319222680965]
[epoch 501/1000, batch 21/100 -> loss before: 0.09866648034462606, loss after: 0.0747819558513051]
[epoch 501/1000, batch 31/100 -> loss before: 0.03384202861381297, loss after: 0.010047918874197405]
[epoch 501/1000, batch 41/100 -> loss before: 0.04770804841079239, loss after: 0.02627269926800228]
[epoch 501/1000, batch 51/100 -> loss before: 0.013841071494926128, loss after: 0.004792432389054255]
[epoch 501/1000, batch 61/100 -> loss before: 0.014136743014566073, loss after: 0.009686024306692392]
[epoch 501/1000, batch 71/100 -> loss before: 0.05912138374821822, loss after: 0.04483286953473164]
[epoch 501/1000, batch 81/100 -> loss before: 0.03242530032358453, loss after: 0.019992662100291655]
[epoch 501/1000, batch 91/100 -> loss before: 0.11441002388445054, loss after: 0.10357914865443892]
ENDING EPOCH 501/1000 [loss before: 0.05330207645755068, loss after: 0.05130551102152448; epoch time: 0.03501415252685547 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.06510684507459201, loss after: 0.025400279419646586]
[epoch 601/1000, batch 11/100 -> loss before: 0.03792243936078277, loss after: 0.02906402851929075]
[epoch 601/1000, batch 21/100 -> loss before: 0.01271057923290669, loss after: 0.006624830304972249]
[epoch 601/1000, batch 31/100 -> loss before: 0.04043258946202503, loss after: 0.020203377466628935]
[epoch 601/1000, batch 41/100 -> loss before: 0.012612626137801388, loss after: 0.005639665477740134]
[epoch 601/1000, batch 51/100 -> loss before: 0.029239015318258343, loss after: 0.01722039348106196]
[epoch 601/1000, batch 61/100 -> loss before: 0.06777936965858757, loss after: 0.046579568865105545]
[epoch 601/1000, batch 71/100 -> loss before: 0.05717371595862479, loss after: 0.03668716560483853]
[epoch 601/1000, batch 81/100 -> loss before: 0.040475895807121076, loss after: 0.017570551695747193]
[epoch 601/1000, batch 91/100 -> loss before: 0.06571469752248951, loss after: 0.055110340744430275]
ENDING EPOCH 601/1000 [loss before: 0.03738542184767547, loss after: 0.03926610139554528; epoch time: 0.03374934196472168 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.014900695187517738, loss after: 0.009163071642199917]
[epoch 701/1000, batch 11/100 -> loss before: 0.00711022681637911, loss after: 0.004655243107956406]
[epoch 701/1000, batch 21/100 -> loss before: 0.007334788288403676, loss after: 0.004894828231345805]
[epoch 701/1000, batch 31/100 -> loss before: 0.007642708656670797, loss after: 0.004577584271290492]
[epoch 701/1000, batch 41/100 -> loss before: 0.022608828843682136, loss after: 0.014090246207822524]
[epoch 701/1000, batch 51/100 -> loss before: 0.014480508557684799, loss after: 0.00924621283528886]
[epoch 701/1000, batch 61/100 -> loss before: 0.02471629921995388, loss after: 0.016026127041947762]
[epoch 701/1000, batch 71/100 -> loss before: 0.04417987040422482, loss after: 0.018561763964159515]
[epoch 701/1000, batch 81/100 -> loss before: 0.03930057134835929, loss after: 0.03016335325573647]
[epoch 701/1000, batch 91/100 -> loss before: 0.07372310736078988, loss after: 0.05984860183440836]
ENDING EPOCH 701/1000 [loss before: 0.033865344738568455, loss after: 0.0410061402991593; epoch time: 0.03597426414489746 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.04001284364130054, loss after: 0.022924461328966562]
[epoch 801/1000, batch 11/100 -> loss before: 0.029038871000238255, loss after: 0.019974271870705197]
[epoch 801/1000, batch 21/100 -> loss before: 0.01172838703478686, loss after: 0.007153266594008709]
[epoch 801/1000, batch 31/100 -> loss before: 0.009346900360888184, loss after: 0.004737367573569915]
[epoch 801/1000, batch 41/100 -> loss before: 0.06193816041034408, loss after: 0.0384954974398037]
[epoch 801/1000, batch 51/100 -> loss before: 0.03368348364524437, loss after: 0.01688382658680354]
[epoch 801/1000, batch 61/100 -> loss before: 0.010989597563446123, loss after: 0.005737430309129635]
[epoch 801/1000, batch 71/100 -> loss before: 0.003142554279228137, loss after: 0.0024618705823545904]
[epoch 801/1000, batch 81/100 -> loss before: 0.02248611596260546, loss after: 0.01045808040523565]
[epoch 801/1000, batch 91/100 -> loss before: 0.030359232006749816, loss after: 0.011565520962581555]
ENDING EPOCH 801/1000 [loss before: 0.033990375862611305, loss after: 0.029291328871603968; epoch time: 0.04195237159729004 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.0019202940507501627, loss after: 0.001123215176534032]
[epoch 901/1000, batch 11/100 -> loss before: 0.007481212119479129, loss after: 0.004451772885633033]
[epoch 901/1000, batch 21/100 -> loss before: 0.018565629452241775, loss after: 0.012765263731819285]
[epoch 901/1000, batch 31/100 -> loss before: 0.15529914262904926, loss after: 0.11624055045019666]
[epoch 901/1000, batch 41/100 -> loss before: 0.01309646170875856, loss after: 0.003281592030241716]
[epoch 901/1000, batch 51/100 -> loss before: 0.10790888299092441, loss after: 0.09202933828083076]
[epoch 901/1000, batch 61/100 -> loss before: 0.05188523342880038, loss after: 0.0270299727378037]
[epoch 901/1000, batch 71/100 -> loss before: 0.007620834783825027, loss after: 0.005856755224936611]
[epoch 901/1000, batch 81/100 -> loss before: 0.03509658304331841, loss after: 0.015024988139556106]
[epoch 901/1000, batch 91/100 -> loss before: 0.007360673159717361, loss after: 0.004646015298536021]
ENDING EPOCH 901/1000 [loss before: 0.027527732487654583, loss after: 0.02715810375751277; epoch time: 0.03999614715576172 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.029730074020211317, loss after: 0.007968945057198019]
[epoch 1000/1000, batch 11/100 -> loss before: 0.00834950774757626, loss after: 0.004440513231382987]
[epoch 1000/1000, batch 21/100 -> loss before: 0.06330186707304417, loss after: 0.02259219584073485]
[epoch 1000/1000, batch 31/100 -> loss before: 0.04936498849947331, loss after: 0.03827215864381825]
[epoch 1000/1000, batch 41/100 -> loss before: 0.014906719968531193, loss after: 0.007449545219167966]
[epoch 1000/1000, batch 51/100 -> loss before: 0.11309387795617194, loss after: 0.08791179918383248]
[epoch 1000/1000, batch 61/100 -> loss before: 0.016577121441710595, loss after: 0.008043112093540373]
[epoch 1000/1000, batch 71/100 -> loss before: 0.013228365631714537, loss after: 0.009428113220586646]
[epoch 1000/1000, batch 81/100 -> loss before: 0.028480859247808875, loss after: 0.0186457441653687]
[epoch 1000/1000, batch 91/100 -> loss before: 0.09295710559015744, loss after: 0.08724110397055883]
ENDING EPOCH 1000/1000 [loss before: 0.02592215752339231, loss after: 0.028753678646780963; epoch time: 0.03615283966064453 s]
FIT DONE. [time: 32.76916861534119 s]
LOSS TRAIN (MSE): 0.028753678646780963
LOSS TEST (MSE): 0.030140009313352287
R^2 TRAIN: 0.8984249533499497
R^2 TEST: 0.8913992372116448
EXPERIMENT DONE

EXPERIMENT 2213 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[64, 64, 64, 64, 64, 32, 32, 32, 32, 32, 16, 16, 16, 16, 16, 8, 8, 8, 8, 8], activation_name=relu, targets_activation_name=linear, 
initialization_name=uniform, algo_name=sgd_simple, learning_rate=0.001, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 25185]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 0.18318931763552243, loss after: 0.17593067113950667]
[epoch 1/1000, batch 11/100 -> loss before: 0.34908833838708014, loss after: 0.3462527165514505]
[epoch 1/1000, batch 21/100 -> loss before: 0.3554250446989994, loss after: 0.3554051067493797]
[epoch 1/1000, batch 31/100 -> loss before: 0.38190929253314065, loss after: 0.3814286190505512]
[epoch 1/1000, batch 41/100 -> loss before: 0.20506137806827712, loss after: 0.20487767959394992]
[epoch 1/1000, batch 51/100 -> loss before: 0.24687762637322636, loss after: 0.24625454910649042]
[epoch 1/1000, batch 61/100 -> loss before: 0.46813630109678883, loss after: 0.46810332174093416]
[epoch 1/1000, batch 71/100 -> loss before: 0.34028577617597516, loss after: 0.34019100578514233]
[epoch 1/1000, batch 81/100 -> loss before: 0.39918721189031536, loss after: 0.3990958308831878]
[epoch 1/1000, batch 91/100 -> loss before: 0.29993423361253246, loss after: 0.29956971981787517]
ENDING EPOCH 1/1000 [loss before: 0.2899884218128069, loss after: 0.28309880671050924; epoch time: 0.07222914695739746 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.28649125037472184, loss after: 0.28634602517058594]
[epoch 101/1000, batch 11/100 -> loss before: 0.22066862168703558, loss after: 0.22063235269842382]
[epoch 101/1000, batch 21/100 -> loss before: 0.24272734452092298, loss after: 0.24249333850295224]
[epoch 101/1000, batch 31/100 -> loss before: 0.3891286553921868, loss after: 0.38810878415583483]
[epoch 101/1000, batch 41/100 -> loss before: 0.6571790343934241, loss after: 0.6486109149032829]
[epoch 101/1000, batch 51/100 -> loss before: 0.26338289772152923, loss after: 0.26045757144909765]
[epoch 101/1000, batch 61/100 -> loss before: 0.5158282271066572, loss after: 0.5157572862890056]
[epoch 101/1000, batch 71/100 -> loss before: 0.14568308781003733, loss after: 0.1456128266787358]
[epoch 101/1000, batch 81/100 -> loss before: 0.2660955902228544, loss after: 0.2658990173603917]
[epoch 101/1000, batch 91/100 -> loss before: 0.24436483534549516, loss after: 0.2425452414651243]
ENDING EPOCH 101/1000 [loss before: 0.2830781840369027, loss after: 0.2830813053307439; epoch time: 0.07191944122314453 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.08813338777936547, loss after: 0.08813066181054345]
[epoch 201/1000, batch 11/100 -> loss before: 0.357418753466029, loss after: 0.35692696164834353]
[epoch 201/1000, batch 21/100 -> loss before: 0.18872801920728452, loss after: 0.18715065802658115]
[epoch 201/1000, batch 31/100 -> loss before: 0.4618065828941047, loss after: 0.4611750599258845]
[epoch 201/1000, batch 41/100 -> loss before: 0.3178063015838926, loss after: 0.31656993242056347]
[epoch 201/1000, batch 51/100 -> loss before: 0.2844173342154356, loss after: 0.28430906427418773]
[epoch 201/1000, batch 61/100 -> loss before: 0.48530875347890284, loss after: 0.48480711781576585]
[epoch 201/1000, batch 71/100 -> loss before: 0.41376409236420864, loss after: 0.4135053290188823]
[epoch 201/1000, batch 81/100 -> loss before: 0.19905218382937762, loss after: 0.19903813557251102]
[epoch 201/1000, batch 91/100 -> loss before: 0.10910710183480928, loss after: 0.10910161578975486]
ENDING EPOCH 201/1000 [loss before: 0.28308538942759015, loss after: 0.28309050258482116; epoch time: 0.07148933410644531 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.18879703538152542, loss after: 0.18871028395535158]
[epoch 301/1000, batch 11/100 -> loss before: 0.20111482821645166, loss after: 0.20096133677552452]
[epoch 301/1000, batch 21/100 -> loss before: 0.3076452887554443, loss after: 0.30643073606327215]
[epoch 301/1000, batch 31/100 -> loss before: 0.3252335476073428, loss after: 0.3231555013752093]
[epoch 301/1000, batch 41/100 -> loss before: 0.2605574292314132, loss after: 0.25976419822860713]
[epoch 301/1000, batch 51/100 -> loss before: 0.28253076092718404, loss after: 0.2825238049515428]
[epoch 301/1000, batch 61/100 -> loss before: 0.3128528796736244, loss after: 0.3111006344282301]
[epoch 301/1000, batch 71/100 -> loss before: 0.31002955571216123, loss after: 0.309489923324224]
[epoch 301/1000, batch 81/100 -> loss before: 0.32257731764930353, loss after: 0.3225620790136654]
[epoch 301/1000, batch 91/100 -> loss before: 0.3158351061063402, loss after: 0.3115858185549925]
ENDING EPOCH 301/1000 [loss before: 0.2830809343280859, loss after: 0.2831145423680607; epoch time: 0.0936129093170166 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.28503837872438137, loss after: 0.28488196491075146]
[epoch 401/1000, batch 11/100 -> loss before: 0.2755952216305704, loss after: 0.27545246700433335]
[epoch 401/1000, batch 21/100 -> loss before: 0.3392118225719393, loss after: 0.33594234947731966]
[epoch 401/1000, batch 31/100 -> loss before: 0.3777876206967151, loss after: 0.3678767764612712]
[epoch 401/1000, batch 41/100 -> loss before: 0.23511967802750505, loss after: 0.2351196712034586]
[epoch 401/1000, batch 51/100 -> loss before: 0.32760658730203635, loss after: 0.3274470306214444]
[epoch 401/1000, batch 61/100 -> loss before: 0.2556418171593153, loss after: 0.2529094862353811]
[epoch 401/1000, batch 71/100 -> loss before: 0.26557906766466777, loss after: 0.2655480667888007]
[epoch 401/1000, batch 81/100 -> loss before: 0.1900069551311796, loss after: 0.18969004679758894]
[epoch 401/1000, batch 91/100 -> loss before: 0.19358646881502126, loss after: 0.19348567508967007]
ENDING EPOCH 401/1000 [loss before: 0.2831749579456667, loss after: 0.2831446820101739; epoch time: 0.07292056083679199 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.2848654235175756, loss after: 0.2841351889924856]
[epoch 501/1000, batch 11/100 -> loss before: 0.5791799077307842, loss after: 0.5786933845742117]
[epoch 501/1000, batch 21/100 -> loss before: 0.38004281911598214, loss after: 0.37987478909553196]
[epoch 501/1000, batch 31/100 -> loss before: 0.24522781416534262, loss after: 0.24482504007961808]
[epoch 501/1000, batch 41/100 -> loss before: 0.3152192750751003, loss after: 0.31520059750360824]
[epoch 501/1000, batch 51/100 -> loss before: 0.17737243909863973, loss after: 0.17717861209324987]
[epoch 501/1000, batch 61/100 -> loss before: 0.2896987062698222, loss after: 0.28969791043702037]
[epoch 501/1000, batch 71/100 -> loss before: 0.14747665649769387, loss after: 0.1474764298524685]
[epoch 501/1000, batch 81/100 -> loss before: 0.23989032999087803, loss after: 0.23794549604988954]
[epoch 501/1000, batch 91/100 -> loss before: 0.21383094498902522, loss after: 0.21379470550047763]
ENDING EPOCH 501/1000 [loss before: 0.2830782822812307, loss after: 0.2830931051137161; epoch time: 0.072845458984375 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.34446475186400366, loss after: 0.3442746256568866]
[epoch 601/1000, batch 11/100 -> loss before: 0.3482816250603758, loss after: 0.3472724036144209]
[epoch 601/1000, batch 21/100 -> loss before: 0.29740715981337307, loss after: 0.29721975568821113]
[epoch 601/1000, batch 31/100 -> loss before: 0.13545983255709507, loss after: 0.13490971151312256]
[epoch 601/1000, batch 41/100 -> loss before: 0.36985253889556585, loss after: 0.3663202292051516]
[epoch 601/1000, batch 51/100 -> loss before: 0.28624429615892105, loss after: 0.28480770713972425]
[epoch 601/1000, batch 61/100 -> loss before: 0.13680758416545946, loss after: 0.1367823630463691]
[epoch 601/1000, batch 71/100 -> loss before: 0.2693972204928775, loss after: 0.26575637304323474]
[epoch 601/1000, batch 81/100 -> loss before: 0.3435815641508081, loss after: 0.3394285994358236]
[epoch 601/1000, batch 91/100 -> loss before: 0.3473303951623425, loss after: 0.34732897760948767]
ENDING EPOCH 601/1000 [loss before: 0.28308359807787054, loss after: 0.28319829119169904; epoch time: 0.0772848129272461 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.13938586590326857, loss after: 0.13903345648826157]
[epoch 701/1000, batch 11/100 -> loss before: 0.17006912869342886, loss after: 0.1669513739534823]
[epoch 701/1000, batch 21/100 -> loss before: 0.22969521323166261, loss after: 0.22934122981716926]
[epoch 701/1000, batch 31/100 -> loss before: 0.20663544492529798, loss after: 0.20648106413972483]
[epoch 701/1000, batch 41/100 -> loss before: 0.19736838457506245, loss after: 0.19729236332421857]
[epoch 701/1000, batch 51/100 -> loss before: 0.5456006109688121, loss after: 0.5404192508837858]
[epoch 701/1000, batch 61/100 -> loss before: 0.13634115259295337, loss after: 0.13620175987727712]
[epoch 701/1000, batch 71/100 -> loss before: 0.3679751147738651, loss after: 0.3679450960334286]
[epoch 701/1000, batch 81/100 -> loss before: 0.2837328923788077, loss after: 0.28371415000011646]
[epoch 701/1000, batch 91/100 -> loss before: 0.35356889247311263, loss after: 0.35355996593547656]
ENDING EPOCH 701/1000 [loss before: 0.2830846858347203, loss after: 0.2831161319699118; epoch time: 0.0678706169128418 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.24436666312009075, loss after: 0.23960479559534448]
[epoch 801/1000, batch 11/100 -> loss before: 0.11751060928013117, loss after: 0.11743571699441198]
[epoch 801/1000, batch 21/100 -> loss before: 0.24154640896534083, loss after: 0.24119873915229043]
[epoch 801/1000, batch 31/100 -> loss before: 0.21519889900722838, loss after: 0.21494188673546635]
[epoch 801/1000, batch 41/100 -> loss before: 0.4702539884287539, loss after: 0.469168797379507]
[epoch 801/1000, batch 51/100 -> loss before: 0.2668072307537418, loss after: 0.2664797501926578]
[epoch 801/1000, batch 61/100 -> loss before: 0.27146734607541184, loss after: 0.27049377259546825]
[epoch 801/1000, batch 71/100 -> loss before: 0.3233909171966792, loss after: 0.3230463421561552]
[epoch 801/1000, batch 81/100 -> loss before: 0.29250360019132426, loss after: 0.2914101591894121]
[epoch 801/1000, batch 91/100 -> loss before: 0.24493574845597413, loss after: 0.24467150069457047]
ENDING EPOCH 801/1000 [loss before: 0.28309058607131876, loss after: 0.2830820177107022; epoch time: 0.07466387748718262 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.135873899460406, loss after: 0.13509676309471425]
[epoch 901/1000, batch 11/100 -> loss before: 0.32866018405438246, loss after: 0.3265546808706983]
[epoch 901/1000, batch 21/100 -> loss before: 0.2536824745869407, loss after: 0.2520624514309018]
[epoch 901/1000, batch 31/100 -> loss before: 0.28812174748586045, loss after: 0.2869826529715568]
[epoch 901/1000, batch 41/100 -> loss before: 0.34331371124430743, loss after: 0.341672140682923]
[epoch 901/1000, batch 51/100 -> loss before: 0.24268345001884545, loss after: 0.23846704631726504]
[epoch 901/1000, batch 61/100 -> loss before: 0.4076237105777773, loss after: 0.40762107103328765]
[epoch 901/1000, batch 71/100 -> loss before: 0.17577698562484806, loss after: 0.1747688645210774]
[epoch 901/1000, batch 81/100 -> loss before: 0.39010152206761584, loss after: 0.3893077071793543]
[epoch 901/1000, batch 91/100 -> loss before: 0.21028486786449951, loss after: 0.20988139505829012]
ENDING EPOCH 901/1000 [loss before: 0.2830988015802787, loss after: 0.2832887798172794; epoch time: 0.07153058052062988 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.25777176337867436, loss after: 0.25675771132198016]
[epoch 1000/1000, batch 11/100 -> loss before: 0.23146403796932774, loss after: 0.23118213015340056]
[epoch 1000/1000, batch 21/100 -> loss before: 0.31475054119344564, loss after: 0.3136135428619755]
[epoch 1000/1000, batch 31/100 -> loss before: 0.23635107093407867, loss after: 0.23627254735638528]
[epoch 1000/1000, batch 41/100 -> loss before: 0.296614222861368, loss after: 0.2939168801960647]
[epoch 1000/1000, batch 51/100 -> loss before: 0.29974089332106046, loss after: 0.29816916904507446]
[epoch 1000/1000, batch 61/100 -> loss before: 0.2114635128881764, loss after: 0.21051466773886068]
[epoch 1000/1000, batch 71/100 -> loss before: 0.34874119268124637, loss after: 0.3485670287833768]
[epoch 1000/1000, batch 81/100 -> loss before: 0.10211237585412924, loss after: 0.10211199064528338]
[epoch 1000/1000, batch 91/100 -> loss before: 0.3561913082944543, loss after: 0.35535387791198014]
ENDING EPOCH 1000/1000 [loss before: 0.28312566551960605, loss after: 0.28308828909773137; epoch time: 0.06922483444213867 s]
FIT DONE. [time: 67.76002264022827 s]
LOSS TRAIN (MSE): 0.28308828909773137
LOSS TEST (MSE): 0.2776194997003586
R^2 TRAIN: -3.573540682100251e-05
R^2 TEST: -0.0003211717331461639
EXPERIMENT DONE

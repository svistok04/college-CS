EXPERIMENT 1143 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[64, 64, 64, 64, 64, 32, 32, 32, 32, 32, 16, 16, 16, 16, 16, 8, 8, 8, 8, 8], activation_name=sigmoid, targets_activation_name=linear, 
initialization_name=uniform, algo_name=adam, learning_rate=0.01, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 25185]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 0.6815884323265685, loss after: 0.5897375500533114]
[epoch 1/1000, batch 11/100 -> loss before: 0.38667724917569957, loss after: 0.40569196413318886]
[epoch 1/1000, batch 21/100 -> loss before: 0.35590433320020387, loss after: 0.35493558890212806]
[epoch 1/1000, batch 31/100 -> loss before: 0.3706986755319477, loss after: 0.3711123757397961]
[epoch 1/1000, batch 41/100 -> loss before: 0.20892223849692987, loss after: 0.20734102165284338]
[epoch 1/1000, batch 51/100 -> loss before: 0.2600315492905202, loss after: 0.2615854438028277]
[epoch 1/1000, batch 61/100 -> loss before: 0.46809305407382984, loss after: 0.4684456362516056]
[epoch 1/1000, batch 71/100 -> loss before: 0.34191535478639634, loss after: 0.34125426361713607]
[epoch 1/1000, batch 81/100 -> loss before: 0.40603109024315254, loss after: 0.4055684111736668]
[epoch 1/1000, batch 91/100 -> loss before: 0.2920258978402648, loss after: 0.2920083273924482]
ENDING EPOCH 1/1000 [loss before: 0.599648552700766, loss after: 0.2861881983177128; epoch time: 0.16333413124084473 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.285008450665521, loss after: 0.28534019553935547]
[epoch 101/1000, batch 11/100 -> loss before: 0.2200104834418204, loss after: 0.21993632178274597]
[epoch 101/1000, batch 21/100 -> loss before: 0.24597194456025365, loss after: 0.24556852440626878]
[epoch 101/1000, batch 31/100 -> loss before: 0.3880240670411731, loss after: 0.388165775538568]
[epoch 101/1000, batch 41/100 -> loss before: 0.656810472116698, loss after: 0.6552901732991795]
[epoch 101/1000, batch 51/100 -> loss before: 0.260220833979925, loss after: 0.25858800881663474]
[epoch 101/1000, batch 61/100 -> loss before: 0.5178736671596127, loss after: 0.5177232154385419]
[epoch 101/1000, batch 71/100 -> loss before: 0.14634983357971598, loss after: 0.14606988561978748]
[epoch 101/1000, batch 81/100 -> loss before: 0.2650641106392314, loss after: 0.26489008596204483]
[epoch 101/1000, batch 91/100 -> loss before: 0.24510223197447586, loss after: 0.244284143133553]
ENDING EPOCH 101/1000 [loss before: 0.28326628575604973, loss after: 0.28307875569107716; epoch time: 0.16432952880859375 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.08806542121181794, loss after: 0.08806586437911573]
[epoch 201/1000, batch 11/100 -> loss before: 0.356895410227399, loss after: 0.35656129257094893]
[epoch 201/1000, batch 21/100 -> loss before: 0.18344335081529825, loss after: 0.1822666812395181]
[epoch 201/1000, batch 31/100 -> loss before: 0.4661210918645501, loss after: 0.465843304905491]
[epoch 201/1000, batch 41/100 -> loss before: 0.31404855802248494, loss after: 0.3149147848739423]
[epoch 201/1000, batch 51/100 -> loss before: 0.2858600445751736, loss after: 0.28584046045980205]
[epoch 201/1000, batch 61/100 -> loss before: 0.4864164275584755, loss after: 0.48674540724299825]
[epoch 201/1000, batch 71/100 -> loss before: 0.41235869227580546, loss after: 0.41195976140077606]
[epoch 201/1000, batch 81/100 -> loss before: 0.200603741087722, loss after: 0.2003253263738019]
[epoch 201/1000, batch 91/100 -> loss before: 0.10909877211451294, loss after: 0.1090811178875866]
ENDING EPOCH 201/1000 [loss before: 0.2831209948325285, loss after: 0.2831406733057152; epoch time: 0.16324281692504883 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.18901321456509007, loss after: 0.18910075611224117]
[epoch 301/1000, batch 11/100 -> loss before: 0.19987126224428936, loss after: 0.19987542660486188]
[epoch 301/1000, batch 21/100 -> loss before: 0.3104711443068794, loss after: 0.3103285540788659]
[epoch 301/1000, batch 31/100 -> loss before: 0.32256890889476103, loss after: 0.32283060482285963]
[epoch 301/1000, batch 41/100 -> loss before: 0.2614776413738823, loss after: 0.2607731487920143]
[epoch 301/1000, batch 51/100 -> loss before: 0.2831612272880984, loss after: 0.2830778116181526]
[epoch 301/1000, batch 61/100 -> loss before: 0.31496417105662544, loss after: 0.3142950779879154]
[epoch 301/1000, batch 71/100 -> loss before: 0.3084093083538089, loss after: 0.30835426505706864]
[epoch 301/1000, batch 81/100 -> loss before: 0.3226438853847699, loss after: 0.3227041796482126]
[epoch 301/1000, batch 91/100 -> loss before: 0.3204882853863905, loss after: 0.31964152042756244]
ENDING EPOCH 301/1000 [loss before: 0.28309351382800213, loss after: 0.28308655022817825; epoch time: 0.16300439834594727 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.2841257595496772, loss after: 0.28443652042027456]
[epoch 401/1000, batch 11/100 -> loss before: 0.27426379336444484, loss after: 0.2742300463898663]
[epoch 401/1000, batch 21/100 -> loss before: 0.33137506281497114, loss after: 0.3305722294294819]
[epoch 401/1000, batch 31/100 -> loss before: 0.3702800193352894, loss after: 0.370098473822556]
[epoch 401/1000, batch 41/100 -> loss before: 0.23512185397499136, loss after: 0.23512354982234468]
[epoch 401/1000, batch 51/100 -> loss before: 0.3250712616297634, loss after: 0.32499882800993574]
[epoch 401/1000, batch 61/100 -> loss before: 0.24061198938725264, loss after: 0.24144469363183574]
[epoch 401/1000, batch 71/100 -> loss before: 0.2650720453597365, loss after: 0.26521409434021725]
[epoch 401/1000, batch 81/100 -> loss before: 0.19403995374480168, loss after: 0.19462704214237153]
[epoch 401/1000, batch 91/100 -> loss before: 0.1982931596413467, loss after: 0.19804662007758775]
ENDING EPOCH 401/1000 [loss before: 0.283082588069015, loss after: 0.2841773368197701; epoch time: 0.16086363792419434 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.2864752415784434, loss after: 0.285952232734345]
[epoch 501/1000, batch 11/100 -> loss before: 0.5795984177881076, loss after: 0.5791441484097773]
[epoch 501/1000, batch 21/100 -> loss before: 0.3788693224017433, loss after: 0.37889571955718415]
[epoch 501/1000, batch 31/100 -> loss before: 0.24494416591274498, loss after: 0.2448829736292978]
[epoch 501/1000, batch 41/100 -> loss before: 0.3150229773021189, loss after: 0.31504342817175834]
[epoch 501/1000, batch 51/100 -> loss before: 0.1769586186144871, loss after: 0.1769384145766864]
[epoch 501/1000, batch 61/100 -> loss before: 0.2897508571116797, loss after: 0.28973875714203035]
[epoch 501/1000, batch 71/100 -> loss before: 0.14747263624943652, loss after: 0.1474810832081312]
[epoch 501/1000, batch 81/100 -> loss before: 0.24428888988933095, loss after: 0.2438115765129684]
[epoch 501/1000, batch 91/100 -> loss before: 0.21335530916853424, loss after: 0.21340214112766304]
ENDING EPOCH 501/1000 [loss before: 0.2831157951784931, loss after: 0.2831256663590118; epoch time: 0.18809032440185547 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.3434330028290963, loss after: 0.3437983091953188]
[epoch 601/1000, batch 11/100 -> loss before: 0.3527811738022209, loss after: 0.35373572398741465]
[epoch 601/1000, batch 21/100 -> loss before: 0.30315356102448104, loss after: 0.3028790364267511]
[epoch 601/1000, batch 31/100 -> loss before: 0.13154514211556778, loss after: 0.13232105350656884]
[epoch 601/1000, batch 41/100 -> loss before: 0.37606863879018454, loss after: 0.3738901113788881]
[epoch 601/1000, batch 51/100 -> loss before: 0.2872176607246354, loss after: 0.2871742075802429]
[epoch 601/1000, batch 61/100 -> loss before: 0.13686241389975434, loss after: 0.13675628918309857]
[epoch 601/1000, batch 71/100 -> loss before: 0.273753788978269, loss after: 0.2717856208136443]
[epoch 601/1000, batch 81/100 -> loss before: 0.34353944281058696, loss after: 0.3425517321499726]
[epoch 601/1000, batch 91/100 -> loss before: 0.3472955307002684, loss after: 0.3473049005627364]
ENDING EPOCH 601/1000 [loss before: 0.2831091505123112, loss after: 0.2835903064577884; epoch time: 0.1700897216796875 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.13801944561232135, loss after: 0.13805182657593665]
[epoch 701/1000, batch 11/100 -> loss before: 0.17676877833199883, loss after: 0.17343206762980096]
[epoch 701/1000, batch 21/100 -> loss before: 0.22653324472988232, loss after: 0.22615152317423837]
[epoch 701/1000, batch 31/100 -> loss before: 0.2037806094166251, loss after: 0.2038001145180476]
[epoch 701/1000, batch 41/100 -> loss before: 0.1991178764898039, loss after: 0.19847716961456013]
[epoch 701/1000, batch 51/100 -> loss before: 0.5355676175512935, loss after: 0.5346194589619714]
[epoch 701/1000, batch 61/100 -> loss before: 0.13841074738004497, loss after: 0.13844122173772108]
[epoch 701/1000, batch 71/100 -> loss before: 0.3683864196064893, loss after: 0.36838703878797935]
[epoch 701/1000, batch 81/100 -> loss before: 0.2834574237019963, loss after: 0.28339190487398136]
[epoch 701/1000, batch 91/100 -> loss before: 0.3533560834906684, loss after: 0.35335498698669454]
ENDING EPOCH 701/1000 [loss before: 0.2831801015977792, loss after: 0.28345720261411406; epoch time: 0.16877388954162598 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.25010422142587474, loss after: 0.24820391723094487]
[epoch 801/1000, batch 11/100 -> loss before: 0.11740644330426828, loss after: 0.11742961286119882]
[epoch 801/1000, batch 21/100 -> loss before: 0.2403005700999231, loss after: 0.23994496111445263]
[epoch 801/1000, batch 31/100 -> loss before: 0.21387732885021254, loss after: 0.2138128086012109]
[epoch 801/1000, batch 41/100 -> loss before: 0.4674535891453355, loss after: 0.4682401380865109]
[epoch 801/1000, batch 51/100 -> loss before: 0.2660394802105344, loss after: 0.2658611246044498]
[epoch 801/1000, batch 61/100 -> loss before: 0.2691380157848084, loss after: 0.26862583404447926]
[epoch 801/1000, batch 71/100 -> loss before: 0.3211115898667988, loss after: 0.3212466873816172]
[epoch 801/1000, batch 81/100 -> loss before: 0.29014031947720775, loss after: 0.29033691315269117]
[epoch 801/1000, batch 91/100 -> loss before: 0.2459609802380502, loss after: 0.24575139961606415]
ENDING EPOCH 801/1000 [loss before: 0.283099826181001, loss after: 0.2830784922235233; epoch time: 0.16858386993408203 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.1349855167353538, loss after: 0.13449035492011524]
[epoch 901/1000, batch 11/100 -> loss before: 0.33618888272235037, loss after: 0.3358994909878594]
[epoch 901/1000, batch 21/100 -> loss before: 0.24915496464562956, loss after: 0.2486245581245496]
[epoch 901/1000, batch 31/100 -> loss before: 0.2836140618285316, loss after: 0.2829945258034493]
[epoch 901/1000, batch 41/100 -> loss before: 0.33677083231106486, loss after: 0.33670320383528834]
[epoch 901/1000, batch 51/100 -> loss before: 0.23547848069804805, loss after: 0.23617117389680606]
[epoch 901/1000, batch 61/100 -> loss before: 0.40774506851454406, loss after: 0.4078488424574472]
[epoch 901/1000, batch 71/100 -> loss before: 0.18537458854754196, loss after: 0.18425631756264776]
[epoch 901/1000, batch 81/100 -> loss before: 0.39085133786006787, loss after: 0.39028482759954114]
[epoch 901/1000, batch 91/100 -> loss before: 0.21100773548605614, loss after: 0.21046540165775585]
ENDING EPOCH 901/1000 [loss before: 0.28313822594477606, loss after: 0.2834164147712773; epoch time: 0.16488075256347656 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.25659732792734385, loss after: 0.2570489384897407]
[epoch 1000/1000, batch 11/100 -> loss before: 0.23046672907728824, loss after: 0.2302901422876326]
[epoch 1000/1000, batch 21/100 -> loss before: 0.3175774509123665, loss after: 0.31773218223141264]
[epoch 1000/1000, batch 31/100 -> loss before: 0.2350828856206046, loss after: 0.2352083779001898]
[epoch 1000/1000, batch 41/100 -> loss before: 0.29502586139893344, loss after: 0.2944881810771712]
[epoch 1000/1000, batch 51/100 -> loss before: 0.3002726878633817, loss after: 0.3003729846007209]
[epoch 1000/1000, batch 61/100 -> loss before: 0.2077873731794802, loss after: 0.20805631619918047]
[epoch 1000/1000, batch 71/100 -> loss before: 0.3491653766880503, loss after: 0.3489643503010369]
[epoch 1000/1000, batch 81/100 -> loss before: 0.10218074511307107, loss after: 0.10214567373237715]
[epoch 1000/1000, batch 91/100 -> loss before: 0.35137321340795746, loss after: 0.35095525863891497]
ENDING EPOCH 1000/1000 [loss before: 0.28308827806790954, loss after: 0.2836531206558723; epoch time: 0.1654965877532959 s]
FIT DONE. [time: 156.53867745399475 s]
LOSS TRAIN (MSE): 0.2836531206558723
LOSS TEST (MSE): 0.277659332189185
R^2 TRAIN: -0.0020310554690767813
R^2 TEST: -0.00046469652855440913
EXPERIMENT DONE

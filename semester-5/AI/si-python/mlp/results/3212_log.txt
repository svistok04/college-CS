EXPERIMENT 3212 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 128, 64, 64, 32, 32], activation_name=relu, targets_activation_name=linear, 
initialization_name=uniform, algo_name=sgd_simple, learning_rate=0.0001, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 32481]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 0.87553713426397, loss after: 0.8757682416145176]
[epoch 1/1000, batch 11/100 -> loss before: 0.5150209937641084, loss after: 0.19953893443845472]
[epoch 1/1000, batch 21/100 -> loss before: 0.27546923983289595, loss after: 0.22023719859849167]
[epoch 1/1000, batch 31/100 -> loss before: 0.35926280384087017, loss after: 0.24502826547957174]
[epoch 1/1000, batch 41/100 -> loss before: 0.39732298821298906, loss after: 0.2698870156083655]
[epoch 1/1000, batch 51/100 -> loss before: 0.14547911473583072, loss after: 0.08630221224736676]
[epoch 1/1000, batch 61/100 -> loss before: 0.19833057279177607, loss after: 0.13818669551175772]
[epoch 1/1000, batch 71/100 -> loss before: 0.6265335590167973, loss after: 0.392647280952694]
[epoch 1/1000, batch 81/100 -> loss before: 0.3622192717163747, loss after: 0.3477393340918994]
[epoch 1/1000, batch 91/100 -> loss before: 0.28492104045792, loss after: 0.25001589007044245]
ENDING EPOCH 1/1000 [loss before: 1.102092538201909, loss after: 0.3205185481795642; epoch time: 0.041571855545043945 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.21314014422091293, loss after: 0.1959036249390479]
[epoch 101/1000, batch 11/100 -> loss before: 0.25292881229864805, loss after: 0.23420478209128529]
[epoch 101/1000, batch 21/100 -> loss before: 0.1638289617302118, loss after: 0.14852690158335943]
[epoch 101/1000, batch 31/100 -> loss before: 0.10560715236116439, loss after: 0.09090121196956945]
[epoch 101/1000, batch 41/100 -> loss before: 0.15562000762708988, loss after: 0.12256068326261953]
[epoch 101/1000, batch 51/100 -> loss before: 0.08326779540913343, loss after: 0.07783159994116433]
[epoch 101/1000, batch 61/100 -> loss before: 0.10403628750683513, loss after: 0.10016342102799695]
[epoch 101/1000, batch 71/100 -> loss before: 0.2991777866921267, loss after: 0.28398688033125663]
[epoch 101/1000, batch 81/100 -> loss before: 0.24313889510554437, loss after: 0.19950656735546113]
[epoch 101/1000, batch 91/100 -> loss before: 0.2505483730687911, loss after: 0.22478915534367175]
ENDING EPOCH 101/1000 [loss before: 0.19081204671276827, loss after: 0.1926585901488111; epoch time: 0.047324419021606445 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.42513384569456647, loss after: 0.4138953470698198]
[epoch 201/1000, batch 11/100 -> loss before: 0.3440984601318728, loss after: 0.3075652002794774]
[epoch 201/1000, batch 21/100 -> loss before: 0.2579688375260209, loss after: 0.19325658660219047]
[epoch 201/1000, batch 31/100 -> loss before: 0.14804017283881446, loss after: 0.12253052536826001]
[epoch 201/1000, batch 41/100 -> loss before: 0.15003036954949436, loss after: 0.06918181487408635]
[epoch 201/1000, batch 51/100 -> loss before: 0.3318427549582915, loss after: 0.3036605449085291]
[epoch 201/1000, batch 61/100 -> loss before: 0.16548591757704945, loss after: 0.15718579117307935]
[epoch 201/1000, batch 71/100 -> loss before: 0.08880177794217932, loss after: 0.0789032340993786]
[epoch 201/1000, batch 81/100 -> loss before: 0.34084042097702155, loss after: 0.28228123885169687]
[epoch 201/1000, batch 91/100 -> loss before: 0.17584409600356585, loss after: 0.16809086236706672]
ENDING EPOCH 201/1000 [loss before: 0.18097097259437855, loss after: 0.18387610457197912; epoch time: 0.0465085506439209 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.060752748392611834, loss after: 0.057613078543432304]
[epoch 301/1000, batch 11/100 -> loss before: 0.05129510822327762, loss after: 0.0349719731823596]
[epoch 301/1000, batch 21/100 -> loss before: 0.10597611283636352, loss after: 0.07242702360343244]
[epoch 301/1000, batch 31/100 -> loss before: 0.15089387811604232, loss after: 0.12814001745657727]
[epoch 301/1000, batch 41/100 -> loss before: 0.26016135604219764, loss after: 0.2510265435678054]
[epoch 301/1000, batch 51/100 -> loss before: 0.17562400677724907, loss after: 0.1545386837137556]
[epoch 301/1000, batch 61/100 -> loss before: 0.17612738003550038, loss after: 0.15904078743820696]
[epoch 301/1000, batch 71/100 -> loss before: 0.06941262026641211, loss after: 0.06335599785766324]
[epoch 301/1000, batch 81/100 -> loss before: 0.05080219108924026, loss after: 0.035296158309308864]
[epoch 301/1000, batch 91/100 -> loss before: 0.13889142759249803, loss after: 0.11775470965953445]
ENDING EPOCH 301/1000 [loss before: 0.17637068117275095, loss after: 0.17555133315306892; epoch time: 0.04064798355102539 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.33160680178722823, loss after: 0.31617825773989966]
[epoch 401/1000, batch 11/100 -> loss before: 0.2119270216021883, loss after: 0.19041534219796902]
[epoch 401/1000, batch 21/100 -> loss before: 0.06093119147783619, loss after: 0.05752392614907983]
[epoch 401/1000, batch 31/100 -> loss before: 0.09677461589095795, loss after: 0.08573187041727001]
[epoch 401/1000, batch 41/100 -> loss before: 0.19225706774393952, loss after: 0.1445748868715336]
[epoch 401/1000, batch 51/100 -> loss before: 0.23978519878752577, loss after: 0.17797336850071677]
[epoch 401/1000, batch 61/100 -> loss before: 0.11003813188532793, loss after: 0.10269673200716858]
[epoch 401/1000, batch 71/100 -> loss before: 0.1788158959600831, loss after: 0.13506529580969592]
[epoch 401/1000, batch 81/100 -> loss before: 0.3825429509438344, loss after: 0.3339394295772551]
[epoch 401/1000, batch 91/100 -> loss before: 0.12231720396999031, loss after: 0.10489995652351584]
ENDING EPOCH 401/1000 [loss before: 0.16216162860738276, loss after: 0.17063189902229034; epoch time: 0.04147219657897949 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.062118649037805375, loss after: 0.05602071232851089]
[epoch 501/1000, batch 11/100 -> loss before: 0.16746934849331316, loss after: 0.141901608085604]
[epoch 501/1000, batch 21/100 -> loss before: 0.23965802349068716, loss after: 0.22953096699829872]
[epoch 501/1000, batch 31/100 -> loss before: 0.08873071086036202, loss after: 0.06086486747314833]
[epoch 501/1000, batch 41/100 -> loss before: 0.1059301787687283, loss after: 0.07958862446826548]
[epoch 501/1000, batch 51/100 -> loss before: 0.24826064168380188, loss after: 0.1800556252716619]
[epoch 501/1000, batch 61/100 -> loss before: 0.16137933637290652, loss after: 0.1344342923292079]
[epoch 501/1000, batch 71/100 -> loss before: 0.0703788667400419, loss after: 0.05091114111793969]
[epoch 501/1000, batch 81/100 -> loss before: 0.3363979175510779, loss after: 0.30661763423320376]
[epoch 501/1000, batch 91/100 -> loss before: 0.21474918108787627, loss after: 0.13243058592954]
ENDING EPOCH 501/1000 [loss before: 0.15608960628978572, loss after: 0.1612964682301126; epoch time: 0.04047894477844238 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.06305766133578115, loss after: 0.05635129356669912]
[epoch 601/1000, batch 11/100 -> loss before: 0.1523064864350594, loss after: 0.06312647107590069]
[epoch 601/1000, batch 21/100 -> loss before: 0.2241243695382229, loss after: 0.14989098379901838]
[epoch 601/1000, batch 31/100 -> loss before: 0.08532751507264977, loss after: 0.0728393847006139]
[epoch 601/1000, batch 41/100 -> loss before: 0.18022851134582618, loss after: 0.14802032473897273]
[epoch 601/1000, batch 51/100 -> loss before: 0.18979955182508731, loss after: 0.1526197693692816]
[epoch 601/1000, batch 61/100 -> loss before: 0.16773205148923725, loss after: 0.1257656254712727]
[epoch 601/1000, batch 71/100 -> loss before: 0.19734567045975374, loss after: 0.15885446068798492]
[epoch 601/1000, batch 81/100 -> loss before: 0.18744912138572226, loss after: 0.13775675681835448]
[epoch 601/1000, batch 91/100 -> loss before: 0.31282356199502614, loss after: 0.2618148379830393]
ENDING EPOCH 601/1000 [loss before: 0.1418048683484896, loss after: 0.14199072531322626; epoch time: 0.0449213981628418 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.22988265118590454, loss after: 0.17694216039070995]
[epoch 701/1000, batch 11/100 -> loss before: 0.10158317103250089, loss after: 0.05875832796407461]
[epoch 701/1000, batch 21/100 -> loss before: 0.14040201341442624, loss after: 0.09337479143511054]
[epoch 701/1000, batch 31/100 -> loss before: 0.1903903329683126, loss after: 0.18252034404592377]
[epoch 701/1000, batch 41/100 -> loss before: 0.030596213791696962, loss after: 0.022042548304461236]
[epoch 701/1000, batch 51/100 -> loss before: 0.10652652773897717, loss after: 0.08359735664674192]
[epoch 701/1000, batch 61/100 -> loss before: 0.06868406518523631, loss after: 0.05514672331488631]
[epoch 701/1000, batch 71/100 -> loss before: 0.051050675898822076, loss after: 0.04089499982590804]
[epoch 701/1000, batch 81/100 -> loss before: 0.07558710165185069, loss after: 0.05951765297970076]
[epoch 701/1000, batch 91/100 -> loss before: 0.11034217148574883, loss after: 0.08999454097880015]
ENDING EPOCH 701/1000 [loss before: 0.17332156811544622, loss after: 0.12375238116763146; epoch time: 0.039325714111328125 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.045747809739454505, loss after: 0.0074890709307774]
[epoch 801/1000, batch 11/100 -> loss before: 0.06573776170176501, loss after: 0.05104462230840341]
[epoch 801/1000, batch 21/100 -> loss before: 0.09282593204629999, loss after: 0.06746097442961134]
[epoch 801/1000, batch 31/100 -> loss before: 0.04249312697919098, loss after: 0.03291530113004904]
[epoch 801/1000, batch 41/100 -> loss before: 0.22173843912407717, loss after: 0.18625180299705935]
[epoch 801/1000, batch 51/100 -> loss before: 0.18009826528445633, loss after: 0.12724201272725388]
[epoch 801/1000, batch 61/100 -> loss before: 0.13580058925202215, loss after: 0.0834389589681128]
[epoch 801/1000, batch 71/100 -> loss before: 0.19784743851663952, loss after: 0.15222065098225174]
[epoch 801/1000, batch 81/100 -> loss before: 0.07974473987337856, loss after: 0.04507857404902245]
[epoch 801/1000, batch 91/100 -> loss before: 0.17546669343647375, loss after: 0.09960313061187523]
ENDING EPOCH 801/1000 [loss before: 0.13547055600982344, loss after: 0.12230577253502728; epoch time: 0.04376697540283203 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.07919659132627029, loss after: 0.0560375987164629]
[epoch 901/1000, batch 11/100 -> loss before: 0.08947282993925135, loss after: 0.08078865100261202]
[epoch 901/1000, batch 21/100 -> loss before: 0.07212983795992509, loss after: 0.052279426182014]
[epoch 901/1000, batch 31/100 -> loss before: 0.07101238215720405, loss after: 0.05527813847479592]
[epoch 901/1000, batch 41/100 -> loss before: 0.16322298335883775, loss after: 0.07519499606986231]
[epoch 901/1000, batch 51/100 -> loss before: 0.19483568486582561, loss after: 0.10117694471307799]
[epoch 901/1000, batch 61/100 -> loss before: 0.17741035786234058, loss after: 0.1449172119634503]
[epoch 901/1000, batch 71/100 -> loss before: 0.09285844779204382, loss after: 0.053502619543155286]
[epoch 901/1000, batch 81/100 -> loss before: 0.10850912835838322, loss after: 0.0854501440231753]
[epoch 901/1000, batch 91/100 -> loss before: 0.1989324134315434, loss after: 0.14916311978749383]
ENDING EPOCH 901/1000 [loss before: 0.11529271784671258, loss after: 0.12339033003875949; epoch time: 0.04037666320800781 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.15923276426903654, loss after: 0.11475004639287442]
[epoch 1000/1000, batch 11/100 -> loss before: 0.09376860019667063, loss after: 0.06533819680897743]
[epoch 1000/1000, batch 21/100 -> loss before: 0.05733625880732979, loss after: 0.04722849174276471]
[epoch 1000/1000, batch 31/100 -> loss before: 0.11844471482612633, loss after: 0.10049908859175209]
[epoch 1000/1000, batch 41/100 -> loss before: 0.09550926757581472, loss after: 0.06341977665253974]
[epoch 1000/1000, batch 51/100 -> loss before: 0.11327179442904685, loss after: 0.0914906860975949]
[epoch 1000/1000, batch 61/100 -> loss before: 0.06671031106856287, loss after: 0.05498615716388546]
[epoch 1000/1000, batch 71/100 -> loss before: 0.08061043580416076, loss after: 0.06178546214857169]
[epoch 1000/1000, batch 81/100 -> loss before: 0.13568159344995434, loss after: 0.11058137553629885]
[epoch 1000/1000, batch 91/100 -> loss before: 0.20793500191760353, loss after: 0.15157913406240414]
ENDING EPOCH 1000/1000 [loss before: 0.11373807326460596, loss after: 0.09271264115433124; epoch time: 0.04220414161682129 s]
FIT DONE. [time: 40.108216285705566 s]
LOSS TRAIN (MSE): 0.09271264115433124
LOSS TEST (MSE): 0.09793965736514479
R^2 TRAIN: 0.6724839640177707
R^2 TEST: 0.6471029127262781
EXPERIMENT DONE

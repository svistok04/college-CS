EXPERIMENT 1231 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 64, 32], activation_name=relu, targets_activation_name=linear, 
initialization_name=uniform, algo_name=rmsprop, learning_rate=0.01, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 10753]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 20.679362556386955, loss after: 44.37577675055836]
[epoch 1/1000, batch 11/100 -> loss before: 0.2590632998131451, loss after: 0.19387588605990283]
[epoch 1/1000, batch 21/100 -> loss before: 0.09299746731668937, loss after: 0.08235757825794217]
[epoch 1/1000, batch 31/100 -> loss before: 0.6583604937659951, loss after: 0.5855722589386674]
[epoch 1/1000, batch 41/100 -> loss before: 0.21195842964721906, loss after: 0.1738382731789325]
[epoch 1/1000, batch 51/100 -> loss before: 0.18915234256349228, loss after: 0.1787142801504904]
[epoch 1/1000, batch 61/100 -> loss before: 0.6093980497767639, loss after: 0.4143257841468159]
[epoch 1/1000, batch 71/100 -> loss before: 0.3696558406363538, loss after: 0.2711073285894626]
[epoch 1/1000, batch 81/100 -> loss before: 0.15395742113458938, loss after: 0.15289603319523132]
[epoch 1/1000, batch 91/100 -> loss before: 0.417261524766384, loss after: 0.41013387592933076]
ENDING EPOCH 1/1000 [loss before: 18.773492598911375, loss after: 0.28439353525587685; epoch time: 0.03275465965270996 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.37764662297559337, loss after: 0.37455050024911335]
[epoch 101/1000, batch 11/100 -> loss before: 0.15143840057950245, loss after: 0.1513380428864323]
[epoch 101/1000, batch 21/100 -> loss before: 0.10132033169030788, loss after: 0.09996598650310924]
[epoch 101/1000, batch 31/100 -> loss before: 0.18833687008254124, loss after: 0.18815137612551944]
[epoch 101/1000, batch 41/100 -> loss before: 0.5307451930624744, loss after: 0.5295287698587323]
[epoch 101/1000, batch 51/100 -> loss before: 0.19768751733658638, loss after: 0.19561264709154697]
[epoch 101/1000, batch 61/100 -> loss before: 0.22906814493452238, loss after: 0.22540869197314314]
[epoch 101/1000, batch 71/100 -> loss before: 0.25052868201822937, loss after: 0.25021868249804746]
[epoch 101/1000, batch 81/100 -> loss before: 0.2940626836014692, loss after: 0.2910694799912598]
[epoch 101/1000, batch 91/100 -> loss before: 0.34297817213688686, loss after: 0.3429555802988633]
ENDING EPOCH 101/1000 [loss before: 0.28319453797256494, loss after: 0.2833243068095319; epoch time: 0.032022714614868164 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.1707003320648073, loss after: 0.16895051078417425]
[epoch 201/1000, batch 11/100 -> loss before: 0.24927483180696686, loss after: 0.24222904239989318]
[epoch 201/1000, batch 21/100 -> loss before: 0.1938555078500775, loss after: 0.19155760405020128]
[epoch 201/1000, batch 31/100 -> loss before: 0.21403839315588408, loss after: 0.2138134352384624]
[epoch 201/1000, batch 41/100 -> loss before: 0.386652015888295, loss after: 0.38497318144317105]
[epoch 201/1000, batch 51/100 -> loss before: 0.4468388471491441, loss after: 0.44636102217925433]
[epoch 201/1000, batch 61/100 -> loss before: 0.3842716493999444, loss after: 0.38232270405627145]
[epoch 201/1000, batch 71/100 -> loss before: 0.1489922902960023, loss after: 0.14318990651390767]
[epoch 201/1000, batch 81/100 -> loss before: 0.23807731275924446, loss after: 0.237709545332706]
[epoch 201/1000, batch 91/100 -> loss before: 0.12938653394090469, loss after: 0.12926790967592128]
ENDING EPOCH 201/1000 [loss before: 0.28308383075882215, loss after: 0.2831729035067537; epoch time: 0.031200885772705078 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.18527396815269925, loss after: 0.18407723805747445]
[epoch 301/1000, batch 11/100 -> loss before: 0.4932867761665312, loss after: 0.4786104108378935]
[epoch 301/1000, batch 21/100 -> loss before: 0.1662096024798878, loss after: 0.15944550857103196]
[epoch 301/1000, batch 31/100 -> loss before: 0.22230347773113984, loss after: 0.2217984309713183]
[epoch 301/1000, batch 41/100 -> loss before: 0.13684586743688246, loss after: 0.13683331166495602]
[epoch 301/1000, batch 51/100 -> loss before: 0.2939443763420734, loss after: 0.2896091936730478]
[epoch 301/1000, batch 61/100 -> loss before: 0.23211030010601003, loss after: 0.23151419190472197]
[epoch 301/1000, batch 71/100 -> loss before: 0.3996164008715378, loss after: 0.3851423667374748]
[epoch 301/1000, batch 81/100 -> loss before: 0.1187695221783717, loss after: 0.11869728167836917]
[epoch 301/1000, batch 91/100 -> loss before: 0.3582698921795253, loss after: 0.34706363095679443]
ENDING EPOCH 301/1000 [loss before: 0.283542641605511, loss after: 0.28309937659064044; epoch time: 0.03331565856933594 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.4382834766236285, loss after: 0.4381154941176487]
[epoch 401/1000, batch 11/100 -> loss before: 0.33202942337617863, loss after: 0.32974858832624665]
[epoch 401/1000, batch 21/100 -> loss before: 0.3396549849615175, loss after: 0.3343371516625912]
[epoch 401/1000, batch 31/100 -> loss before: 0.32866320862210174, loss after: 0.3206117885629488]
[epoch 401/1000, batch 41/100 -> loss before: 0.18201371098137287, loss after: 0.17722280150325778]
[epoch 401/1000, batch 51/100 -> loss before: 0.4418064331443695, loss after: 0.44093941167448636]
[epoch 401/1000, batch 61/100 -> loss before: 0.13733277726839827, loss after: 0.1370121793033568]
[epoch 401/1000, batch 71/100 -> loss before: 0.2620872351111635, loss after: 0.25678202581400533]
[epoch 401/1000, batch 81/100 -> loss before: 0.36501110449266194, loss after: 0.36019821444245614]
[epoch 401/1000, batch 91/100 -> loss before: 0.2388781045214528, loss after: 0.23882728930617336]
ENDING EPOCH 401/1000 [loss before: 0.2847975140680282, loss after: 0.2870752950909076; epoch time: 0.03596377372741699 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.23601886975306502, loss after: 0.22870071519846907]
[epoch 501/1000, batch 11/100 -> loss before: 0.33942290473102815, loss after: 0.33828428779667424]
[epoch 501/1000, batch 21/100 -> loss before: 0.12812448752002842, loss after: 0.12811732192345934]
[epoch 501/1000, batch 31/100 -> loss before: 0.18190608068734687, loss after: 0.18186346174048704]
[epoch 501/1000, batch 41/100 -> loss before: 0.26093207129006835, loss after: 0.2598950374253159]
[epoch 501/1000, batch 51/100 -> loss before: 0.16475961568565586, loss after: 0.15985831237477494]
[epoch 501/1000, batch 61/100 -> loss before: 0.11633457223166783, loss after: 0.11363027112757992]
[epoch 501/1000, batch 71/100 -> loss before: 0.22644393857947231, loss after: 0.22642423569448922]
[epoch 501/1000, batch 81/100 -> loss before: 0.23879114368814994, loss after: 0.23663204236497154]
[epoch 501/1000, batch 91/100 -> loss before: 0.3511731481489698, loss after: 0.34713206714132483]
ENDING EPOCH 501/1000 [loss before: 0.2840964165963438, loss after: 0.28346681718711864; epoch time: 0.036301612854003906 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.3395707724240893, loss after: 0.3369899539125232]
[epoch 601/1000, batch 11/100 -> loss before: 0.18114703304591773, loss after: 0.17934402178154732]
[epoch 601/1000, batch 21/100 -> loss before: 0.520218417189205, loss after: 0.5183462730380244]
[epoch 601/1000, batch 31/100 -> loss before: 0.17609129939567733, loss after: 0.17592776777589209]
[epoch 601/1000, batch 41/100 -> loss before: 0.26045925385989804, loss after: 0.2595409757809688]
[epoch 601/1000, batch 51/100 -> loss before: 0.282050813137087, loss after: 0.27894042445682105]
[epoch 601/1000, batch 61/100 -> loss before: 0.44463074049364665, loss after: 0.4408737654394065]
[epoch 601/1000, batch 71/100 -> loss before: 0.3550147586128435, loss after: 0.3549481800219977]
[epoch 601/1000, batch 81/100 -> loss before: 0.17870875722800444, loss after: 0.1769704608688943]
[epoch 601/1000, batch 91/100 -> loss before: 0.2203445947510508, loss after: 0.2134787005094132]
ENDING EPOCH 601/1000 [loss before: 0.2834353317210795, loss after: 0.28318202082809196; epoch time: 0.032087087631225586 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.32687705066622846, loss after: 0.3239099470435617]
[epoch 701/1000, batch 11/100 -> loss before: 0.28500642507029783, loss after: 0.27602646783614093]
[epoch 701/1000, batch 21/100 -> loss before: 0.2845226208731223, loss after: 0.28325456325853526]
[epoch 701/1000, batch 31/100 -> loss before: 0.2943589301063095, loss after: 0.29129974388669333]
[epoch 701/1000, batch 41/100 -> loss before: 0.23628700174440245, loss after: 0.2337926183850738]
[epoch 701/1000, batch 51/100 -> loss before: 0.3527588823065047, loss after: 0.3525674450238633]
[epoch 701/1000, batch 61/100 -> loss before: 0.10000621406114363, loss after: 0.10000549461341282]
[epoch 701/1000, batch 71/100 -> loss before: 0.2543717416315209, loss after: 0.25404237057556944]
[epoch 701/1000, batch 81/100 -> loss before: 0.3058996920634848, loss after: 0.3010594405689736]
[epoch 701/1000, batch 91/100 -> loss before: 0.3263943044843672, loss after: 0.3263625775757789]
ENDING EPOCH 701/1000 [loss before: 0.2838397404785364, loss after: 0.28369213723018627; epoch time: 0.03597402572631836 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.4025050693506086, loss after: 0.39387968835486015]
[epoch 801/1000, batch 11/100 -> loss before: 0.22784550738115797, loss after: 0.2253462269385198]
[epoch 801/1000, batch 21/100 -> loss before: 0.521996634030985, loss after: 0.5204591076209294]
[epoch 801/1000, batch 31/100 -> loss before: 0.19718203168835563, loss after: 0.1966189108919399]
[epoch 801/1000, batch 41/100 -> loss before: 0.3502025712221536, loss after: 0.3501921422327594]
[epoch 801/1000, batch 51/100 -> loss before: 0.30007843791725597, loss after: 0.3000681588091259]
[epoch 801/1000, batch 61/100 -> loss before: 0.21753716827756037, loss after: 0.21342943983293922]
[epoch 801/1000, batch 71/100 -> loss before: 0.24968263915062744, loss after: 0.23750137182056066]
[epoch 801/1000, batch 81/100 -> loss before: 0.340449318340264, loss after: 0.3384531958047118]
[epoch 801/1000, batch 91/100 -> loss before: 0.1729696481987574, loss after: 0.17159690727243904]
ENDING EPOCH 801/1000 [loss before: 0.28312055930644864, loss after: 0.28308095370522435; epoch time: 0.032892465591430664 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.3640076103799516, loss after: 0.36370885190887614]
[epoch 901/1000, batch 11/100 -> loss before: 0.4364052681592606, loss after: 0.43580004509549397]
[epoch 901/1000, batch 21/100 -> loss before: 0.13474600425917066, loss after: 0.1339680907969843]
[epoch 901/1000, batch 31/100 -> loss before: 0.274663090777875, loss after: 0.27329272879709277]
[epoch 901/1000, batch 41/100 -> loss before: 0.14748076795879073, loss after: 0.14695820517438257]
[epoch 901/1000, batch 51/100 -> loss before: 0.3393847100715638, loss after: 0.3367402804285917]
[epoch 901/1000, batch 61/100 -> loss before: 0.35813529466816546, loss after: 0.3579132973489697]
[epoch 901/1000, batch 71/100 -> loss before: 0.30743775488834735, loss after: 0.3064514361838253]
[epoch 901/1000, batch 81/100 -> loss before: 0.28932917249923806, loss after: 0.28384227874715456]
[epoch 901/1000, batch 91/100 -> loss before: 0.19604077248700252, loss after: 0.19602559455494734]
ENDING EPOCH 901/1000 [loss before: 0.2832099381823788, loss after: 0.2839327682419277; epoch time: 0.03383660316467285 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.17481673718515164, loss after: 0.17407387351998432]
[epoch 1000/1000, batch 11/100 -> loss before: 0.31769656612027863, loss after: 0.3158441619869143]
[epoch 1000/1000, batch 21/100 -> loss before: 0.13815824908043886, loss after: 0.13808175520039664]
[epoch 1000/1000, batch 31/100 -> loss before: 0.26754241199684814, loss after: 0.26414914730620426]
[epoch 1000/1000, batch 41/100 -> loss before: 0.25674379623915633, loss after: 0.25673767798612185]
[epoch 1000/1000, batch 51/100 -> loss before: 0.33492648018483007, loss after: 0.33492303588743877]
[epoch 1000/1000, batch 61/100 -> loss before: 0.22409736105175818, loss after: 0.2192985999807143]
[epoch 1000/1000, batch 71/100 -> loss before: 0.38529605475552436, loss after: 0.38467766177372964]
[epoch 1000/1000, batch 81/100 -> loss before: 0.39485499130536317, loss after: 0.39476503720623485]
[epoch 1000/1000, batch 91/100 -> loss before: 0.35561920127353136, loss after: 0.35427123567425245]
ENDING EPOCH 1000/1000 [loss before: 0.28307821821194623, loss after: 0.2838325270596932; epoch time: 0.03274941444396973 s]
FIT DONE. [time: 32.041468143463135 s]
LOSS TRAIN (MSE): 0.2838325270596932
LOSS TEST (MSE): 0.27913707007450367
R^2 TRAIN: -0.002664825292454376
R^2 TEST: -0.0057892954654155115
EXPERIMENT DONE

EXPERIMENT 3111 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 64, 32], activation_name=sigmoid, targets_activation_name=linear, 
initialization_name=uniform, algo_name=sgd_simple, learning_rate=0.0001, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 10753]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 1.6197437009973044, loss after: 1.5672835831451044]
[epoch 1/1000, batch 11/100 -> loss before: 0.5254411614449952, loss after: 0.513299320524654]
[epoch 1/1000, batch 21/100 -> loss before: 0.21138343182574587, loss after: 0.2064033720248474]
[epoch 1/1000, batch 31/100 -> loss before: 0.5485579185538174, loss after: 0.5449992082717389]
[epoch 1/1000, batch 41/100 -> loss before: 0.27302690987807055, loss after: 0.2692805631107926]
[epoch 1/1000, batch 51/100 -> loss before: 0.7187751335233924, loss after: 0.7019642624500354]
[epoch 1/1000, batch 61/100 -> loss before: 0.49305856383862895, loss after: 0.49293997293833114]
[epoch 1/1000, batch 71/100 -> loss before: 0.4036133356037138, loss after: 0.40326783436113234]
[epoch 1/1000, batch 81/100 -> loss before: 0.18124780398020848, loss after: 0.17987076423840173]
[epoch 1/1000, batch 91/100 -> loss before: 0.3931174446074336, loss after: 0.39309440008422747]
ENDING EPOCH 1/1000 [loss before: 0.7227142221308361, loss after: 0.29489690007440766; epoch time: 0.027138471603393555 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.3658689583141053, loss after: 0.3647818304312024]
[epoch 101/1000, batch 11/100 -> loss before: 0.14500114856018542, loss after: 0.14496282863720705]
[epoch 101/1000, batch 21/100 -> loss before: 0.10144794096454182, loss after: 0.10105155064343249]
[epoch 101/1000, batch 31/100 -> loss before: 0.1869123884103644, loss after: 0.18689188684165595]
[epoch 101/1000, batch 41/100 -> loss before: 0.5273410009031934, loss after: 0.5271147210400441]
[epoch 101/1000, batch 51/100 -> loss before: 0.19610419749932542, loss after: 0.19561340505960276]
[epoch 101/1000, batch 61/100 -> loss before: 0.22958807254847988, loss after: 0.228578202805364]
[epoch 101/1000, batch 71/100 -> loss before: 0.24642871732802263, loss after: 0.24638069283269673]
[epoch 101/1000, batch 81/100 -> loss before: 0.28353814840569985, loss after: 0.28310280548003053]
[epoch 101/1000, batch 91/100 -> loss before: 0.34664298802604787, loss after: 0.34653736983894534]
ENDING EPOCH 101/1000 [loss before: 0.2798455082992081, loss after: 0.279887349707985; epoch time: 0.025327205657958984 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.17153931404411366, loss after: 0.17077466014661002]
[epoch 201/1000, batch 11/100 -> loss before: 0.23704355219820683, loss after: 0.23474473800531875]
[epoch 201/1000, batch 21/100 -> loss before: 0.19191411084547358, loss after: 0.19130248195480917]
[epoch 201/1000, batch 31/100 -> loss before: 0.22083826174138807, loss after: 0.2207587584527996]
[epoch 201/1000, batch 41/100 -> loss before: 0.37110674599710347, loss after: 0.37081679384919813]
[epoch 201/1000, batch 51/100 -> loss before: 0.43800115419094193, loss after: 0.43782987011722163]
[epoch 201/1000, batch 61/100 -> loss before: 0.37831331280345404, loss after: 0.37769785816295975]
[epoch 201/1000, batch 71/100 -> loss before: 0.14698540879848593, loss after: 0.14528754711690967]
[epoch 201/1000, batch 81/100 -> loss before: 0.22322413537600885, loss after: 0.22302687803668358]
[epoch 201/1000, batch 91/100 -> loss before: 0.12818544724019248, loss after: 0.1281824167960779]
ENDING EPOCH 201/1000 [loss before: 0.27793697431781206, loss after: 0.27791323353238906; epoch time: 0.02451920509338379 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.18346441244439002, loss after: 0.1831907440131076]
[epoch 301/1000, batch 11/100 -> loss before: 0.4748602473515409, loss after: 0.46981948608507595]
[epoch 301/1000, batch 21/100 -> loss before: 0.17303807455957818, loss after: 0.1700456185637661]
[epoch 301/1000, batch 31/100 -> loss before: 0.2120180671134971, loss after: 0.21178089262695532]
[epoch 301/1000, batch 41/100 -> loss before: 0.12404711163254833, loss after: 0.12402831939880596]
[epoch 301/1000, batch 51/100 -> loss before: 0.30454205074606877, loss after: 0.3030826374928225]
[epoch 301/1000, batch 61/100 -> loss before: 0.2279556882606028, loss after: 0.22765896117109832]
[epoch 301/1000, batch 71/100 -> loss before: 0.3673977484589173, loss after: 0.3628600576333078]
[epoch 301/1000, batch 81/100 -> loss before: 0.12251460248629006, loss after: 0.12247763227987989]
[epoch 301/1000, batch 91/100 -> loss before: 0.33330873609796424, loss after: 0.33032548323601907]
ENDING EPOCH 301/1000 [loss before: 0.2759156575672431, loss after: 0.2758906696444669; epoch time: 0.024428129196166992 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.4175182509322465, loss after: 0.41751199537589734]
[epoch 401/1000, batch 11/100 -> loss before: 0.33696106446810037, loss after: 0.33633647029631936]
[epoch 401/1000, batch 21/100 -> loss before: 0.3113830288867908, loss after: 0.31037077889920633]
[epoch 401/1000, batch 31/100 -> loss before: 0.3143449708141087, loss after: 0.3116317539966387]
[epoch 401/1000, batch 41/100 -> loss before: 0.16260390517846451, loss after: 0.16154005024647175]
[epoch 401/1000, batch 51/100 -> loss before: 0.4058236004308444, loss after: 0.4056404258427432]
[epoch 401/1000, batch 61/100 -> loss before: 0.14270029302931458, loss after: 0.14264978986135296]
[epoch 401/1000, batch 71/100 -> loss before: 0.2581662081254265, loss after: 0.2564599466877733]
[epoch 401/1000, batch 81/100 -> loss before: 0.36240827253351326, loss after: 0.3611099346058511]
[epoch 401/1000, batch 91/100 -> loss before: 0.2363491442412251, loss after: 0.23632077194648726]
ENDING EPOCH 401/1000 [loss before: 0.27397369089998996, loss after: 0.27400508769398213; epoch time: 0.025202512741088867 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.21969164764269591, loss after: 0.21713105816174325]
[epoch 501/1000, batch 11/100 -> loss before: 0.33201120464877804, loss after: 0.33166111333991655]
[epoch 501/1000, batch 21/100 -> loss before: 0.12722160154232814, loss after: 0.1272074857000015]
[epoch 501/1000, batch 31/100 -> loss before: 0.17617191359927517, loss after: 0.17616854959312175]
[epoch 501/1000, batch 41/100 -> loss before: 0.24086739160769688, loss after: 0.24038858779750777]
[epoch 501/1000, batch 51/100 -> loss before: 0.16293296125898343, loss after: 0.16110708972313664]
[epoch 501/1000, batch 61/100 -> loss before: 0.1500300374106419, loss after: 0.14838816885866465]
[epoch 501/1000, batch 71/100 -> loss before: 0.21736206498917285, loss after: 0.21732363106418257]
[epoch 501/1000, batch 81/100 -> loss before: 0.2329208036531465, loss after: 0.23217043360250714]
[epoch 501/1000, batch 91/100 -> loss before: 0.339514691254458, loss after: 0.3384701327392301]
ENDING EPOCH 501/1000 [loss before: 0.2720075462982966, loss after: 0.27186297513820407; epoch time: 0.02542281150817871 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.30903594123411404, loss after: 0.3084148188562204]
[epoch 601/1000, batch 11/100 -> loss before: 0.1769273476146091, loss after: 0.17649592328178146]
[epoch 601/1000, batch 21/100 -> loss before: 0.5151934005796707, loss after: 0.5145869246098138]
[epoch 601/1000, batch 31/100 -> loss before: 0.20215883140238317, loss after: 0.2020021634561539]
[epoch 601/1000, batch 41/100 -> loss before: 0.2412167325779831, loss after: 0.24071420601386295]
[epoch 601/1000, batch 51/100 -> loss before: 0.2610506009218724, loss after: 0.26009277693771]
[epoch 601/1000, batch 61/100 -> loss before: 0.4178619254757006, loss after: 0.4170515129020688]
[epoch 601/1000, batch 71/100 -> loss before: 0.34199990459168983, loss after: 0.34199641216629856]
[epoch 601/1000, batch 81/100 -> loss before: 0.1394424930391424, loss after: 0.13889327299996254]
[epoch 601/1000, batch 91/100 -> loss before: 0.18883647078466126, loss after: 0.18647277155803307]
ENDING EPOCH 601/1000 [loss before: 0.2702401425312797, loss after: 0.2702605508250199; epoch time: 0.027704715728759766 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.2919989809645671, loss after: 0.29087093977566286]
[epoch 701/1000, batch 11/100 -> loss before: 0.28245054757216714, loss after: 0.2800367134785757]
[epoch 701/1000, batch 21/100 -> loss before: 0.2737990793147148, loss after: 0.27338916592020757]
[epoch 701/1000, batch 31/100 -> loss before: 0.24299059467864015, loss after: 0.24251124409412225]
[epoch 701/1000, batch 41/100 -> loss before: 0.17334279936649996, loss after: 0.1727102114368578]
[epoch 701/1000, batch 51/100 -> loss before: 0.3739871419098788, loss after: 0.37397999125165826]
[epoch 701/1000, batch 61/100 -> loss before: 0.11961814721659385, loss after: 0.11961422589086097]
[epoch 701/1000, batch 71/100 -> loss before: 0.23553004548743214, loss after: 0.23538038855111904]
[epoch 701/1000, batch 81/100 -> loss before: 0.27983892110670844, loss after: 0.2789441171890658]
[epoch 701/1000, batch 91/100 -> loss before: 0.32922094326611395, loss after: 0.3292141525947282]
ENDING EPOCH 701/1000 [loss before: 0.2691359981820391, loss after: 0.26905881874429394; epoch time: 0.03503751754760742 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.4215873078877873, loss after: 0.4164081924132771]
[epoch 801/1000, batch 11/100 -> loss before: 0.2745984672665907, loss after: 0.27367877918393024]
[epoch 801/1000, batch 21/100 -> loss before: 0.4614259560388209, loss after: 0.4606591154154732]
[epoch 801/1000, batch 31/100 -> loss before: 0.19625488124244234, loss after: 0.19588016487391605]
[epoch 801/1000, batch 41/100 -> loss before: 0.3307848538825119, loss after: 0.3307517330839069]
[epoch 801/1000, batch 51/100 -> loss before: 0.2812489604481834, loss after: 0.2812448099930981]
[epoch 801/1000, batch 61/100 -> loss before: 0.22732214366453057, loss after: 0.22639000865321418]
[epoch 801/1000, batch 71/100 -> loss before: 0.2982959162250921, loss after: 0.29193396867722277]
[epoch 801/1000, batch 81/100 -> loss before: 0.3435162994048619, loss after: 0.342771490686072]
[epoch 801/1000, batch 91/100 -> loss before: 0.13947762425271876, loss after: 0.13905849278579657]
ENDING EPOCH 801/1000 [loss before: 0.26838190558057895, loss after: 0.2683091756244635; epoch time: 0.026853084564208984 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.33710962581107023, loss after: 0.33683390517950573]
[epoch 901/1000, batch 11/100 -> loss before: 0.4446997864213464, loss after: 0.4442388662863954]
[epoch 901/1000, batch 21/100 -> loss before: 0.1963052008761507, loss after: 0.19579346975934503]
[epoch 901/1000, batch 31/100 -> loss before: 0.2605515629692926, loss after: 0.2601159498949883]
[epoch 901/1000, batch 41/100 -> loss before: 0.09730751769478761, loss after: 0.09724424206496868]
[epoch 901/1000, batch 51/100 -> loss before: 0.26369917420809763, loss after: 0.2631884820854622]
[epoch 901/1000, batch 61/100 -> loss before: 0.28845191915621404, loss after: 0.2884356660806048]
[epoch 901/1000, batch 71/100 -> loss before: 0.277307271342159, loss after: 0.2767157211456944]
[epoch 901/1000, batch 81/100 -> loss before: 0.24501816998341744, loss after: 0.2432029654996124]
[epoch 901/1000, batch 91/100 -> loss before: 0.17987418246890552, loss after: 0.1796778450950807]
ENDING EPOCH 901/1000 [loss before: 0.2678364568696686, loss after: 0.2679767292572288; epoch time: 0.03296470642089844 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.12472290721977822, loss after: 0.12423784697674516]
[epoch 1000/1000, batch 11/100 -> loss before: 0.25924148140798564, loss after: 0.2587725176685238]
[epoch 1000/1000, batch 21/100 -> loss before: 0.14237461477842553, loss after: 0.1423030429219242]
[epoch 1000/1000, batch 31/100 -> loss before: 0.2183068722550808, loss after: 0.21756489291047204]
[epoch 1000/1000, batch 41/100 -> loss before: 0.2611647096262405, loss after: 0.2610189094169569]
[epoch 1000/1000, batch 51/100 -> loss before: 0.3113005685855829, loss after: 0.3112985021989302]
[epoch 1000/1000, batch 61/100 -> loss before: 0.21966454802684438, loss after: 0.21738810374392567]
[epoch 1000/1000, batch 71/100 -> loss before: 0.36235729170589387, loss after: 0.36141751807026995]
[epoch 1000/1000, batch 81/100 -> loss before: 0.3618963458724965, loss after: 0.361755781760934]
[epoch 1000/1000, batch 91/100 -> loss before: 0.3869283784874375, loss after: 0.3858563841461372]
ENDING EPOCH 1000/1000 [loss before: 0.267602569296116, loss after: 0.2677119871385316; epoch time: 0.021968364715576172 s]
FIT DONE. [time: 23.58128786087036 s]
LOSS TRAIN (MSE): 0.2677119871385316
LOSS TEST (MSE): 0.26232615997709646
R^2 TRAIN: 0.05428248272440328
R^2 TEST: 0.054783932656849776
EXPERIMENT DONE

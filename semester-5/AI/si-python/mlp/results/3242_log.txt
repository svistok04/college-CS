EXPERIMENT 3242 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 128, 64, 64, 32, 32], activation_name=relu, targets_activation_name=linear, 
initialization_name=uniform, algo_name=adam, learning_rate=0.0001, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 32481]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 0.87553713426397, loss after: 0.7590826772677668]
[epoch 1/1000, batch 11/100 -> loss before: 0.7966189824253224, loss after: 0.6754572107449348]
[epoch 1/1000, batch 21/100 -> loss before: 0.4238039189227785, loss after: 0.41354862120060804]
[epoch 1/1000, batch 31/100 -> loss before: 0.34037274548366814, loss after: 0.33026735983942296]
[epoch 1/1000, batch 41/100 -> loss before: 0.3990905971216387, loss after: 0.3789574172489613]
[epoch 1/1000, batch 51/100 -> loss before: 0.16665967588712724, loss after: 0.14918069394111216]
[epoch 1/1000, batch 61/100 -> loss before: 0.15731949148316546, loss after: 0.1557854920113632]
[epoch 1/1000, batch 71/100 -> loss before: 0.4172911472329397, loss after: 0.4121277688192716]
[epoch 1/1000, batch 81/100 -> loss before: 0.43869383056313566, loss after: 0.4224538080320811]
[epoch 1/1000, batch 91/100 -> loss before: 0.3065431784065093, loss after: 0.2950189874250926]
ENDING EPOCH 1/1000 [loss before: 1.102092538201909, loss after: 0.26163312360967145; epoch time: 0.0873715877532959 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.2058844137821695, loss after: 0.1974016480238832]
[epoch 101/1000, batch 11/100 -> loss before: 0.21394038920447253, loss after: 0.1953177571242984]
[epoch 101/1000, batch 21/100 -> loss before: 0.23444325811066147, loss after: 0.2226005173978046]
[epoch 101/1000, batch 31/100 -> loss before: 0.12649995054071383, loss after: 0.12825474715910157]
[epoch 101/1000, batch 41/100 -> loss before: 0.10180759158597526, loss after: 0.11213329083773589]
[epoch 101/1000, batch 51/100 -> loss before: 0.1081035803940191, loss after: 0.10781008941411782]
[epoch 101/1000, batch 61/100 -> loss before: 0.07920779387611052, loss after: 0.08201331674251568]
[epoch 101/1000, batch 71/100 -> loss before: 0.2643175347276311, loss after: 0.2578427662027428]
[epoch 101/1000, batch 81/100 -> loss before: 0.23770114709726547, loss after: 0.22964423491359728]
[epoch 101/1000, batch 91/100 -> loss before: 0.21961338712929357, loss after: 0.22054913929186296]
ENDING EPOCH 101/1000 [loss before: 0.1855855092890701, loss after: 0.18911289333790762; epoch time: 0.08368325233459473 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.3539899598435229, loss after: 0.3497687320123586]
[epoch 201/1000, batch 11/100 -> loss before: 0.24967613681205827, loss after: 0.2322834137041959]
[epoch 201/1000, batch 21/100 -> loss before: 0.35603741543783063, loss after: 0.2976962826626363]
[epoch 201/1000, batch 31/100 -> loss before: 0.1926990957277705, loss after: 0.17453704456995817]
[epoch 201/1000, batch 41/100 -> loss before: 0.13607402783730707, loss after: 0.12871161575530532]
[epoch 201/1000, batch 51/100 -> loss before: 0.21590180433415643, loss after: 0.21458715240032208]
[epoch 201/1000, batch 61/100 -> loss before: 0.12972398795371387, loss after: 0.1284540463655221]
[epoch 201/1000, batch 71/100 -> loss before: 0.05478495166205487, loss after: 0.0524924095811103]
[epoch 201/1000, batch 81/100 -> loss before: 0.36154044602293445, loss after: 0.34294060710508545]
[epoch 201/1000, batch 91/100 -> loss before: 0.12421147875652856, loss after: 0.11976525412806545]
ENDING EPOCH 201/1000 [loss before: 0.14899908835646422, loss after: 0.15352198412378698; epoch time: 0.09037947654724121 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.03607546759493211, loss after: 0.03430337883943561]
[epoch 301/1000, batch 11/100 -> loss before: 0.05092272282453716, loss after: 0.045224616822214375]
[epoch 301/1000, batch 21/100 -> loss before: 0.061602453390162536, loss after: 0.060870809856595154]
[epoch 301/1000, batch 31/100 -> loss before: 0.07882866657651287, loss after: 0.0756398109959447]
[epoch 301/1000, batch 41/100 -> loss before: 0.15036305078996332, loss after: 0.13791412933922184]
[epoch 301/1000, batch 51/100 -> loss before: 0.044426266299420245, loss after: 0.044060601320608614]
[epoch 301/1000, batch 61/100 -> loss before: 0.09760434803261128, loss after: 0.09609673717952809]
[epoch 301/1000, batch 71/100 -> loss before: 0.06791175088576788, loss after: 0.06335820849350865]
[epoch 301/1000, batch 81/100 -> loss before: 0.04130099278433725, loss after: 0.03835816209851113]
[epoch 301/1000, batch 91/100 -> loss before: 0.06429917433034786, loss after: 0.057351116356498845]
ENDING EPOCH 301/1000 [loss before: 0.10786560322546775, loss after: 0.11401224960741123; epoch time: 0.08847260475158691 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.20090576857698625, loss after: 0.19644853175220622]
[epoch 401/1000, batch 11/100 -> loss before: 0.15182749078447494, loss after: 0.13740062385453147]
[epoch 401/1000, batch 21/100 -> loss before: 0.03975564614147335, loss after: 0.03794102523599758]
[epoch 401/1000, batch 31/100 -> loss before: 0.053192122614387806, loss after: 0.045037086662847704]
[epoch 401/1000, batch 41/100 -> loss before: 0.07461183178519777, loss after: 0.07299096763782421]
[epoch 401/1000, batch 51/100 -> loss before: 0.1556892664650244, loss after: 0.14109217680972752]
[epoch 401/1000, batch 61/100 -> loss before: 0.07760702109909928, loss after: 0.07381957580380452]
[epoch 401/1000, batch 71/100 -> loss before: 0.0887451465598817, loss after: 0.0857801613004924]
[epoch 401/1000, batch 81/100 -> loss before: 0.11598830243113692, loss after: 0.10022186601486087]
[epoch 401/1000, batch 91/100 -> loss before: 0.12092994671651622, loss after: 0.11206580194471913]
ENDING EPOCH 401/1000 [loss before: 0.07987824498553024, loss after: 0.08564000929117267; epoch time: 0.08411359786987305 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.03630342568562871, loss after: 0.036529045569462196]
[epoch 501/1000, batch 11/100 -> loss before: 0.07087853568451206, loss after: 0.06970414171206854]
[epoch 501/1000, batch 21/100 -> loss before: 0.11883334740512479, loss after: 0.11375583762544597]
[epoch 501/1000, batch 31/100 -> loss before: 0.09991416841829151, loss after: 0.09757926910047905]
[epoch 501/1000, batch 41/100 -> loss before: 0.11434773909149168, loss after: 0.08057648958269809]
[epoch 501/1000, batch 51/100 -> loss before: 0.12003014458292416, loss after: 0.10358591905103993]
[epoch 501/1000, batch 61/100 -> loss before: 0.034838020943736316, loss after: 0.028171495917260765]
[epoch 501/1000, batch 71/100 -> loss before: 0.0435507107267503, loss after: 0.041685910087487385]
[epoch 501/1000, batch 81/100 -> loss before: 0.11179811499794157, loss after: 0.10469337062276726]
[epoch 501/1000, batch 91/100 -> loss before: 0.15078856652558814, loss after: 0.12928540933800176]
ENDING EPOCH 501/1000 [loss before: 0.0670323838133603, loss after: 0.065438400687739; epoch time: 0.08452463150024414 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.038687842399295735, loss after: 0.03725178572181695]
[epoch 601/1000, batch 11/100 -> loss before: 0.02328798946571856, loss after: 0.024586282762368027]
[epoch 601/1000, batch 21/100 -> loss before: 0.09520796550319417, loss after: 0.09098408218863263]
[epoch 601/1000, batch 31/100 -> loss before: 0.11627229320259354, loss after: 0.09935678851812615]
[epoch 601/1000, batch 41/100 -> loss before: 0.0704545353307844, loss after: 0.0667259535427248]
[epoch 601/1000, batch 51/100 -> loss before: 0.07101315990968059, loss after: 0.06535513469010364]
[epoch 601/1000, batch 61/100 -> loss before: 0.11502231126257212, loss after: 0.10480214016792286]
[epoch 601/1000, batch 71/100 -> loss before: 0.07239611961754858, loss after: 0.06861427598668186]
[epoch 601/1000, batch 81/100 -> loss before: 0.06472615320083595, loss after: 0.06127400140392016]
[epoch 601/1000, batch 91/100 -> loss before: 0.05808252702041392, loss after: 0.05379768718240311]
ENDING EPOCH 601/1000 [loss before: 0.06480070954607269, loss after: 0.056564015789909466; epoch time: 0.08798980712890625 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.10171595340634003, loss after: 0.08582870440376614]
[epoch 701/1000, batch 11/100 -> loss before: 0.05716300916508351, loss after: 0.05383562614863343]
[epoch 701/1000, batch 21/100 -> loss before: 0.011191974509706073, loss after: 0.009952388166564395]
[epoch 701/1000, batch 31/100 -> loss before: 0.042989459822991516, loss after: 0.03894041886986765]
[epoch 701/1000, batch 41/100 -> loss before: 0.023375991986548505, loss after: 0.021728089777648892]
[epoch 701/1000, batch 51/100 -> loss before: 0.011178419583941907, loss after: 0.010848649495003474]
[epoch 701/1000, batch 61/100 -> loss before: 0.013978966787034034, loss after: 0.010119178304640224]
[epoch 701/1000, batch 71/100 -> loss before: 0.03992245418693194, loss after: 0.0396706523261026]
[epoch 701/1000, batch 81/100 -> loss before: 0.03026717808322289, loss after: 0.029219641915857474]
[epoch 701/1000, batch 91/100 -> loss before: 0.03880025952954939, loss after: 0.035186002679582315]
ENDING EPOCH 701/1000 [loss before: 0.09065100342905487, loss after: 0.044660431817922404; epoch time: 0.10714125633239746 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.00466289835194627, loss after: 0.004505265297692821]
[epoch 801/1000, batch 11/100 -> loss before: 0.02632143590164184, loss after: 0.025567127711525712]
[epoch 801/1000, batch 21/100 -> loss before: 0.01977366858254252, loss after: 0.016982778886682835]
[epoch 801/1000, batch 31/100 -> loss before: 0.0192061684759624, loss after: 0.019817564062556574]
[epoch 801/1000, batch 41/100 -> loss before: 0.08975814225099985, loss after: 0.07589217042271369]
[epoch 801/1000, batch 51/100 -> loss before: 0.056655496014265914, loss after: 0.05547845477421463]
[epoch 801/1000, batch 61/100 -> loss before: 0.10431331355314535, loss after: 0.09569660421245091]
[epoch 801/1000, batch 71/100 -> loss before: 0.1414905967709305, loss after: 0.13155012185208353]
[epoch 801/1000, batch 81/100 -> loss before: 0.026382260126605227, loss after: 0.026267633669504888]
[epoch 801/1000, batch 91/100 -> loss before: 0.1593808877721387, loss after: 0.09789950755493618]
ENDING EPOCH 801/1000 [loss before: 0.03571523021349115, loss after: 0.042171163041353064; epoch time: 0.0913689136505127 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.0396868905730464, loss after: 0.04084865761604647]
[epoch 901/1000, batch 11/100 -> loss before: 0.03031280085868467, loss after: 0.02696010638975358]
[epoch 901/1000, batch 21/100 -> loss before: 0.019966884825177243, loss after: 0.01811641979806939]
[epoch 901/1000, batch 31/100 -> loss before: 0.040457809095086145, loss after: 0.03168595943004436]
[epoch 901/1000, batch 41/100 -> loss before: 0.05931239446046549, loss after: 0.05737186297056316]
[epoch 901/1000, batch 51/100 -> loss before: 0.12876785144987463, loss after: 0.11371974445225005]
[epoch 901/1000, batch 61/100 -> loss before: 0.019518366942493807, loss after: 0.01651311438432638]
[epoch 901/1000, batch 71/100 -> loss before: 0.06397906129815809, loss after: 0.0500710521829836]
[epoch 901/1000, batch 81/100 -> loss before: 0.02615658656606818, loss after: 0.025913518911909357]
[epoch 901/1000, batch 91/100 -> loss before: 0.01320388229702119, loss after: 0.011546746717098638]
ENDING EPOCH 901/1000 [loss before: 0.050723237998284106, loss after: 0.03202238878515068; epoch time: 0.08721518516540527 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.047514479165558295, loss after: 0.0448797060943979]
[epoch 1000/1000, batch 11/100 -> loss before: 0.0319173214898833, loss after: 0.027868876740656627]
[epoch 1000/1000, batch 21/100 -> loss before: 0.012221825803306182, loss after: 0.009382934833624975]
[epoch 1000/1000, batch 31/100 -> loss before: 0.01913214213640768, loss after: 0.017193849354531904]
[epoch 1000/1000, batch 41/100 -> loss before: 0.02646376240728311, loss after: 0.018504748174066468]
[epoch 1000/1000, batch 51/100 -> loss before: 0.06662414285909413, loss after: 0.05817260316550963]
[epoch 1000/1000, batch 61/100 -> loss before: 0.02124225300099445, loss after: 0.018239348717784477]
[epoch 1000/1000, batch 71/100 -> loss before: 0.015678069420477805, loss after: 0.01296464120197301]
[epoch 1000/1000, batch 81/100 -> loss before: 0.05612184425532625, loss after: 0.02845859119392542]
[epoch 1000/1000, batch 91/100 -> loss before: 0.06585253602598205, loss after: 0.065937121700484]
ENDING EPOCH 1000/1000 [loss before: 0.03177155624012422, loss after: 0.027310804916943467; epoch time: 0.10278964042663574 s]
FIT DONE. [time: 84.79482865333557 s]
LOSS TRAIN (MSE): 0.027310804916943467
LOSS TEST (MSE): 0.04302596306009015
R^2 TRAIN: 0.9035220391252609
R^2 TEST: 0.8449684484351052
EXPERIMENT DONE

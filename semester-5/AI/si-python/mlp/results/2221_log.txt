EXPERIMENT 2221 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 64, 32], activation_name=relu, targets_activation_name=linear, 
initialization_name=uniform, algo_name=sgd_momentum, learning_rate=0.001, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 10753]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 20.679362556386955, loss after: 0.39754610217258846]
[epoch 1/1000, batch 11/100 -> loss before: 0.26450899213300205, loss after: 0.2634763379447305]
[epoch 1/1000, batch 21/100 -> loss before: 0.13318201164836269, loss after: 0.1917236599598347]
[epoch 1/1000, batch 31/100 -> loss before: 0.5186366673756622, loss after: 0.49060097746826703]
[epoch 1/1000, batch 41/100 -> loss before: 0.16768595076454196, loss after: 0.184116282457021]
[epoch 1/1000, batch 51/100 -> loss before: 0.3913072838198148, loss after: 0.3064547695724806]
[epoch 1/1000, batch 61/100 -> loss before: 0.5047720182481739, loss after: 0.4869298110410895]
[epoch 1/1000, batch 71/100 -> loss before: 0.44155960691419127, loss after: 0.4401168077031142]
[epoch 1/1000, batch 81/100 -> loss before: 0.11701857638675386, loss after: 0.11651345291483343]
[epoch 1/1000, batch 91/100 -> loss before: 0.42278640014686825, loss after: 0.4202984347651789]
ENDING EPOCH 1/1000 [loss before: 18.773492598911375, loss after: 0.2822565900118579; epoch time: 0.024949073791503906 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.16103845439192266, loss after: 0.1610155940239144]
[epoch 101/1000, batch 11/100 -> loss before: 0.09373999045119787, loss after: 0.09372834650488075]
[epoch 101/1000, batch 21/100 -> loss before: 0.11288170920971927, loss after: 0.11101691235375019]
[epoch 101/1000, batch 31/100 -> loss before: 0.1543303919895021, loss after: 0.15464894161462167]
[epoch 101/1000, batch 41/100 -> loss before: 0.43642270658472054, loss after: 0.4361708992235974]
[epoch 101/1000, batch 51/100 -> loss before: 0.14499450569531971, loss after: 0.14305789394660148]
[epoch 101/1000, batch 61/100 -> loss before: 0.20720600033038483, loss after: 0.20682705498515572]
[epoch 101/1000, batch 71/100 -> loss before: 0.26140325379803236, loss after: 0.26185061786651]
[epoch 101/1000, batch 81/100 -> loss before: 0.25031177436832086, loss after: 0.25264303329020277]
[epoch 101/1000, batch 91/100 -> loss before: 0.19964520346755193, loss after: 0.20078516672574542]
ENDING EPOCH 101/1000 [loss before: 0.21845372735809887, loss after: 0.22431361351327386; epoch time: 0.02597975730895996 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.1768308142860944, loss after: 0.17655140308519696]
[epoch 201/1000, batch 11/100 -> loss before: 0.1899008735147371, loss after: 0.18603863524555384]
[epoch 201/1000, batch 21/100 -> loss before: 0.1899075077753658, loss after: 0.18939654389518917]
[epoch 201/1000, batch 31/100 -> loss before: 0.2225693979747536, loss after: 0.22351842500473232]
[epoch 201/1000, batch 41/100 -> loss before: 0.32468176834684864, loss after: 0.3234011651198021]
[epoch 201/1000, batch 51/100 -> loss before: 0.3403558021515839, loss after: 0.3398346752551023]
[epoch 201/1000, batch 61/100 -> loss before: 0.23060775302407371, loss after: 0.2329504092838386]
[epoch 201/1000, batch 71/100 -> loss before: 0.10992105300931823, loss after: 0.10841769951982438]
[epoch 201/1000, batch 81/100 -> loss before: 0.11262018294641711, loss after: 0.11222458189124156]
[epoch 201/1000, batch 91/100 -> loss before: 0.1704350101582041, loss after: 0.16133478216727107]
ENDING EPOCH 201/1000 [loss before: 0.21281885085407723, loss after: 0.21208350783714525; epoch time: 0.02375483512878418 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.17547239226222103, loss after: 0.175470286196952]
[epoch 301/1000, batch 11/100 -> loss before: 0.3727639991391435, loss after: 0.3720462499953642]
[epoch 301/1000, batch 21/100 -> loss before: 0.18747229819905079, loss after: 0.18734894486892292]
[epoch 301/1000, batch 31/100 -> loss before: 0.1305914859976752, loss after: 0.12939060723403503]
[epoch 301/1000, batch 41/100 -> loss before: 0.10265316508505559, loss after: 0.10277153758692617]
[epoch 301/1000, batch 51/100 -> loss before: 0.2447213887868494, loss after: 0.24851049228520083]
[epoch 301/1000, batch 61/100 -> loss before: 0.13732997548867748, loss after: 0.13731896237995184]
[epoch 301/1000, batch 71/100 -> loss before: 0.3370513387716531, loss after: 0.3365984377778777]
[epoch 301/1000, batch 81/100 -> loss before: 0.12080669327354658, loss after: 0.12076664087596749]
[epoch 301/1000, batch 91/100 -> loss before: 0.11704012955625409, loss after: 0.11078103851734059]
ENDING EPOCH 301/1000 [loss before: 0.2056398581081348, loss after: 0.20842708993216155; epoch time: 0.025162458419799805 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.3375611249034042, loss after: 0.3371019028272279]
[epoch 401/1000, batch 11/100 -> loss before: 0.33530857184732044, loss after: 0.3350816861780114]
[epoch 401/1000, batch 21/100 -> loss before: 0.1329495440604242, loss after: 0.13277662558715908]
[epoch 401/1000, batch 31/100 -> loss before: 0.3227157545561895, loss after: 0.32161556942037545]
[epoch 401/1000, batch 41/100 -> loss before: 0.09248177661894122, loss after: 0.09219730502558011]
[epoch 401/1000, batch 51/100 -> loss before: 0.3784078080832963, loss after: 0.3785868698049523]
[epoch 401/1000, batch 61/100 -> loss before: 0.12410359909197828, loss after: 0.12402742629903878]
[epoch 401/1000, batch 71/100 -> loss before: 0.14585736957421214, loss after: 0.14352791619166966]
[epoch 401/1000, batch 81/100 -> loss before: 0.18735888645069634, loss after: 0.18744579080265625]
[epoch 401/1000, batch 91/100 -> loss before: 0.20350364944755017, loss after: 0.20241347712536711]
ENDING EPOCH 401/1000 [loss before: 0.20536570496199727, loss after: 0.20480989914780026; epoch time: 0.03626894950866699 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.19908039434598185, loss after: 0.197746881765188]
[epoch 501/1000, batch 11/100 -> loss before: 0.15588733627373821, loss after: 0.15590478841222152]
[epoch 501/1000, batch 21/100 -> loss before: 0.1380543262704573, loss after: 0.13762071459553157]
[epoch 501/1000, batch 31/100 -> loss before: 0.11458918518882563, loss after: 0.10982444581581297]
[epoch 501/1000, batch 41/100 -> loss before: 0.2603095299230134, loss after: 0.24840372474362993]
[epoch 501/1000, batch 51/100 -> loss before: 0.18628763184122793, loss after: 0.1842350863422248]
[epoch 501/1000, batch 61/100 -> loss before: 0.10765317186358048, loss after: 0.10632163078423298]
[epoch 501/1000, batch 71/100 -> loss before: 0.17443102885011977, loss after: 0.17420894678239712]
[epoch 501/1000, batch 81/100 -> loss before: 0.20351031890890492, loss after: 0.20012733250499912]
[epoch 501/1000, batch 91/100 -> loss before: 0.34259226045473046, loss after: 0.3428779513513842]
ENDING EPOCH 501/1000 [loss before: 0.204749387386321, loss after: 0.207983257512441; epoch time: 0.024585247039794922 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.2760117945781518, loss after: 0.27621729822735197]
[epoch 601/1000, batch 11/100 -> loss before: 0.14531985927267715, loss after: 0.14443033459361898]
[epoch 601/1000, batch 21/100 -> loss before: 0.4716401659993556, loss after: 0.4707573064783091]
[epoch 601/1000, batch 31/100 -> loss before: 0.06746966220889848, loss after: 0.06758802158692846]
[epoch 601/1000, batch 41/100 -> loss before: 0.14644361200655315, loss after: 0.14626723135062597]
[epoch 601/1000, batch 51/100 -> loss before: 0.1555818058210764, loss after: 0.1502235730152951]
[epoch 601/1000, batch 61/100 -> loss before: 0.39876888529420473, loss after: 0.3984840857418656]
[epoch 601/1000, batch 71/100 -> loss before: 0.30595639763016347, loss after: 0.30513459805094]
[epoch 601/1000, batch 81/100 -> loss before: 0.05944995411240243, loss after: 0.05820845214084162]
[epoch 601/1000, batch 91/100 -> loss before: 0.08361183047381933, loss after: 0.08358310022571122]
ENDING EPOCH 601/1000 [loss before: 0.20190303566807466, loss after: 0.20609746819930042; epoch time: 0.024029016494750977 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.13809001558717957, loss after: 0.1370257653657451]
[epoch 701/1000, batch 11/100 -> loss before: 0.23950665808852084, loss after: 0.23931932787531526]
[epoch 701/1000, batch 21/100 -> loss before: 0.14573235923638547, loss after: 0.1446667852408715]
[epoch 701/1000, batch 31/100 -> loss before: 0.15257997155754055, loss after: 0.1510382626099728]
[epoch 701/1000, batch 41/100 -> loss before: 0.16744246890001557, loss after: 0.16377634102411825]
[epoch 701/1000, batch 51/100 -> loss before: 0.29102653328845757, loss after: 0.2913977861009447]
[epoch 701/1000, batch 61/100 -> loss before: 0.07728775420270373, loss after: 0.07441737168547385]
[epoch 701/1000, batch 71/100 -> loss before: 0.20863952545079592, loss after: 0.20759277578786467]
[epoch 701/1000, batch 81/100 -> loss before: 0.13007123856953512, loss after: 0.12357848373575112]
[epoch 701/1000, batch 91/100 -> loss before: 0.24600378008365653, loss after: 0.2454250569679745]
ENDING EPOCH 701/1000 [loss before: 0.19306388642545955, loss after: 0.19288716457227195; epoch time: 0.034607887268066406 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.31123363916266517, loss after: 0.3109534206557183]
[epoch 801/1000, batch 11/100 -> loss before: 0.11358727045221088, loss after: 0.1101726254344481]
[epoch 801/1000, batch 21/100 -> loss before: 0.31659114289888424, loss after: 0.3145452697579559]
[epoch 801/1000, batch 31/100 -> loss before: 0.140627539416678, loss after: 0.13834712097886182]
[epoch 801/1000, batch 41/100 -> loss before: 0.16514914962346092, loss after: 0.16352118696213547]
[epoch 801/1000, batch 51/100 -> loss before: 0.1748123153902754, loss after: 0.17243877634969448]
[epoch 801/1000, batch 61/100 -> loss before: 0.22213318672938112, loss after: 0.2219463945657559]
[epoch 801/1000, batch 71/100 -> loss before: 0.051777005775132015, loss after: 0.05140201055940826]
[epoch 801/1000, batch 81/100 -> loss before: 0.12723441205308703, loss after: 0.12455499221723057]
[epoch 801/1000, batch 91/100 -> loss before: 0.11788104946736885, loss after: 0.11477573737976496]
ENDING EPOCH 801/1000 [loss before: 0.19110234444081448, loss after: 0.18715960797068787; epoch time: 0.026325225830078125 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.14770552208504445, loss after: 0.14922831778975879]
[epoch 901/1000, batch 11/100 -> loss before: 0.2449500991741894, loss after: 0.22263085131241805]
[epoch 901/1000, batch 21/100 -> loss before: 0.10657536969649592, loss after: 0.10745234954661823]
[epoch 901/1000, batch 31/100 -> loss before: 0.1235569562330338, loss after: 0.1224913917508101]
[epoch 901/1000, batch 41/100 -> loss before: 0.04522955166084649, loss after: 0.047588879737242316]
[epoch 901/1000, batch 51/100 -> loss before: 0.14537593923746578, loss after: 0.13991351191801704]
[epoch 901/1000, batch 61/100 -> loss before: 0.21493178543736455, loss after: 0.21626096727563654]
[epoch 901/1000, batch 71/100 -> loss before: 0.03805305444670692, loss after: 0.03836453990909379]
[epoch 901/1000, batch 81/100 -> loss before: 0.14932598261621227, loss after: 0.14797089453114326]
[epoch 901/1000, batch 91/100 -> loss before: 0.10699121352671104, loss after: 0.09587336329120225]
ENDING EPOCH 901/1000 [loss before: 0.1649632173721529, loss after: 0.1615922333648922; epoch time: 0.024954557418823242 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.04872236363420816, loss after: 0.04800544210894199]
[epoch 1000/1000, batch 11/100 -> loss before: 0.0883740255189892, loss after: 0.08125075588024877]
[epoch 1000/1000, batch 21/100 -> loss before: 0.16108480512805828, loss after: 0.15725445632863627]
[epoch 1000/1000, batch 31/100 -> loss before: 0.09933045758374677, loss after: 0.09819826413079633]
[epoch 1000/1000, batch 41/100 -> loss before: 0.20672041330495822, loss after: 0.20906938488727098]
[epoch 1000/1000, batch 51/100 -> loss before: 0.19532833267276106, loss after: 0.19553319854528742]
[epoch 1000/1000, batch 61/100 -> loss before: 0.15066855947683244, loss after: 0.14916325523524876]
[epoch 1000/1000, batch 71/100 -> loss before: 0.12602622232327676, loss after: 0.12681646916103714]
[epoch 1000/1000, batch 81/100 -> loss before: 0.30563780420019737, loss after: 0.30378706173293313]
[epoch 1000/1000, batch 91/100 -> loss before: 0.25471700932883645, loss after: 0.2512749805805009]
ENDING EPOCH 1000/1000 [loss before: 0.14498346419923985, loss after: 0.1405781121462252; epoch time: 0.026778221130371094 s]
FIT DONE. [time: 23.816234350204468 s]
LOSS TRAIN (MSE): 0.1405781121462252
LOSS TEST (MSE): 0.1391090699929913
R^2 TRAIN: 0.5033947316919247
R^2 TEST: 0.4987609010019496
EXPERIMENT DONE

EXPERIMENT 1132 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 128, 64, 64, 32, 32], activation_name=sigmoid, targets_activation_name=linear, 
initialization_name=uniform, algo_name=rmsprop, learning_rate=0.01, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 32481]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 0.26392389365226554, loss after: 2.869183641914642]
[epoch 1/1000, batch 11/100 -> loss before: 0.4747132855245493, loss after: 0.15857437261246501]
[epoch 1/1000, batch 21/100 -> loss before: 0.27112821582090335, loss after: 0.26104218980580907]
[epoch 1/1000, batch 31/100 -> loss before: 0.3727379192717969, loss after: 0.3432755799088335]
[epoch 1/1000, batch 41/100 -> loss before: 0.2863758572775684, loss after: 0.2854529995261693]
[epoch 1/1000, batch 51/100 -> loss before: 0.1530626485467978, loss after: 0.09744171594448647]
[epoch 1/1000, batch 61/100 -> loss before: 0.30682653943870697, loss after: 0.22207718630293033]
[epoch 1/1000, batch 71/100 -> loss before: 0.324164218205582, loss after: 0.3237060672361145]
[epoch 1/1000, batch 81/100 -> loss before: 0.38980714106088155, loss after: 0.3776707557475461]
[epoch 1/1000, batch 91/100 -> loss before: 0.4012463904915163, loss after: 0.3163766479523215]
ENDING EPOCH 1/1000 [loss before: 0.2838936199301506, loss after: 0.33035430594460685; epoch time: 0.07421517372131348 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.3096509761338525, loss after: 0.29941579950434466]
[epoch 101/1000, batch 11/100 -> loss before: 0.2425908248993145, loss after: 0.24258736971175204]
[epoch 101/1000, batch 21/100 -> loss before: 0.27962497892127336, loss after: 0.2790585088702582]
[epoch 101/1000, batch 31/100 -> loss before: 0.14701282522314696, loss after: 0.14635729660412944]
[epoch 101/1000, batch 41/100 -> loss before: 0.36843046918266364, loss after: 0.36842176165720075]
[epoch 101/1000, batch 51/100 -> loss before: 0.1615296212519576, loss after: 0.16140237366150884]
[epoch 101/1000, batch 61/100 -> loss before: 0.16280731878068588, loss after: 0.16280174045014462]
[epoch 101/1000, batch 71/100 -> loss before: 0.36965449122346933, loss after: 0.36406722116206236]
[epoch 101/1000, batch 81/100 -> loss before: 0.33283564853834585, loss after: 0.3152108920584499]
[epoch 101/1000, batch 91/100 -> loss before: 0.3717113771825801, loss after: 0.37039428182781925]
ENDING EPOCH 101/1000 [loss before: 0.2830900510529994, loss after: 0.28379010440615504; epoch time: 0.07841157913208008 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.5735933436539249, loss after: 0.5698155490469882]
[epoch 201/1000, batch 11/100 -> loss before: 0.45830712544836505, loss after: 0.45822686491717396]
[epoch 201/1000, batch 21/100 -> loss before: 0.34000789309938545, loss after: 0.326958372227009]
[epoch 201/1000, batch 31/100 -> loss before: 0.2744893439591881, loss after: 0.27414559460835186]
[epoch 201/1000, batch 41/100 -> loss before: 0.2478820482378823, loss after: 0.24102907477442392]
[epoch 201/1000, batch 51/100 -> loss before: 0.38772279801930243, loss after: 0.3876022118433615]
[epoch 201/1000, batch 61/100 -> loss before: 0.3090422171684915, loss after: 0.3059091046264481]
[epoch 201/1000, batch 71/100 -> loss before: 0.17743065104037556, loss after: 0.176112310536918]
[epoch 201/1000, batch 81/100 -> loss before: 0.2902452168978088, loss after: 0.28251260483793017]
[epoch 201/1000, batch 91/100 -> loss before: 0.4610128697762727, loss after: 0.4568400341975184]
ENDING EPOCH 201/1000 [loss before: 0.28331773290045154, loss after: 0.28527204273388096; epoch time: 0.07709360122680664 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.14946699213142473, loss after: 0.14902869881932695]
[epoch 301/1000, batch 11/100 -> loss before: 0.10491451750817633, loss after: 0.10396796172070846]
[epoch 301/1000, batch 21/100 -> loss before: 0.4063728272769308, loss after: 0.39575496083954664]
[epoch 301/1000, batch 31/100 -> loss before: 0.2810132993516989, loss after: 0.28002491852977013]
[epoch 301/1000, batch 41/100 -> loss before: 0.3273077768399301, loss after: 0.32709695472702977]
[epoch 301/1000, batch 51/100 -> loss before: 0.3184925867068663, loss after: 0.31574132778552666]
[epoch 301/1000, batch 61/100 -> loss before: 0.1750878160315273, loss after: 0.1750820008316404]
[epoch 301/1000, batch 71/100 -> loss before: 0.18943291205735244, loss after: 0.1881098601902591]
[epoch 301/1000, batch 81/100 -> loss before: 0.25147684993019703, loss after: 0.2484671468532938]
[epoch 301/1000, batch 91/100 -> loss before: 0.36237584075991985, loss after: 0.3553930635689432]
ENDING EPOCH 301/1000 [loss before: 0.2832357264980495, loss after: 0.2833650482776483; epoch time: 0.07377076148986816 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.5413903143985525, loss after: 0.5331193050131214]
[epoch 401/1000, batch 11/100 -> loss before: 0.24209455636725288, loss after: 0.24147981024498608]
[epoch 401/1000, batch 21/100 -> loss before: 0.20845189184572394, loss after: 0.1960158298341734]
[epoch 401/1000, batch 31/100 -> loss before: 0.28623359435897344, loss after: 0.2862324013360689]
[epoch 401/1000, batch 41/100 -> loss before: 0.20599290961129713, loss after: 0.20485691259754618]
[epoch 401/1000, batch 51/100 -> loss before: 0.3094634804507749, loss after: 0.3069962153937344]
[epoch 401/1000, batch 61/100 -> loss before: 0.28533348614666604, loss after: 0.2848711951505432]
[epoch 401/1000, batch 71/100 -> loss before: 0.2961896137846035, loss after: 0.2849283061118813]
[epoch 401/1000, batch 81/100 -> loss before: 0.47476540985955706, loss after: 0.4661083604618323]
[epoch 401/1000, batch 91/100 -> loss before: 0.1547108424113451, loss after: 0.1545507045030447]
ENDING EPOCH 401/1000 [loss before: 0.2836611383844632, loss after: 0.283078867698437; epoch time: 0.07501482963562012 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.2882966531713227, loss after: 0.28552992673293964]
[epoch 501/1000, batch 11/100 -> loss before: 0.40377330616825613, loss after: 0.4022397277452421]
[epoch 501/1000, batch 21/100 -> loss before: 0.6353664201825788, loss after: 0.6293107770382725]
[epoch 501/1000, batch 31/100 -> loss before: 0.11265192490224889, loss after: 0.11256857830383818]
[epoch 501/1000, batch 41/100 -> loss before: 0.2988744485826854, loss after: 0.2831557081476294]
[epoch 501/1000, batch 51/100 -> loss before: 0.2109943136240419, loss after: 0.2103522433578215]
[epoch 501/1000, batch 61/100 -> loss before: 0.5008894656705277, loss after: 0.49329634982571113]
[epoch 501/1000, batch 71/100 -> loss before: 0.2656864141616405, loss after: 0.2648273835624114]
[epoch 501/1000, batch 81/100 -> loss before: 0.5051186032232469, loss after: 0.5050538186530671]
[epoch 501/1000, batch 91/100 -> loss before: 0.26564798448875526, loss after: 0.26509821183903626]
ENDING EPOCH 501/1000 [loss before: 0.28309098882467937, loss after: 0.28357527323437454; epoch time: 0.07840776443481445 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.2682087800597912, loss after: 0.26798289546658227]
[epoch 601/1000, batch 11/100 -> loss before: 0.38849185806940295, loss after: 0.3751118247672174]
[epoch 601/1000, batch 21/100 -> loss before: 0.6217815507034377, loss after: 0.6193308963932892]
[epoch 601/1000, batch 31/100 -> loss before: 0.1499909164864715, loss after: 0.14701840830480156]
[epoch 601/1000, batch 41/100 -> loss before: 0.35076592568311526, loss after: 0.35029560263010795]
[epoch 601/1000, batch 51/100 -> loss before: 0.30850107679781485, loss after: 0.30791385710637886]
[epoch 601/1000, batch 61/100 -> loss before: 0.16976211393126853, loss after: 0.16848302661044173]
[epoch 601/1000, batch 71/100 -> loss before: 0.20745043380526615, loss after: 0.20621787042963452]
[epoch 601/1000, batch 81/100 -> loss before: 0.3183580910747715, loss after: 0.315702564400834]
[epoch 601/1000, batch 91/100 -> loss before: 0.5245907557741977, loss after: 0.5226580512462383]
ENDING EPOCH 601/1000 [loss before: 0.28335818823359726, loss after: 0.28435122596081164; epoch time: 0.0735483169555664 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.25866639729119967, loss after: 0.2511860902731458]
[epoch 701/1000, batch 11/100 -> loss before: 0.3877028053548407, loss after: 0.38566187677117186]
[epoch 701/1000, batch 21/100 -> loss before: 0.35570945851776387, loss after: 0.3431849694892981]
[epoch 701/1000, batch 31/100 -> loss before: 0.2527499619259447, loss after: 0.2527479339096135]
[epoch 701/1000, batch 41/100 -> loss before: 0.1540520342264236, loss after: 0.1487984864684467]
[epoch 701/1000, batch 51/100 -> loss before: 0.2924224550743166, loss after: 0.2912194240177987]
[epoch 701/1000, batch 61/100 -> loss before: 0.3144890661027513, loss after: 0.3144885620112686]
[epoch 701/1000, batch 71/100 -> loss before: 0.11482165550080996, loss after: 0.11244294519715918]
[epoch 701/1000, batch 81/100 -> loss before: 0.3141470186145531, loss after: 0.3114993907254061]
[epoch 701/1000, batch 91/100 -> loss before: 0.30792157524774455, loss after: 0.3034764363960562]
ENDING EPOCH 701/1000 [loss before: 0.28834090925934847, loss after: 0.28343831878097875; epoch time: 0.09789490699768066 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.2612157350248895, loss after: 0.25913007149275546]
[epoch 801/1000, batch 11/100 -> loss before: 0.30367382574974533, loss after: 0.3028954397476152]
[epoch 801/1000, batch 21/100 -> loss before: 0.2282364608272826, loss after: 0.21669234397885165]
[epoch 801/1000, batch 31/100 -> loss before: 0.18825373703680154, loss after: 0.18503014641494622]
[epoch 801/1000, batch 41/100 -> loss before: 0.2639639450492671, loss after: 0.26284012548607366]
[epoch 801/1000, batch 51/100 -> loss before: 0.20922289701847566, loss after: 0.20749223987577592]
[epoch 801/1000, batch 61/100 -> loss before: 0.3674098056753335, loss after: 0.3670785034935515]
[epoch 801/1000, batch 71/100 -> loss before: 0.2858632908441826, loss after: 0.2835707259589288]
[epoch 801/1000, batch 81/100 -> loss before: 0.18370551486894773, loss after: 0.17845959165749256]
[epoch 801/1000, batch 91/100 -> loss before: 0.3296720709269244, loss after: 0.32963514680450234]
ENDING EPOCH 801/1000 [loss before: 0.28393993208570417, loss after: 0.2831005240087593; epoch time: 0.07768774032592773 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.21746395963734103, loss after: 0.21386016893276136]
[epoch 901/1000, batch 11/100 -> loss before: 0.28939801104118734, loss after: 0.28918789907136483]
[epoch 901/1000, batch 21/100 -> loss before: 0.11149805362901197, loss after: 0.10867931422827652]
[epoch 901/1000, batch 31/100 -> loss before: 0.22308113996151438, loss after: 0.21636387796035533]
[epoch 901/1000, batch 41/100 -> loss before: 0.2997496140363363, loss after: 0.29882810657640346]
[epoch 901/1000, batch 51/100 -> loss before: 0.2978794341021041, loss after: 0.296920138048183]
[epoch 901/1000, batch 61/100 -> loss before: 0.3154543782387694, loss after: 0.3151313426002419]
[epoch 901/1000, batch 71/100 -> loss before: 0.3939739766086535, loss after: 0.3880750840073046]
[epoch 901/1000, batch 81/100 -> loss before: 0.2044999881859361, loss after: 0.19610307726711085]
[epoch 901/1000, batch 91/100 -> loss before: 0.4201131246193146, loss after: 0.4086778273918788]
ENDING EPOCH 901/1000 [loss before: 0.2847150298864164, loss after: 0.28307953766324223; epoch time: 0.0745842456817627 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.3568704030512444, loss after: 0.3568647950025514]
[epoch 1000/1000, batch 11/100 -> loss before: 0.2772056106305241, loss after: 0.26733114937117225]
[epoch 1000/1000, batch 21/100 -> loss before: 0.24341731252096052, loss after: 0.23174688180570477]
[epoch 1000/1000, batch 31/100 -> loss before: 0.34944848783094196, loss after: 0.3484200368361558]
[epoch 1000/1000, batch 41/100 -> loss before: 0.29405803277961395, loss after: 0.2880676089025715]
[epoch 1000/1000, batch 51/100 -> loss before: 0.19829732619360274, loss after: 0.19828925562938884]
[epoch 1000/1000, batch 61/100 -> loss before: 0.22107507986639066, loss after: 0.21813909682763494]
[epoch 1000/1000, batch 71/100 -> loss before: 0.24126494337192797, loss after: 0.2405632593636311]
[epoch 1000/1000, batch 81/100 -> loss before: 0.3440089407739242, loss after: 0.337408121640984]
[epoch 1000/1000, batch 91/100 -> loss before: 0.41494291660205845, loss after: 0.4106970707934582]
ENDING EPOCH 1000/1000 [loss before: 0.2850049505438029, loss after: 0.2831446897600665; epoch time: 0.07736778259277344 s]
FIT DONE. [time: 66.76388931274414 s]
LOSS TRAIN (MSE): 0.2831446897600665
LOSS TEST (MSE): 0.2779620672396404
R^2 TRAIN: -0.00023497599715249784
R^2 TEST: -0.0015555142871164218
EXPERIMENT DONE

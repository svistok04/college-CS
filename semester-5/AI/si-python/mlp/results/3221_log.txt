EXPERIMENT 3221 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 64, 32], activation_name=relu, targets_activation_name=linear, 
initialization_name=uniform, algo_name=sgd_momentum, learning_rate=0.0001, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 10753]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 20.679362556386955, loss after: 16.448405397984413]
[epoch 1/1000, batch 11/100 -> loss before: 3.416506816581845, loss after: 3.5450443603041415]
[epoch 1/1000, batch 21/100 -> loss before: 0.15755923339434075, loss after: 0.1367063852508872]
[epoch 1/1000, batch 31/100 -> loss before: 0.8992484727330539, loss after: 0.8715755261099792]
[epoch 1/1000, batch 41/100 -> loss before: 0.2047956783203698, loss after: 0.19414576234021114]
[epoch 1/1000, batch 51/100 -> loss before: 0.33241489111002576, loss after: 0.3205618220754467]
[epoch 1/1000, batch 61/100 -> loss before: 0.5218653482210778, loss after: 0.5164440547324721]
[epoch 1/1000, batch 71/100 -> loss before: 0.4808938021371432, loss after: 0.47007053128413034]
[epoch 1/1000, batch 81/100 -> loss before: 0.10385663618496191, loss after: 0.10413582592135107]
[epoch 1/1000, batch 91/100 -> loss before: 0.38286956236305547, loss after: 0.38276022031637963]
ENDING EPOCH 1/1000 [loss before: 18.773492598911375, loss after: 0.2745511771318279; epoch time: 0.02937936782836914 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.23762014443806262, loss after: 0.23858483971077957]
[epoch 101/1000, batch 11/100 -> loss before: 0.09341893036259594, loss after: 0.09306040642503843]
[epoch 101/1000, batch 21/100 -> loss before: 0.14562730171505506, loss after: 0.1410870329591422]
[epoch 101/1000, batch 31/100 -> loss before: 0.15687774113494407, loss after: 0.15582708433558115]
[epoch 101/1000, batch 41/100 -> loss before: 0.46728078055121725, loss after: 0.465168832870359]
[epoch 101/1000, batch 51/100 -> loss before: 0.08932420918982922, loss after: 0.08924363598442231]
[epoch 101/1000, batch 61/100 -> loss before: 0.25384195158116774, loss after: 0.253371817998934]
[epoch 101/1000, batch 71/100 -> loss before: 0.24901455457582578, loss after: 0.24789547853574367]
[epoch 101/1000, batch 81/100 -> loss before: 0.3156258249717936, loss after: 0.3179496432404094]
[epoch 101/1000, batch 91/100 -> loss before: 0.178731646037749, loss after: 0.1755283326337636]
ENDING EPOCH 101/1000 [loss before: 0.2266958813653876, loss after: 0.22477950644542904; epoch time: 0.03300213813781738 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.1544909667677424, loss after: 0.1531063042503766]
[epoch 201/1000, batch 11/100 -> loss before: 0.2028482497487269, loss after: 0.19770637922347079]
[epoch 201/1000, batch 21/100 -> loss before: 0.21986798059812288, loss after: 0.21914223190583568]
[epoch 201/1000, batch 31/100 -> loss before: 0.2347987516547172, loss after: 0.23254731361282732]
[epoch 201/1000, batch 41/100 -> loss before: 0.2747436638506065, loss after: 0.273914226906303]
[epoch 201/1000, batch 51/100 -> loss before: 0.2831270958438793, loss after: 0.2804417611733396]
[epoch 201/1000, batch 61/100 -> loss before: 0.23208145486010795, loss after: 0.2327843819815855]
[epoch 201/1000, batch 71/100 -> loss before: 0.12414164485908848, loss after: 0.12384745495840974]
[epoch 201/1000, batch 81/100 -> loss before: 0.1965882504515944, loss after: 0.1821554105861582]
[epoch 201/1000, batch 91/100 -> loss before: 0.2164221105356298, loss after: 0.2174804297371221]
ENDING EPOCH 201/1000 [loss before: 0.21229017550703952, loss after: 0.20964060263744005; epoch time: 0.027838706970214844 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.11681069406296658, loss after: 0.11716166680800195]
[epoch 301/1000, batch 11/100 -> loss before: 0.47732069734134985, loss after: 0.46612264724650637]
[epoch 301/1000, batch 21/100 -> loss before: 0.17227798932230948, loss after: 0.17471341707099267]
[epoch 301/1000, batch 31/100 -> loss before: 0.1252475998827037, loss after: 0.1263896302691218]
[epoch 301/1000, batch 41/100 -> loss before: 0.10112132983057683, loss after: 0.10120662859908829]
[epoch 301/1000, batch 51/100 -> loss before: 0.30738482874039164, loss after: 0.2996853138068275]
[epoch 301/1000, batch 61/100 -> loss before: 0.1506633573804626, loss after: 0.15032708559454624]
[epoch 301/1000, batch 71/100 -> loss before: 0.26632275667561356, loss after: 0.25505590449812365]
[epoch 301/1000, batch 81/100 -> loss before: 0.1616217110639136, loss after: 0.15729810873919478]
[epoch 301/1000, batch 91/100 -> loss before: 0.1826782685361698, loss after: 0.18177207441121496]
ENDING EPOCH 301/1000 [loss before: 0.2081149927700689, loss after: 0.20543973759304332; epoch time: 0.027447223663330078 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.21860370520280722, loss after: 0.21979756727928348]
[epoch 401/1000, batch 11/100 -> loss before: 0.2830045544020844, loss after: 0.2840574541395934]
[epoch 401/1000, batch 21/100 -> loss before: 0.19352997037358527, loss after: 0.19027622024626345]
[epoch 401/1000, batch 31/100 -> loss before: 0.24244941898070596, loss after: 0.24031438823872028]
[epoch 401/1000, batch 41/100 -> loss before: 0.12688722589646242, loss after: 0.1286112020668125]
[epoch 401/1000, batch 51/100 -> loss before: 0.35015590664108687, loss after: 0.346590212248439]
[epoch 401/1000, batch 61/100 -> loss before: 0.12271606214250311, loss after: 0.12184747398188267]
[epoch 401/1000, batch 71/100 -> loss before: 0.23747996244911146, loss after: 0.23674832837143384]
[epoch 401/1000, batch 81/100 -> loss before: 0.1687629851745171, loss after: 0.17015099694575544]
[epoch 401/1000, batch 91/100 -> loss before: 0.21895435551251494, loss after: 0.21801588112385667]
ENDING EPOCH 401/1000 [loss before: 0.1996449634685788, loss after: 0.20105761370454775; epoch time: 0.027965307235717773 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.19014138964169527, loss after: 0.19159218497846264]
[epoch 501/1000, batch 11/100 -> loss before: 0.1752749969914979, loss after: 0.17380816314378708]
[epoch 501/1000, batch 21/100 -> loss before: 0.13039581317802085, loss after: 0.1270909996980562]
[epoch 501/1000, batch 31/100 -> loss before: 0.13471197598745815, loss after: 0.13156002349653095]
[epoch 501/1000, batch 41/100 -> loss before: 0.2141475615070263, loss after: 0.20622770418238962]
[epoch 501/1000, batch 51/100 -> loss before: 0.10659281472151186, loss after: 0.09934894623881518]
[epoch 501/1000, batch 61/100 -> loss before: 0.12369832461411152, loss after: 0.11341085231282652]
[epoch 501/1000, batch 71/100 -> loss before: 0.26049257834502815, loss after: 0.2555951152228886]
[epoch 501/1000, batch 81/100 -> loss before: 0.26989105061223484, loss after: 0.267504916399054]
[epoch 501/1000, batch 91/100 -> loss before: 0.45135328667251784, loss after: 0.44045156042396816]
ENDING EPOCH 501/1000 [loss before: 0.1996488906630763, loss after: 0.1965904414959039; epoch time: 0.028535127639770508 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.17163501031126072, loss after: 0.17083288622005946]
[epoch 601/1000, batch 11/100 -> loss before: 0.19233986807505082, loss after: 0.1873497827856009]
[epoch 601/1000, batch 21/100 -> loss before: 0.28631887371618825, loss after: 0.2834979154900891]
[epoch 601/1000, batch 31/100 -> loss before: 0.09298188166433881, loss after: 0.09113255115489802]
[epoch 601/1000, batch 41/100 -> loss before: 0.10443085716241074, loss after: 0.10251020871543903]
[epoch 601/1000, batch 51/100 -> loss before: 0.18056200033928002, loss after: 0.18031037844388878]
[epoch 601/1000, batch 61/100 -> loss before: 0.2426630886574878, loss after: 0.2380007009536788]
[epoch 601/1000, batch 71/100 -> loss before: 0.1509708240817329, loss after: 0.14472111480137084]
[epoch 601/1000, batch 81/100 -> loss before: 0.03356770210984895, loss after: 0.033661795262833846]
[epoch 601/1000, batch 91/100 -> loss before: 0.05893851375046825, loss after: 0.05953178975293525]
ENDING EPOCH 601/1000 [loss before: 0.19365873362156247, loss after: 0.1906556089935086; epoch time: 0.027128219604492188 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.12490116041393703, loss after: 0.1259842030983839]
[epoch 701/1000, batch 11/100 -> loss before: 0.2311377472933233, loss after: 0.22871358081489274]
[epoch 701/1000, batch 21/100 -> loss before: 0.14484692831164997, loss after: 0.1441665151814593]
[epoch 701/1000, batch 31/100 -> loss before: 0.15781308240473108, loss after: 0.15566550007928098]
[epoch 701/1000, batch 41/100 -> loss before: 0.14107217049511792, loss after: 0.14063701650872837]
[epoch 701/1000, batch 51/100 -> loss before: 0.2889984782818951, loss after: 0.2849432595433169]
[epoch 701/1000, batch 61/100 -> loss before: 0.07084790558140205, loss after: 0.06987110713381348]
[epoch 701/1000, batch 71/100 -> loss before: 0.19062226900270227, loss after: 0.1883469899188548]
[epoch 701/1000, batch 81/100 -> loss before: 0.14239012119874822, loss after: 0.14157924634261157]
[epoch 701/1000, batch 91/100 -> loss before: 0.2837966809035618, loss after: 0.2833531135122576]
ENDING EPOCH 701/1000 [loss before: 0.18842866628257088, loss after: 0.1909173070038542; epoch time: 0.02838611602783203 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.35738327733815756, loss after: 0.3572288488326251]
[epoch 801/1000, batch 11/100 -> loss before: 0.18287944214784538, loss after: 0.1788393572638441]
[epoch 801/1000, batch 21/100 -> loss before: 0.3003242736805751, loss after: 0.2955243173061097]
[epoch 801/1000, batch 31/100 -> loss before: 0.08862821471901523, loss after: 0.0864017962011952]
[epoch 801/1000, batch 41/100 -> loss before: 0.18606337113784893, loss after: 0.1857439823384816]
[epoch 801/1000, batch 51/100 -> loss before: 0.2211773087650953, loss after: 0.21889182456018327]
[epoch 801/1000, batch 61/100 -> loss before: 0.23572701451830236, loss after: 0.23289375492495795]
[epoch 801/1000, batch 71/100 -> loss before: 0.11948069634956922, loss after: 0.11932970431504406]
[epoch 801/1000, batch 81/100 -> loss before: 0.18478274782302345, loss after: 0.18253597434762808]
[epoch 801/1000, batch 91/100 -> loss before: 0.12451448053723913, loss after: 0.12164794162357104]
ENDING EPOCH 801/1000 [loss before: 0.19640297019111272, loss after: 0.18998509431953936; epoch time: 0.028005361557006836 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.20906110609552417, loss after: 0.2095910703494074]
[epoch 901/1000, batch 11/100 -> loss before: 0.19804678966749434, loss after: 0.19048592964757158]
[epoch 901/1000, batch 21/100 -> loss before: 0.07776340649135842, loss after: 0.07853580419906563]
[epoch 901/1000, batch 31/100 -> loss before: 0.16975076566469355, loss after: 0.17214023836927572]
[epoch 901/1000, batch 41/100 -> loss before: 0.05650459270648987, loss after: 0.05716738085966518]
[epoch 901/1000, batch 51/100 -> loss before: 0.1985035404888819, loss after: 0.19795740528038835]
[epoch 901/1000, batch 61/100 -> loss before: 0.2741527635769416, loss after: 0.272103888149226]
[epoch 901/1000, batch 71/100 -> loss before: 0.10654860646200573, loss after: 0.10600690533761019]
[epoch 901/1000, batch 81/100 -> loss before: 0.243440064567166, loss after: 0.24181466574460836]
[epoch 901/1000, batch 91/100 -> loss before: 0.08556302062368688, loss after: 0.08507133725633195]
ENDING EPOCH 901/1000 [loss before: 0.1872342829544827, loss after: 0.1898054074453342; epoch time: 0.02375006675720215 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.09704661600769453, loss after: 0.09608177180566564]
[epoch 1000/1000, batch 11/100 -> loss before: 0.24418461587617174, loss after: 0.24219395499591223]
[epoch 1000/1000, batch 21/100 -> loss before: 0.20354203599754542, loss after: 0.2019011557014477]
[epoch 1000/1000, batch 31/100 -> loss before: 0.23527048918658916, loss after: 0.2320653439310119]
[epoch 1000/1000, batch 41/100 -> loss before: 0.22663402310361538, loss after: 0.2210122972027107]
[epoch 1000/1000, batch 51/100 -> loss before: 0.28034049951972634, loss after: 0.28019252590398225]
[epoch 1000/1000, batch 61/100 -> loss before: 0.10471765300769675, loss after: 0.10520603890632432]
[epoch 1000/1000, batch 71/100 -> loss before: 0.2430343579153714, loss after: 0.24320575862241106]
[epoch 1000/1000, batch 81/100 -> loss before: 0.2454606244513656, loss after: 0.23719920761500565]
[epoch 1000/1000, batch 91/100 -> loss before: 0.3166749602942889, loss after: 0.31123421275502683]
ENDING EPOCH 1000/1000 [loss before: 0.20042952175099754, loss after: 0.1864219885056941; epoch time: 0.025279998779296875 s]
FIT DONE. [time: 25.699628353118896 s]
LOSS TRAIN (MSE): 0.1864219885056941
LOSS TEST (MSE): 0.18959458044262714
R^2 TRAIN: 0.34144697060593543
R^2 TEST: 0.31685103867947784
EXPERIMENT DONE

EXPERIMENT 1111 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 64, 32], activation_name=sigmoid, targets_activation_name=linear, 
initialization_name=uniform, algo_name=sgd_simple, learning_rate=0.01, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 10753]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 1.6197437009973044, loss after: 1.0209674195582221]
[epoch 1/1000, batch 11/100 -> loss before: 0.2508367736055369, loss after: 0.19121832514898204]
[epoch 1/1000, batch 21/100 -> loss before: 0.07342549340148108, loss after: 0.07164665684610935]
[epoch 1/1000, batch 31/100 -> loss before: 0.4634120824678658, loss after: 0.44978132834987716]
[epoch 1/1000, batch 41/100 -> loss before: 0.18145827296655467, loss after: 0.16840806517202708]
[epoch 1/1000, batch 51/100 -> loss before: 0.31640250053471153, loss after: 0.24837981208525642]
[epoch 1/1000, batch 61/100 -> loss before: 0.5267545540904308, loss after: 0.4903143477090236]
[epoch 1/1000, batch 71/100 -> loss before: 0.4651135267096553, loss after: 0.3953293130749872]
[epoch 1/1000, batch 81/100 -> loss before: 0.15418611159733048, loss after: 0.14195365159375503]
[epoch 1/1000, batch 91/100 -> loss before: 0.39700743022901336, loss after: 0.39151127643538186]
ENDING EPOCH 1/1000 [loss before: 0.7227142221308361, loss after: 0.28341804775047835; epoch time: 0.02367424964904785 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.16840250489671144, loss after: 0.16651829622993675]
[epoch 101/1000, batch 11/100 -> loss before: 0.11426237115272053, loss after: 0.10945848624127334]
[epoch 101/1000, batch 21/100 -> loss before: 0.09846643854808262, loss after: 0.09623931551072806]
[epoch 101/1000, batch 31/100 -> loss before: 0.1839899919980797, loss after: 0.1838638368320889]
[epoch 101/1000, batch 41/100 -> loss before: 0.4336725854617803, loss after: 0.4256529560201646]
[epoch 101/1000, batch 51/100 -> loss before: 0.1798938125309022, loss after: 0.17975056011922041]
[epoch 101/1000, batch 61/100 -> loss before: 0.20488001459614585, loss after: 0.19791687054240553]
[epoch 101/1000, batch 71/100 -> loss before: 0.2485509698014711, loss after: 0.2477547207560135]
[epoch 101/1000, batch 81/100 -> loss before: 0.2810068977933312, loss after: 0.26290601773710304]
[epoch 101/1000, batch 91/100 -> loss before: 0.2794772425356217, loss after: 0.27810694666002844]
ENDING EPOCH 101/1000 [loss before: 0.23554032227066624, loss after: 0.23530129506240444; epoch time: 0.027624845504760742 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.19027279795025084, loss after: 0.1813585450401381]
[epoch 201/1000, batch 11/100 -> loss before: 0.17357510387404085, loss after: 0.15213670064816812]
[epoch 201/1000, batch 21/100 -> loss before: 0.1783026493686401, loss after: 0.1778650922989283]
[epoch 201/1000, batch 31/100 -> loss before: 0.21377467553586063, loss after: 0.2130586823342003]
[epoch 201/1000, batch 41/100 -> loss before: 0.38416641850569955, loss after: 0.38311864859412426]
[epoch 201/1000, batch 51/100 -> loss before: 0.3721665082931132, loss after: 0.3711733477944164]
[epoch 201/1000, batch 61/100 -> loss before: 0.27235735826966945, loss after: 0.2598959194525171]
[epoch 201/1000, batch 71/100 -> loss before: 0.13233980606391255, loss after: 0.11016352247168093]
[epoch 201/1000, batch 81/100 -> loss before: 0.11334637132973202, loss after: 0.10890732101256491]
[epoch 201/1000, batch 91/100 -> loss before: 0.09383632704558863, loss after: 0.09337250620011679]
ENDING EPOCH 201/1000 [loss before: 0.2340458735285947, loss after: 0.23319870814235935; epoch time: 0.024823904037475586 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.17436025251841597, loss after: 0.1740659006666788]
[epoch 301/1000, batch 11/100 -> loss before: 0.4579396955112215, loss after: 0.41459668944994366]
[epoch 301/1000, batch 21/100 -> loss before: 0.24957906411692427, loss after: 0.1869318284762423]
[epoch 301/1000, batch 31/100 -> loss before: 0.16180043348606407, loss after: 0.1609217889298298]
[epoch 301/1000, batch 41/100 -> loss before: 0.063050002573801, loss after: 0.06284150445450326]
[epoch 301/1000, batch 51/100 -> loss before: 0.266973152637768, loss after: 0.25920177714735326]
[epoch 301/1000, batch 61/100 -> loss before: 0.14127302198137537, loss after: 0.1405572474866506]
[epoch 301/1000, batch 71/100 -> loss before: 0.33613663824805123, loss after: 0.26628100791972364]
[epoch 301/1000, batch 81/100 -> loss before: 0.12561770975125158, loss after: 0.12409915601972052]
[epoch 301/1000, batch 91/100 -> loss before: 0.26051750266976736, loss after: 0.21198443863996155]
ENDING EPOCH 301/1000 [loss before: 0.23244407091628358, loss after: 0.23226655138507982; epoch time: 0.035646915435791016 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.40722136938209247, loss after: 0.40469155776759147]
[epoch 401/1000, batch 11/100 -> loss before: 0.3096797252386854, loss after: 0.3051165207626234]
[epoch 401/1000, batch 21/100 -> loss before: 0.18130219344030066, loss after: 0.17844357742225053]
[epoch 401/1000, batch 31/100 -> loss before: 0.37327718445670977, loss after: 0.32907044210260433]
[epoch 401/1000, batch 41/100 -> loss before: 0.1298081852402167, loss after: 0.12282154949751603]
[epoch 401/1000, batch 51/100 -> loss before: 0.353179547560149, loss after: 0.3503863723862508]
[epoch 401/1000, batch 61/100 -> loss before: 0.16289048931475994, loss after: 0.15130915885902874]
[epoch 401/1000, batch 71/100 -> loss before: 0.19037907485449307, loss after: 0.18098139354728512]
[epoch 401/1000, batch 81/100 -> loss before: 0.3206320760999294, loss after: 0.29673026176237843]
[epoch 401/1000, batch 91/100 -> loss before: 0.20563563429174864, loss after: 0.2042231073662621]
ENDING EPOCH 401/1000 [loss before: 0.2353585588628116, loss after: 0.239840202610819; epoch time: 0.025734424591064453 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.28318455935582665, loss after: 0.22936086224613267]
[epoch 501/1000, batch 11/100 -> loss before: 0.25202193883678203, loss after: 0.251640541257308]
[epoch 501/1000, batch 21/100 -> loss before: 0.12316028893950441, loss after: 0.12108592224144159]
[epoch 501/1000, batch 31/100 -> loss before: 0.1703735844525438, loss after: 0.16904186388256714]
[epoch 501/1000, batch 41/100 -> loss before: 0.17987922269173368, loss after: 0.17816022737603693]
[epoch 501/1000, batch 51/100 -> loss before: 0.17037325219688612, loss after: 0.15107262629098148]
[epoch 501/1000, batch 61/100 -> loss before: 0.11635154656796283, loss after: 0.10568903357792045]
[epoch 501/1000, batch 71/100 -> loss before: 0.2058379225006429, loss after: 0.20483523312595547]
[epoch 501/1000, batch 81/100 -> loss before: 0.23238841351089562, loss after: 0.23182171895619336]
[epoch 501/1000, batch 91/100 -> loss before: 0.38735143560539914, loss after: 0.3618685136831162]
ENDING EPOCH 501/1000 [loss before: 0.2384191443456018, loss after: 0.2293984706286825; epoch time: 0.023569822311401367 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.23248771760252446, loss after: 0.22259492817662063]
[epoch 601/1000, batch 11/100 -> loss before: 0.1418745970336144, loss after: 0.14148164057005605]
[epoch 601/1000, batch 21/100 -> loss before: 0.42062368439875836, loss after: 0.4120429251702489]
[epoch 601/1000, batch 31/100 -> loss before: 0.0718295919663413, loss after: 0.06968264168256957]
[epoch 601/1000, batch 41/100 -> loss before: 0.12744294733312161, loss after: 0.10591827194092085]
[epoch 601/1000, batch 51/100 -> loss before: 0.326013835683884, loss after: 0.2886897533527796]
[epoch 601/1000, batch 61/100 -> loss before: 0.3292759307448246, loss after: 0.3209077226398744]
[epoch 601/1000, batch 71/100 -> loss before: 0.3214338630211756, loss after: 0.3087811991250739]
[epoch 601/1000, batch 81/100 -> loss before: 0.07328491827256879, loss after: 0.06249046317198649]
[epoch 601/1000, batch 91/100 -> loss before: 0.08413429302647482, loss after: 0.07973577749983374]
ENDING EPOCH 601/1000 [loss before: 0.21618777671375125, loss after: 0.2123206454468467; epoch time: 0.024460792541503906 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.14538556764684127, loss after: 0.1318678041736449]
[epoch 701/1000, batch 11/100 -> loss before: 0.18771411897124265, loss after: 0.14687980146571294]
[epoch 701/1000, batch 21/100 -> loss before: 0.08245053119740875, loss after: 0.07170741251936462]
[epoch 701/1000, batch 31/100 -> loss before: 0.09751368803472821, loss after: 0.08450012244716286]
[epoch 701/1000, batch 41/100 -> loss before: 0.13630069337586537, loss after: 0.11361673225581723]
[epoch 701/1000, batch 51/100 -> loss before: 0.1937688877466203, loss after: 0.17367621565274688]
[epoch 701/1000, batch 61/100 -> loss before: 0.06219408585933863, loss after: 0.05287896476789352]
[epoch 701/1000, batch 71/100 -> loss before: 0.08199345052171393, loss after: 0.06397570614917172]
[epoch 701/1000, batch 81/100 -> loss before: 0.2646761817226454, loss after: 0.24314368400047565]
[epoch 701/1000, batch 91/100 -> loss before: 0.23530703957936372, loss after: 0.23162754795257762]
ENDING EPOCH 701/1000 [loss before: 0.17116105364976966, loss after: 0.1690286571915047; epoch time: 0.021986007690429688 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.5722450157593193, loss after: 0.3589175546833391]
[epoch 801/1000, batch 11/100 -> loss before: 0.14954258038896118, loss after: 0.11292203685515792]
[epoch 801/1000, batch 21/100 -> loss before: 0.19452266718034908, loss after: 0.1283903548902589]
[epoch 801/1000, batch 31/100 -> loss before: 0.07095479391562823, loss after: 0.06120748598027972]
[epoch 801/1000, batch 41/100 -> loss before: 0.06280498480637216, loss after: 0.05625441197361912]
[epoch 801/1000, batch 51/100 -> loss before: 0.21621162680719047, loss after: 0.19854493466630352]
[epoch 801/1000, batch 61/100 -> loss before: 0.10276942875378878, loss after: 0.0770545630607402]
[epoch 801/1000, batch 71/100 -> loss before: 0.022009833405662677, loss after: 0.005771745329468454]
[epoch 801/1000, batch 81/100 -> loss before: 0.12806684210047067, loss after: 0.11823914311990043]
[epoch 801/1000, batch 91/100 -> loss before: 0.03137184878034664, loss after: 0.01879877895132784]
ENDING EPOCH 801/1000 [loss before: 0.17515071655811457, loss after: 0.15785544638647422; epoch time: 0.02381110191345215 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.09486015903739506, loss after: 0.060428768036842696]
[epoch 901/1000, batch 11/100 -> loss before: 0.17739056094389416, loss after: 0.11179225834614859]
[epoch 901/1000, batch 21/100 -> loss before: 0.10020483713943855, loss after: 0.04807027603471888]
[epoch 901/1000, batch 31/100 -> loss before: 0.14980567458617963, loss after: 0.12881035793161208]
[epoch 901/1000, batch 41/100 -> loss before: 0.01406038603144483, loss after: 0.01004987013701494]
[epoch 901/1000, batch 51/100 -> loss before: 0.1964052576268184, loss after: 0.14809874223851627]
[epoch 901/1000, batch 61/100 -> loss before: 0.1893083417503691, loss after: 0.1780646075617192]
[epoch 901/1000, batch 71/100 -> loss before: 0.08046437141816896, loss after: 0.06768535749176594]
[epoch 901/1000, batch 81/100 -> loss before: 0.09551908025701722, loss after: 0.05484762680333437]
[epoch 901/1000, batch 91/100 -> loss before: 0.03256142315410033, loss after: 0.030397897599013218]
ENDING EPOCH 901/1000 [loss before: 0.12722160175259156, loss after: 0.12541657237756731; epoch time: 0.02273845672607422 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.05848327895867413, loss after: 0.02068074960621885]
[epoch 1000/1000, batch 11/100 -> loss before: 0.01672246786166494, loss after: 0.012990337570148471]
[epoch 1000/1000, batch 21/100 -> loss before: 0.1464654977231604, loss after: 0.12212709943954418]
[epoch 1000/1000, batch 31/100 -> loss before: 0.08299465215847417, loss after: 0.07096553666219983]
[epoch 1000/1000, batch 41/100 -> loss before: 0.1682196371273204, loss after: 0.16340072556583357]
[epoch 1000/1000, batch 51/100 -> loss before: 0.1426486994792996, loss after: 0.1251011807123183]
[epoch 1000/1000, batch 61/100 -> loss before: 0.20800202899913728, loss after: 0.1441429381311718]
[epoch 1000/1000, batch 71/100 -> loss before: 0.11629970815651638, loss after: 0.054448519000951115]
[epoch 1000/1000, batch 81/100 -> loss before: 0.19394519394946594, loss after: 0.18400734182251538]
[epoch 1000/1000, batch 91/100 -> loss before: 0.25482551421018546, loss after: 0.19143935897795444]
ENDING EPOCH 1000/1000 [loss before: 0.11166341793140866, loss after: 0.11550539336730856; epoch time: 0.024506330490112305 s]
FIT DONE. [time: 21.14551091194153 s]
LOSS TRAIN (MSE): 0.11550539336730856
LOSS TEST (MSE): 0.11835871167474978
R^2 TRAIN: 0.5919664449289428
R^2 TEST: 0.5735287857117396
EXPERIMENT DONE

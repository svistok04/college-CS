EXPERIMENT 3222 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 128, 64, 64, 32, 32], activation_name=relu, targets_activation_name=linear, 
initialization_name=uniform, algo_name=sgd_momentum, learning_rate=0.0001, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 32481]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 0.87553713426397, loss after: 0.7623820562456679]
[epoch 1/1000, batch 11/100 -> loss before: 0.2387202586992599, loss after: 0.12535403275519102]
[epoch 1/1000, batch 21/100 -> loss before: 0.6623114620501336, loss after: 0.5911956233515191]
[epoch 1/1000, batch 31/100 -> loss before: 0.46718859645287847, loss after: 0.4112030956740121]
[epoch 1/1000, batch 41/100 -> loss before: 0.4496548619751913, loss after: 0.4104779799026531]
[epoch 1/1000, batch 51/100 -> loss before: 0.09162401896162944, loss after: 0.08674915664842617]
[epoch 1/1000, batch 61/100 -> loss before: 0.2538743533566644, loss after: 0.23048614756642247]
[epoch 1/1000, batch 71/100 -> loss before: 0.5623785615681192, loss after: 0.54654202749399]
[epoch 1/1000, batch 81/100 -> loss before: 0.3738662070172788, loss after: 0.361433484425027]
[epoch 1/1000, batch 91/100 -> loss before: 0.33105356001360675, loss after: 0.3086133076076616]
ENDING EPOCH 1/1000 [loss before: 1.102092538201909, loss after: 0.3420259654358587; epoch time: 0.04815959930419922 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.21845265391548568, loss after: 0.21487163691751726]
[epoch 101/1000, batch 11/100 -> loss before: 0.26532338607586053, loss after: 0.2536166134354748]
[epoch 101/1000, batch 21/100 -> loss before: 0.20115175094956564, loss after: 0.19182178177688552]
[epoch 101/1000, batch 31/100 -> loss before: 0.12138100530190592, loss after: 0.12081778131403768]
[epoch 101/1000, batch 41/100 -> loss before: 0.14255332880964292, loss after: 0.1511566775335362]
[epoch 101/1000, batch 51/100 -> loss before: 0.07603163372537916, loss after: 0.07389360791187082]
[epoch 101/1000, batch 61/100 -> loss before: 0.07950276216051572, loss after: 0.08039361231462805]
[epoch 101/1000, batch 71/100 -> loss before: 0.30058072442328865, loss after: 0.2975044126386098]
[epoch 101/1000, batch 81/100 -> loss before: 0.23741480851071084, loss after: 0.23373979318323812]
[epoch 101/1000, batch 91/100 -> loss before: 0.24218477093768573, loss after: 0.24491526756510465]
ENDING EPOCH 101/1000 [loss before: 0.20136929886365085, loss after: 0.21297217659224596; epoch time: 0.0518338680267334 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.4337180856728967, loss after: 0.432226786879376]
[epoch 201/1000, batch 11/100 -> loss before: 0.3479483381511582, loss after: 0.3402087091650194]
[epoch 201/1000, batch 21/100 -> loss before: 0.31284484024909065, loss after: 0.2607423303028435]
[epoch 201/1000, batch 31/100 -> loss before: 0.19515708176737007, loss after: 0.18123270485781182]
[epoch 201/1000, batch 41/100 -> loss before: 0.18090264249443755, loss after: 0.16769824701921943]
[epoch 201/1000, batch 51/100 -> loss before: 0.3163300349266638, loss after: 0.3156415675398178]
[epoch 201/1000, batch 61/100 -> loss before: 0.18862566496660227, loss after: 0.18728542269906892]
[epoch 201/1000, batch 71/100 -> loss before: 0.09139662147511654, loss after: 0.09183052244870468]
[epoch 201/1000, batch 81/100 -> loss before: 0.3470789570939602, loss after: 0.3330037228880628]
[epoch 201/1000, batch 91/100 -> loss before: 0.17134172576208517, loss after: 0.165793932586416]
ENDING EPOCH 201/1000 [loss before: 0.18504475380675314, loss after: 0.1903518536619037; epoch time: 0.04918265342712402 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.08735131860049912, loss after: 0.08479553019713851]
[epoch 301/1000, batch 11/100 -> loss before: 0.049441267995618945, loss after: 0.04876355353877501]
[epoch 301/1000, batch 21/100 -> loss before: 0.12854077955501014, loss after: 0.12205364583331561]
[epoch 301/1000, batch 31/100 -> loss before: 0.17281630940244028, loss after: 0.16881393116642235]
[epoch 301/1000, batch 41/100 -> loss before: 0.30223202295957186, loss after: 0.2977863557273094]
[epoch 301/1000, batch 51/100 -> loss before: 0.16187228320997737, loss after: 0.1600769751233547]
[epoch 301/1000, batch 61/100 -> loss before: 0.16124832788508864, loss after: 0.1585205255821505]
[epoch 301/1000, batch 71/100 -> loss before: 0.0628220825917086, loss after: 0.0623504690523341]
[epoch 301/1000, batch 81/100 -> loss before: 0.059046850313549726, loss after: 0.05594197436081476]
[epoch 301/1000, batch 91/100 -> loss before: 0.18881595063593776, loss after: 0.17435712669248046]
ENDING EPOCH 301/1000 [loss before: 0.18055141663780147, loss after: 0.1908696404118482; epoch time: 0.0501401424407959 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.3505262932949112, loss after: 0.3491324937016239]
[epoch 401/1000, batch 11/100 -> loss before: 0.21987748048290343, loss after: 0.2206106796535777]
[epoch 401/1000, batch 21/100 -> loss before: 0.08219232482548652, loss after: 0.07954758553054139]
[epoch 401/1000, batch 31/100 -> loss before: 0.09655514874677952, loss after: 0.09409007092418016]
[epoch 401/1000, batch 41/100 -> loss before: 0.18243529368779876, loss after: 0.18060276712751655]
[epoch 401/1000, batch 51/100 -> loss before: 0.28287846675216055, loss after: 0.2741049994584782]
[epoch 401/1000, batch 61/100 -> loss before: 0.12395624949536646, loss after: 0.1237087054832932]
[epoch 401/1000, batch 71/100 -> loss before: 0.19518520728200317, loss after: 0.19266150776471874]
[epoch 401/1000, batch 81/100 -> loss before: 0.400370052799415, loss after: 0.39326920479985206]
[epoch 401/1000, batch 91/100 -> loss before: 0.13507782698337198, loss after: 0.13347142915779506]
ENDING EPOCH 401/1000 [loss before: 0.17490762908018717, loss after: 0.16917441144884457; epoch time: 0.04810452461242676 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.08555863016924303, loss after: 0.0839447154746095]
[epoch 501/1000, batch 11/100 -> loss before: 0.16924543228238328, loss after: 0.16768301075993602]
[epoch 501/1000, batch 21/100 -> loss before: 0.29310108090685116, loss after: 0.2887753956754547]
[epoch 501/1000, batch 31/100 -> loss before: 0.08778645974910491, loss after: 0.08560242528742322]
[epoch 501/1000, batch 41/100 -> loss before: 0.1925435970688868, loss after: 0.18083343189782491]
[epoch 501/1000, batch 51/100 -> loss before: 0.18497605281970486, loss after: 0.18308309744835555]
[epoch 501/1000, batch 61/100 -> loss before: 0.15159660413190287, loss after: 0.14269428520477828]
[epoch 501/1000, batch 71/100 -> loss before: 0.11187471232639061, loss after: 0.10600500859718305]
[epoch 501/1000, batch 81/100 -> loss before: 0.359493644372342, loss after: 0.35352723298487376]
[epoch 501/1000, batch 91/100 -> loss before: 0.20855907779522193, loss after: 0.19549501710866793]
ENDING EPOCH 501/1000 [loss before: 0.15305131617966306, loss after: 0.15845041199186422; epoch time: 0.0621943473815918 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.06515738156689245, loss after: 0.06437599968470764]
[epoch 601/1000, batch 11/100 -> loss before: 0.15014198106988397, loss after: 0.14076981096928817]
[epoch 601/1000, batch 21/100 -> loss before: 0.2427465292936773, loss after: 0.22769528855405502]
[epoch 601/1000, batch 31/100 -> loss before: 0.1084711339747296, loss after: 0.10993297918778522]
[epoch 601/1000, batch 41/100 -> loss before: 0.17337668955102398, loss after: 0.17626871066240715]
[epoch 601/1000, batch 51/100 -> loss before: 0.16085459221018886, loss after: 0.15567431956082484]
[epoch 601/1000, batch 61/100 -> loss before: 0.15672358952276905, loss after: 0.1552407426502254]
[epoch 601/1000, batch 71/100 -> loss before: 0.1458338170762058, loss after: 0.14413245438808814]
[epoch 601/1000, batch 81/100 -> loss before: 0.19859296330806392, loss after: 0.1977769485568758]
[epoch 601/1000, batch 91/100 -> loss before: 0.29314247537725235, loss after: 0.2789292074298927]
ENDING EPOCH 601/1000 [loss before: 0.14226653032567077, loss after: 0.13658265287122265; epoch time: 0.05034804344177246 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.18492309681989155, loss after: 0.18650508040248137]
[epoch 701/1000, batch 11/100 -> loss before: 0.08665994226656361, loss after: 0.08425945776614964]
[epoch 701/1000, batch 21/100 -> loss before: 0.1424689347865959, loss after: 0.1363782221361987]
[epoch 701/1000, batch 31/100 -> loss before: 0.17427024552277642, loss after: 0.1697145705527304]
[epoch 701/1000, batch 41/100 -> loss before: 0.051642601127512455, loss after: 0.04641779173804715]
[epoch 701/1000, batch 51/100 -> loss before: 0.09080018171256007, loss after: 0.09199339362703884]
[epoch 701/1000, batch 61/100 -> loss before: 0.08415835509646757, loss after: 0.07974505868190865]
[epoch 701/1000, batch 71/100 -> loss before: 0.08254952442107345, loss after: 0.08007188627876623]
[epoch 701/1000, batch 81/100 -> loss before: 0.08787847907294177, loss after: 0.08236259921151291]
[epoch 701/1000, batch 91/100 -> loss before: 0.1668450619521875, loss after: 0.14926823299379488]
ENDING EPOCH 701/1000 [loss before: 0.12491643082950872, loss after: 0.12711578696183867; epoch time: 0.049506187438964844 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.013149795273649909, loss after: 0.016982724087205987]
[epoch 801/1000, batch 11/100 -> loss before: 0.03950490673392747, loss after: 0.04258233459816992]
[epoch 801/1000, batch 21/100 -> loss before: 0.039757393261091976, loss after: 0.036828873507474005]
[epoch 801/1000, batch 31/100 -> loss before: 0.08073091663324125, loss after: 0.08008484077626744]
[epoch 801/1000, batch 41/100 -> loss before: 0.22373177938078972, loss after: 0.2235923486001868]
[epoch 801/1000, batch 51/100 -> loss before: 0.24297602602454157, loss after: 0.23519375588695465]
[epoch 801/1000, batch 61/100 -> loss before: 0.1045370993627645, loss after: 0.10298351947281548]
[epoch 801/1000, batch 71/100 -> loss before: 0.16168728052456194, loss after: 0.16093442720617848]
[epoch 801/1000, batch 81/100 -> loss before: 0.07933020271791272, loss after: 0.0779866560942182]
[epoch 801/1000, batch 91/100 -> loss before: 0.18698057127031553, loss after: 0.1848798500039581]
ENDING EPOCH 801/1000 [loss before: 0.1093096845135431, loss after: 0.10482026725661865; epoch time: 0.06131553649902344 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.10045201470714349, loss after: 0.09085025620020158]
[epoch 901/1000, batch 11/100 -> loss before: 0.0845565717742144, loss after: 0.08500028427405694]
[epoch 901/1000, batch 21/100 -> loss before: 0.06166437882042066, loss after: 0.061818447174995864]
[epoch 901/1000, batch 31/100 -> loss before: 0.08170887734765722, loss after: 0.07803190573855845]
[epoch 901/1000, batch 41/100 -> loss before: 0.10786180958430436, loss after: 0.1098388929085569]
[epoch 901/1000, batch 51/100 -> loss before: 0.20426784634634446, loss after: 0.1937375186882278]
[epoch 901/1000, batch 61/100 -> loss before: 0.1434224276109232, loss after: 0.14200378965605964]
[epoch 901/1000, batch 71/100 -> loss before: 0.13828305542226915, loss after: 0.10565191167879555]
[epoch 901/1000, batch 81/100 -> loss before: 0.10288748479736429, loss after: 0.10213456863291878]
[epoch 901/1000, batch 91/100 -> loss before: 0.17840253102839587, loss after: 0.1736004216715869]
ENDING EPOCH 901/1000 [loss before: 0.11303278011608235, loss after: 0.10766985754987976; epoch time: 0.0517125129699707 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.12596774175976316, loss after: 0.12448228310768095]
[epoch 1000/1000, batch 11/100 -> loss before: 0.08041137969071199, loss after: 0.07622459994450057]
[epoch 1000/1000, batch 21/100 -> loss before: 0.0701578512364743, loss after: 0.06853588042094963]
[epoch 1000/1000, batch 31/100 -> loss before: 0.13149423660708592, loss after: 0.13132407319036568]
[epoch 1000/1000, batch 41/100 -> loss before: 0.055005205783894076, loss after: 0.0495451557263978]
[epoch 1000/1000, batch 51/100 -> loss before: 0.10628626605101141, loss after: 0.10708096676970721]
[epoch 1000/1000, batch 61/100 -> loss before: 0.05647118138129357, loss after: 0.05542741997546391]
[epoch 1000/1000, batch 71/100 -> loss before: 0.03693519634940633, loss after: 0.03435173340793617]
[epoch 1000/1000, batch 81/100 -> loss before: 0.13180015357514605, loss after: 0.12628089202449028]
[epoch 1000/1000, batch 91/100 -> loss before: 0.19817934948707072, loss after: 0.18930518679260253]
ENDING EPOCH 1000/1000 [loss before: 0.1059959557205735, loss after: 0.09439119735264433; epoch time: 0.05520796775817871 s]
FIT DONE. [time: 48.43831539154053 s]
LOSS TRAIN (MSE): 0.09439119735264433
LOSS TEST (MSE): 0.10027511671442586
R^2 TRAIN: 0.666554307981656
R^2 TEST: 0.6386877638072378
EXPERIMENT DONE

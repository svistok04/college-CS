EXPERIMENT 1112 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 128, 64, 64, 32, 32], activation_name=sigmoid, targets_activation_name=linear, 
initialization_name=uniform, algo_name=sgd_simple, learning_rate=0.01, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 32481]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 0.26392389365226554, loss after: 0.26387463862145666]
[epoch 1/1000, batch 11/100 -> loss before: 0.5379405505003909, loss after: 0.21916936110147534]
[epoch 1/1000, batch 21/100 -> loss before: 0.26279632223772087, loss after: 0.26128458927390763]
[epoch 1/1000, batch 31/100 -> loss before: 0.3817129189205338, loss after: 0.34604321851903486]
[epoch 1/1000, batch 41/100 -> loss before: 0.3479758303639608, loss after: 0.291632658418392]
[epoch 1/1000, batch 51/100 -> loss before: 0.12828972822038126, loss after: 0.09989607522251356]
[epoch 1/1000, batch 61/100 -> loss before: 0.30514677858814704, loss after: 0.22353773174107502]
[epoch 1/1000, batch 71/100 -> loss before: 0.3237267059267458, loss after: 0.32369298240974353]
[epoch 1/1000, batch 81/100 -> loss before: 0.3981956293193331, loss after: 0.37883819786090217]
[epoch 1/1000, batch 91/100 -> loss before: 0.3937732359486923, loss after: 0.32086649529980754]
ENDING EPOCH 1/1000 [loss before: 0.2838936199301506, loss after: 0.3391274767369877; epoch time: 0.05113387107849121 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.3099044117485602, loss after: 0.2737174790531487]
[epoch 101/1000, batch 11/100 -> loss before: 0.2436296519890541, loss after: 0.2431973194876142]
[epoch 101/1000, batch 21/100 -> loss before: 0.2810639121670727, loss after: 0.27928011070714975]
[epoch 101/1000, batch 31/100 -> loss before: 0.14349947600942403, loss after: 0.1423109966570063]
[epoch 101/1000, batch 41/100 -> loss before: 0.3698987212613581, loss after: 0.36926869434129533]
[epoch 101/1000, batch 51/100 -> loss before: 0.16692199063951935, loss after: 0.16435117821101783]
[epoch 101/1000, batch 61/100 -> loss before: 0.16598230098646088, loss after: 0.16467086614539]
[epoch 101/1000, batch 71/100 -> loss before: 0.3827109530042546, loss after: 0.3597671691437488]
[epoch 101/1000, batch 81/100 -> loss before: 0.39500102197603254, loss after: 0.2881000009562422]
[epoch 101/1000, batch 91/100 -> loss before: 0.36073757045542376, loss after: 0.3593212310224107]
ENDING EPOCH 101/1000 [loss before: 0.28309283776751343, loss after: 0.2835373667800306; epoch time: 0.04994916915893555 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.5784941052277881, loss after: 0.5626207080888517]
[epoch 201/1000, batch 11/100 -> loss before: 0.45855054039635135, loss after: 0.45821577751276815]
[epoch 201/1000, batch 21/100 -> loss before: 0.3625299647661746, loss after: 0.2952523568134595]
[epoch 201/1000, batch 31/100 -> loss before: 0.2812682041175153, loss after: 0.2774926458240011]
[epoch 201/1000, batch 41/100 -> loss before: 0.2617127083899699, loss after: 0.23373642345421777]
[epoch 201/1000, batch 51/100 -> loss before: 0.3869463050765353, loss after: 0.3868683079016921]
[epoch 201/1000, batch 61/100 -> loss before: 0.3190498738424108, loss after: 0.3059872953437011]
[epoch 201/1000, batch 71/100 -> loss before: 0.18638629052064196, loss after: 0.1794879410545222]
[epoch 201/1000, batch 81/100 -> loss before: 0.2690651607145007, loss after: 0.2537846259846622]
[epoch 201/1000, batch 91/100 -> loss before: 0.4544106229744285, loss after: 0.4459565376356764]
ENDING EPOCH 201/1000 [loss before: 0.2838543338880657, loss after: 0.2870812552958266; epoch time: 0.057306766510009766 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.14720529969632484, loss after: 0.14651780179368856]
[epoch 301/1000, batch 11/100 -> loss before: 0.10059862560840842, loss after: 0.09931618789242817]
[epoch 301/1000, batch 21/100 -> loss before: 0.4147894278130992, loss after: 0.3778869554328358]
[epoch 301/1000, batch 31/100 -> loss before: 0.2814212321375908, loss after: 0.2788104662086156]
[epoch 301/1000, batch 41/100 -> loss before: 0.32773944146092937, loss after: 0.32703283124673493]
[epoch 301/1000, batch 51/100 -> loss before: 0.3210845022567257, loss after: 0.31345551776707714]
[epoch 301/1000, batch 61/100 -> loss before: 0.17550046429015603, loss after: 0.17533412387077715]
[epoch 301/1000, batch 71/100 -> loss before: 0.17870133146993497, loss after: 0.17855426067222208]
[epoch 301/1000, batch 81/100 -> loss before: 0.27077646419810086, loss after: 0.2540227037274144]
[epoch 301/1000, batch 91/100 -> loss before: 0.3659841061924112, loss after: 0.33689405366475056]
ENDING EPOCH 301/1000 [loss before: 0.2842132429899628, loss after: 0.2866285465075571; epoch time: 0.06046104431152344 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.5291096864304787, loss after: 0.5042555357709076]
[epoch 401/1000, batch 11/100 -> loss before: 0.241977295918849, loss after: 0.24046052817121097]
[epoch 401/1000, batch 21/100 -> loss before: 0.1967366085826584, loss after: 0.16784354431302775]
[epoch 401/1000, batch 31/100 -> loss before: 0.2885432945383484, loss after: 0.2876861101278533]
[epoch 401/1000, batch 41/100 -> loss before: 0.20689255139281829, loss after: 0.20353277022906138]
[epoch 401/1000, batch 51/100 -> loss before: 0.303911221925396, loss after: 0.2993103014584978]
[epoch 401/1000, batch 61/100 -> loss before: 0.2821095470110674, loss after: 0.2820206863679152]
[epoch 401/1000, batch 71/100 -> loss before: 0.3037714022049932, loss after: 0.25880901840125137]
[epoch 401/1000, batch 81/100 -> loss before: 0.44353916863701964, loss after: 0.41869752903203655]
[epoch 401/1000, batch 91/100 -> loss before: 0.1548991121026843, loss after: 0.1541869158218127]
ENDING EPOCH 401/1000 [loss before: 0.2852710932363634, loss after: 0.2845122978551695; epoch time: 0.056761980056762695 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.28883727007528426, loss after: 0.27806044846585537]
[epoch 501/1000, batch 11/100 -> loss before: 0.39810221061392326, loss after: 0.3955076669948622]
[epoch 501/1000, batch 21/100 -> loss before: 0.6413456735735109, loss after: 0.6230987007240596]
[epoch 501/1000, batch 31/100 -> loss before: 0.11824106375995962, loss after: 0.11589637253972089]
[epoch 501/1000, batch 41/100 -> loss before: 0.2832879488737629, loss after: 0.23275975883423014]
[epoch 501/1000, batch 51/100 -> loss before: 0.21358357382197785, loss after: 0.20994301770621843]
[epoch 501/1000, batch 61/100 -> loss before: 0.49774984069194667, loss after: 0.4708779244498073]
[epoch 501/1000, batch 71/100 -> loss before: 0.2634734003159675, loss after: 0.2613507369355247]
[epoch 501/1000, batch 81/100 -> loss before: 0.5044914200948148, loss after: 0.5044036729935277]
[epoch 501/1000, batch 91/100 -> loss before: 0.2815649157217889, loss after: 0.2735404874848363]
ENDING EPOCH 501/1000 [loss before: 0.2831047425451324, loss after: 0.28724867291388556; epoch time: 0.047472476959228516 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.2697628498485283, loss after: 0.2686926770960091]
[epoch 601/1000, batch 11/100 -> loss before: 0.3857054920752675, loss after: 0.34011805155047065]
[epoch 601/1000, batch 21/100 -> loss before: 0.6070279375487869, loss after: 0.6043967380063484]
[epoch 601/1000, batch 31/100 -> loss before: 0.1505774335920477, loss after: 0.14179103584046182]
[epoch 601/1000, batch 41/100 -> loss before: 0.34936680165978173, loss after: 0.3486471310795133]
[epoch 601/1000, batch 51/100 -> loss before: 0.3108236383380982, loss after: 0.3086734218852707]
[epoch 601/1000, batch 61/100 -> loss before: 0.16769874212009434, loss after: 0.16456145021169688]
[epoch 601/1000, batch 71/100 -> loss before: 0.21808477099914536, loss after: 0.21043429553273607]
[epoch 601/1000, batch 81/100 -> loss before: 0.3129202644459882, loss after: 0.307598153531201]
[epoch 601/1000, batch 91/100 -> loss before: 0.5305160000881498, loss after: 0.5229182266403616]
ENDING EPOCH 601/1000 [loss before: 0.2842202413621866, loss after: 0.2915110554395263; epoch time: 0.06254458427429199 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.2964542687381578, loss after: 0.25821693135039325]
[epoch 701/1000, batch 11/100 -> loss before: 0.38044624781034575, loss after: 0.37668433875136426]
[epoch 701/1000, batch 21/100 -> loss before: 0.34562343123407435, loss after: 0.3109416882890591]
[epoch 701/1000, batch 31/100 -> loss before: 0.25830733298091635, loss after: 0.25627140149754457]
[epoch 701/1000, batch 41/100 -> loss before: 0.14644222486867675, loss after: 0.1336705113196218]
[epoch 701/1000, batch 51/100 -> loss before: 0.30271285490443, loss after: 0.29571605151384184]
[epoch 701/1000, batch 61/100 -> loss before: 0.31499347538144185, loss after: 0.31480774347788076]
[epoch 701/1000, batch 71/100 -> loss before: 0.09360851892546986, loss after: 0.09208390356127966]
[epoch 701/1000, batch 81/100 -> loss before: 0.31389921177328783, loss after: 0.30487718372922806]
[epoch 701/1000, batch 91/100 -> loss before: 0.3352644966816303, loss after: 0.3117730436197486]
ENDING EPOCH 701/1000 [loss before: 0.30196557191656936, loss after: 0.28357231842220904; epoch time: 0.049942970275878906 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.254570532646733, loss after: 0.251107162246358]
[epoch 801/1000, batch 11/100 -> loss before: 0.3011103430892131, loss after: 0.2996426381544399]
[epoch 801/1000, batch 21/100 -> loss before: 0.22958315362626697, loss after: 0.19055263277162476]
[epoch 801/1000, batch 31/100 -> loss before: 0.16970562334228442, loss after: 0.1662031229029179]
[epoch 801/1000, batch 41/100 -> loss before: 0.2666680389682, loss after: 0.2621220133150621]
[epoch 801/1000, batch 51/100 -> loss before: 0.2166882052320338, loss after: 0.20796925759343649]
[epoch 801/1000, batch 61/100 -> loss before: 0.371455976761903, loss after: 0.36906045760230544]
[epoch 801/1000, batch 71/100 -> loss before: 0.2957911840899782, loss after: 0.2837300074362909]
[epoch 801/1000, batch 81/100 -> loss before: 0.193795153430753, loss after: 0.17470644496852603]
[epoch 801/1000, batch 91/100 -> loss before: 0.32957390097764777, loss after: 0.32951743654872073]
ENDING EPOCH 801/1000 [loss before: 0.28655266566466375, loss after: 0.28352218758205183; epoch time: 0.05635476112365723 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.21725057686580923, loss after: 0.20603746371966586]
[epoch 901/1000, batch 11/100 -> loss before: 0.28864521357121276, loss after: 0.2882638188538258]
[epoch 901/1000, batch 21/100 -> loss before: 0.13263409799149006, loss after: 0.11617411039427869]
[epoch 901/1000, batch 31/100 -> loss before: 0.2081608939421426, loss after: 0.19204193807883813]
[epoch 901/1000, batch 41/100 -> loss before: 0.29623402279935884, loss after: 0.29522508096812006]
[epoch 901/1000, batch 51/100 -> loss before: 0.29452028500958155, loss after: 0.2924745363700826]
[epoch 901/1000, batch 61/100 -> loss before: 0.31231057916661775, loss after: 0.31228198603809676]
[epoch 901/1000, batch 71/100 -> loss before: 0.4044282485305729, loss after: 0.38033492423279314]
[epoch 901/1000, batch 81/100 -> loss before: 0.21081796623500862, loss after: 0.17928358748098244]
[epoch 901/1000, batch 91/100 -> loss before: 0.5082488075100369, loss after: 0.4274494359311971]
ENDING EPOCH 901/1000 [loss before: 0.28466618790211806, loss after: 0.2886675186852928; epoch time: 0.06402254104614258 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.36357435899811347, loss after: 0.3611180326562322]
[epoch 1000/1000, batch 11/100 -> loss before: 0.2832543967644651, loss after: 0.2485753744914463]
[epoch 1000/1000, batch 21/100 -> loss before: 0.23486047731313126, loss after: 0.19955765653018806]
[epoch 1000/1000, batch 31/100 -> loss before: 0.3456390062668946, loss after: 0.3438643694926372]
[epoch 1000/1000, batch 41/100 -> loss before: 0.2891853535623764, loss after: 0.27200431611987486]
[epoch 1000/1000, batch 51/100 -> loss before: 0.19824590621228558, loss after: 0.19824077668960927]
[epoch 1000/1000, batch 61/100 -> loss before: 0.2356210276346066, loss after: 0.2208574630000893]
[epoch 1000/1000, batch 71/100 -> loss before: 0.24112775182486393, loss after: 0.23886140914431947]
[epoch 1000/1000, batch 81/100 -> loss before: 0.3752780629328838, loss after: 0.3402870817235988]
[epoch 1000/1000, batch 91/100 -> loss before: 0.42345345291035724, loss after: 0.40806147009947463]
ENDING EPOCH 1000/1000 [loss before: 0.30090527020555774, loss after: 0.2834683103964055; epoch time: 0.08041262626647949 s]
FIT DONE. [time: 45.81215262413025 s]
LOSS TRAIN (MSE): 0.2834683103964055
LOSS TEST (MSE): 0.2785784900014988
R^2 TRAIN: -0.0013781960225571765
R^2 TEST: -0.0037766145343638424
EXPERIMENT DONE

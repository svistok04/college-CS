EXPERIMENT 1243 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[64, 64, 64, 64, 64, 32, 32, 32, 32, 32, 16, 16, 16, 16, 16, 8, 8, 8, 8, 8], activation_name=relu, targets_activation_name=linear, 
initialization_name=uniform, algo_name=adam, learning_rate=0.01, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 25185]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 0.18318931763552243, loss after: 0.3579104541573821]
[epoch 1/1000, batch 11/100 -> loss before: 0.3809321780704472, loss after: 0.3798352789083026]
[epoch 1/1000, batch 21/100 -> loss before: 0.3549816134336912, loss after: 0.35492157698330756]
[epoch 1/1000, batch 31/100 -> loss before: 0.3761729777480042, loss after: 0.3753845903645701]
[epoch 1/1000, batch 41/100 -> loss before: 0.21146050552431633, loss after: 0.21159060526860266]
[epoch 1/1000, batch 51/100 -> loss before: 0.2598307035982101, loss after: 0.2603867543078387]
[epoch 1/1000, batch 61/100 -> loss before: 0.4675385790898476, loss after: 0.46760745798492864]
[epoch 1/1000, batch 71/100 -> loss before: 0.3454430158334242, loss after: 0.34519280982161016]
[epoch 1/1000, batch 81/100 -> loss before: 0.4035856388042018, loss after: 0.40343755131454034]
[epoch 1/1000, batch 91/100 -> loss before: 0.29466885802062187, loss after: 0.2945009636143812]
ENDING EPOCH 1/1000 [loss before: 0.2899884218128069, loss after: 0.28497090726227187; epoch time: 0.14934635162353516 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.2849662752345348, loss after: 0.28528136058262843]
[epoch 101/1000, batch 11/100 -> loss before: 0.2200630890074673, loss after: 0.2199822911180175]
[epoch 101/1000, batch 21/100 -> loss before: 0.24580703017726296, loss after: 0.24542764215499732]
[epoch 101/1000, batch 31/100 -> loss before: 0.3880031734774408, loss after: 0.3881330997082395]
[epoch 101/1000, batch 41/100 -> loss before: 0.6565559975468658, loss after: 0.6550790542468818]
[epoch 101/1000, batch 51/100 -> loss before: 0.2604127415771083, loss after: 0.2588191410837814]
[epoch 101/1000, batch 61/100 -> loss before: 0.5178092101591962, loss after: 0.5176665182123521]
[epoch 101/1000, batch 71/100 -> loss before: 0.1463814899393696, loss after: 0.14610787269912434]
[epoch 101/1000, batch 81/100 -> loss before: 0.2651506307673347, loss after: 0.26497737269999283]
[epoch 101/1000, batch 91/100 -> loss before: 0.24509954016097507, loss after: 0.24431064823067455]
ENDING EPOCH 101/1000 [loss before: 0.2832789279673125, loss after: 0.2830787352272617; epoch time: 0.15143251419067383 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.08806542700464168, loss after: 0.08806585602584661]
[epoch 201/1000, batch 11/100 -> loss before: 0.3568965673611947, loss after: 0.3565624839667157]
[epoch 201/1000, batch 21/100 -> loss before: 0.18344704235082357, loss after: 0.18227048510107974]
[epoch 201/1000, batch 31/100 -> loss before: 0.4661196720730632, loss after: 0.46584207084297313]
[epoch 201/1000, batch 41/100 -> loss before: 0.3140473640986532, loss after: 0.3149133116692574]
[epoch 201/1000, batch 51/100 -> loss before: 0.2858590394929665, loss after: 0.2858394881418676]
[epoch 201/1000, batch 61/100 -> loss before: 0.4864150436819214, loss after: 0.48674399244623084]
[epoch 201/1000, batch 71/100 -> loss before: 0.4123595866580908, loss after: 0.4119606797356126]
[epoch 201/1000, batch 81/100 -> loss before: 0.2006035320649096, loss after: 0.20032522438081876]
[epoch 201/1000, batch 91/100 -> loss before: 0.10909888233473446, loss after: 0.10908122446808055]
ENDING EPOCH 201/1000 [loss before: 0.28312103539162076, loss after: 0.2831405678639952; epoch time: 0.15497159957885742 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.18901321340275495, loss after: 0.18910075491575853]
[epoch 301/1000, batch 11/100 -> loss before: 0.19987126353043708, loss after: 0.19987542778687245]
[epoch 301/1000, batch 21/100 -> loss before: 0.31047114043100843, loss after: 0.31032855072793214]
[epoch 301/1000, batch 31/100 -> loss before: 0.3225688995836631, loss after: 0.32283059496564515]
[epoch 301/1000, batch 41/100 -> loss before: 0.26147763963332926, loss after: 0.26077314851827776]
[epoch 301/1000, batch 51/100 -> loss before: 0.28316122631753027, loss after: 0.28307781087207873]
[epoch 301/1000, batch 61/100 -> loss before: 0.31496417167768886, loss after: 0.3142950799570439]
[epoch 301/1000, batch 71/100 -> loss before: 0.30840930973185093, loss after: 0.30835426649742276]
[epoch 301/1000, batch 81/100 -> loss before: 0.32264388411599837, loss after: 0.3227041782020967]
[epoch 301/1000, batch 91/100 -> loss before: 0.32048826553636367, loss after: 0.3196415030258569]
ENDING EPOCH 301/1000 [loss before: 0.2830935137352069, loss after: 0.2830865501760804; epoch time: 0.1585979461669922 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.28412575956208647, loss after: 0.2844365203882877]
[epoch 401/1000, batch 11/100 -> loss before: 0.2742637935427055, loss after: 0.2742300465667516]
[epoch 401/1000, batch 21/100 -> loss before: 0.33137506391148447, loss after: 0.3305722305832429]
[epoch 401/1000, batch 31/100 -> loss before: 0.3702800176689874, loss after: 0.3700984721450681]
[epoch 401/1000, batch 41/100 -> loss before: 0.23512185397854415, loss after: 0.2351235498156905]
[epoch 401/1000, batch 51/100 -> loss before: 0.32507126199438846, loss after: 0.324998828365791]
[epoch 401/1000, batch 61/100 -> loss before: 0.24061199042625514, loss after: 0.24144469447886893]
[epoch 401/1000, batch 71/100 -> loss before: 0.2650720452534622, loss after: 0.26521409418666414]
[epoch 401/1000, batch 81/100 -> loss before: 0.19403995180074127, loss after: 0.1946270401212576]
[epoch 401/1000, batch 91/100 -> loss before: 0.1982931584959014, loss after: 0.1980466190439749]
ENDING EPOCH 401/1000 [loss before: 0.2830825880694881, loss after: 0.28417733661934286; epoch time: 0.16780543327331543 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.2864752417574269, loss after: 0.28595223292765637]
[epoch 501/1000, batch 11/100 -> loss before: 0.5795984179509819, loss after: 0.5791441485815372]
[epoch 501/1000, batch 21/100 -> loss before: 0.37886932247865457, loss after: 0.3788957196292723]
[epoch 501/1000, batch 31/100 -> loss before: 0.24494416592570611, loss after: 0.24488297364837058]
[epoch 501/1000, batch 41/100 -> loss before: 0.3150229773114108, loss after: 0.31504342818045794]
[epoch 501/1000, batch 51/100 -> loss before: 0.17695861861985807, loss after: 0.1769384145828333]
[epoch 501/1000, batch 61/100 -> loss before: 0.28975085710893855, loss after: 0.2897387571400708]
[epoch 501/1000, batch 71/100 -> loss before: 0.14747263624778287, loss after: 0.14748108320366302]
[epoch 501/1000, batch 81/100 -> loss before: 0.2442888896379693, loss after: 0.24381157629374517]
[epoch 501/1000, batch 91/100 -> loss before: 0.21335530917127662, loss after: 0.2134021411277433]
ENDING EPOCH 501/1000 [loss before: 0.28311579518624613, loss after: 0.28312566634771813; epoch time: 0.1517810821533203 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.34343300276931116, loss after: 0.34379830912539905]
[epoch 601/1000, batch 11/100 -> loss before: 0.3527811734097882, loss after: 0.35373572357920713]
[epoch 601/1000, batch 21/100 -> loss before: 0.3031535608216885, loss after: 0.3028790362432176]
[epoch 601/1000, batch 31/100 -> loss before: 0.13154514206159895, loss after: 0.13232105342739098]
[epoch 601/1000, batch 41/100 -> loss before: 0.3760686384764028, loss after: 0.37389011112397236]
[epoch 601/1000, batch 51/100 -> loss before: 0.28721766075471666, loss after: 0.2871742076075173]
[epoch 601/1000, batch 61/100 -> loss before: 0.13686241390195747, loss after: 0.13675628918764915]
[epoch 601/1000, batch 71/100 -> loss before: 0.27375378902179814, loss after: 0.27178562090001224]
[epoch 601/1000, batch 81/100 -> loss before: 0.34353944274421183, loss after: 0.3425517321095971]
[epoch 601/1000, batch 91/100 -> loss before: 0.3472955306999691, loss after: 0.3473049005614398]
ENDING EPOCH 601/1000 [loss before: 0.28310915051773095, loss after: 0.283590306427826; epoch time: 0.1568622589111328 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.13801944561289678, loss after: 0.13805182657468726]
[epoch 701/1000, batch 11/100 -> loss before: 0.1767687784720948, loss after: 0.1734320678182056]
[epoch 701/1000, batch 21/100 -> loss before: 0.22653324483927087, loss after: 0.2261515232826646]
[epoch 701/1000, batch 31/100 -> loss before: 0.2037806094560724, loss after: 0.2038001145554802]
[epoch 701/1000, batch 41/100 -> loss before: 0.19911787652526486, loss after: 0.19847716965784135]
[epoch 701/1000, batch 51/100 -> loss before: 0.5355676179287443, loss after: 0.5346194593428044]
[epoch 701/1000, batch 61/100 -> loss before: 0.1384107472997356, loss after: 0.13844122166035885]
[epoch 701/1000, batch 71/100 -> loss before: 0.3683864195972759, loss after: 0.36838703877999823]
[epoch 701/1000, batch 81/100 -> loss before: 0.2834574237091836, loss after: 0.2833919048804886]
[epoch 701/1000, batch 91/100 -> loss before: 0.353356083489066, loss after: 0.3533549869852771]
ENDING EPOCH 701/1000 [loss before: 0.28318010159771223, loss after: 0.2834572026171605; epoch time: 0.1565079689025879 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.2501042213374772, loss after: 0.24820391716882462]
[epoch 801/1000, batch 11/100 -> loss before: 0.11740644330260766, loss after: 0.11742961285948128]
[epoch 801/1000, batch 21/100 -> loss before: 0.24030057013897083, loss after: 0.23994496115578165]
[epoch 801/1000, batch 31/100 -> loss before: 0.2138773288670314, loss after: 0.21381280861747762]
[epoch 801/1000, batch 41/100 -> loss before: 0.46745358909525664, loss after: 0.46824013802553044]
[epoch 801/1000, batch 51/100 -> loss before: 0.26603948024497165, loss after: 0.26586112463958683]
[epoch 801/1000, batch 61/100 -> loss before: 0.26913801585467334, loss after: 0.26862583411660235]
[epoch 801/1000, batch 71/100 -> loss before: 0.3211115898850428, loss after: 0.3212466873968173]
[epoch 801/1000, batch 81/100 -> loss before: 0.2901403194596925, loss after: 0.2903369131315705]
[epoch 801/1000, batch 91/100 -> loss before: 0.24596098021228446, loss after: 0.2457513995935791]
ENDING EPOCH 801/1000 [loss before: 0.2830998261798421, loss after: 0.28307849222339926; epoch time: 0.15694165229797363 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.13498551675357232, loss after: 0.13449035494190534]
[epoch 901/1000, batch 11/100 -> loss before: 0.3361888826189373, loss after: 0.33589949089091303]
[epoch 901/1000, batch 21/100 -> loss before: 0.24915496468416704, loss after: 0.24862455816516604]
[epoch 901/1000, batch 31/100 -> loss before: 0.28361406187494803, loss after: 0.2829945258530113]
[epoch 901/1000, batch 41/100 -> loss before: 0.3367708323344211, loss after: 0.3367032038567923]
[epoch 901/1000, batch 51/100 -> loss before: 0.23547848061323312, loss after: 0.23617117380450608]
[epoch 901/1000, batch 61/100 -> loss before: 0.4077450685040146, loss after: 0.4078488424435661]
[epoch 901/1000, batch 71/100 -> loss before: 0.18537458842665772, loss after: 0.18425631746038001]
[epoch 901/1000, batch 81/100 -> loss before: 0.39085133788539805, loss after: 0.3902848276318185]
[epoch 901/1000, batch 91/100 -> loss before: 0.21100773548014784, loss after: 0.21046540165725847]
ENDING EPOCH 901/1000 [loss before: 0.28313822594374466, loss after: 0.2834164147655023; epoch time: 0.15402007102966309 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.25659732788948647, loss after: 0.25704893844868404]
[epoch 1000/1000, batch 11/100 -> loss before: 0.2304667290994594, loss after: 0.23029014230998754]
[epoch 1000/1000, batch 21/100 -> loss before: 0.31757745085733563, loss after: 0.3177321821774362]
[epoch 1000/1000, batch 31/100 -> loss before: 0.23508288562364962, loss after: 0.23520837790208354]
[epoch 1000/1000, batch 41/100 -> loss before: 0.2950258613735784, loss after: 0.29448818105567937]
[epoch 1000/1000, batch 51/100 -> loss before: 0.30027268785919103, loss after: 0.3003729845955994]
[epoch 1000/1000, batch 61/100 -> loss before: 0.20778737318451604, loss after: 0.20805631620180884]
[epoch 1000/1000, batch 71/100 -> loss before: 0.3491653766833245, loss after: 0.34896435029805284]
[epoch 1000/1000, batch 81/100 -> loss before: 0.10218074511433817, loss after: 0.10214567373354218]
[epoch 1000/1000, batch 91/100 -> loss before: 0.35137321347890854, loss after: 0.3509552587102977]
ENDING EPOCH 1000/1000 [loss before: 0.28308827806713965, loss after: 0.2836531206473373; epoch time: 0.15442705154418945 s]
FIT DONE. [time: 151.48676443099976 s]
LOSS TRAIN (MSE): 0.2836531206473373
LOSS TEST (MSE): 0.27765933218514266
R^2 TRAIN: -0.0020310554389262325
R^2 TEST: -0.0004646965139889492
EXPERIMENT DONE

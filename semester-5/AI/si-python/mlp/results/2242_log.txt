EXPERIMENT 2242 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 128, 64, 64, 32, 32], activation_name=relu, targets_activation_name=linear, 
initialization_name=uniform, algo_name=adam, learning_rate=0.001, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 32481]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 0.87553713426397, loss after: 1.2281625910250749]
[epoch 1/1000, batch 11/100 -> loss before: 0.4100521503778345, loss after: 0.2061379919141315]
[epoch 1/1000, batch 21/100 -> loss before: 0.1981755345669601, loss after: 0.17654107595658852]
[epoch 1/1000, batch 31/100 -> loss before: 0.38277593499835116, loss after: 0.31753244767154787]
[epoch 1/1000, batch 41/100 -> loss before: 0.22434368086068585, loss after: 0.22188482549460836]
[epoch 1/1000, batch 51/100 -> loss before: 0.0988336102789463, loss after: 0.11394324677714004]
[epoch 1/1000, batch 61/100 -> loss before: 0.16673101391953588, loss after: 0.15464073936309333]
[epoch 1/1000, batch 71/100 -> loss before: 0.5256027525416378, loss after: 0.4978996505053166]
[epoch 1/1000, batch 81/100 -> loss before: 0.5684319033492538, loss after: 0.49881670211638357]
[epoch 1/1000, batch 91/100 -> loss before: 0.3057335221507843, loss after: 0.2325163710632848]
ENDING EPOCH 1/1000 [loss before: 1.102092538201909, loss after: 0.3390781213596632; epoch time: 0.08104968070983887 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.26315710998520453, loss after: 0.25341876071928027]
[epoch 101/1000, batch 11/100 -> loss before: 0.10159184426232422, loss after: 0.08346315660276618]
[epoch 101/1000, batch 21/100 -> loss before: 0.05892704480982643, loss after: 0.04574952316303566]
[epoch 101/1000, batch 31/100 -> loss before: 0.035399186321464104, loss after: 0.026683916802674346]
[epoch 101/1000, batch 41/100 -> loss before: 0.016650201623794717, loss after: 0.02025892639155282]
[epoch 101/1000, batch 51/100 -> loss before: 0.0592599236659543, loss after: 0.028372161586905732]
[epoch 101/1000, batch 61/100 -> loss before: 0.09367844908830922, loss after: 0.11073858243445411]
[epoch 101/1000, batch 71/100 -> loss before: 0.32365471167848814, loss after: 0.28565965738151017]
[epoch 101/1000, batch 81/100 -> loss before: 0.11702753699857041, loss after: 0.11165282265482697]
[epoch 101/1000, batch 91/100 -> loss before: 0.09044883899260407, loss after: 0.08024185703527151]
ENDING EPOCH 101/1000 [loss before: 0.1250177124281863, loss after: 0.11512451481233786; epoch time: 0.0844428539276123 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.06707704221706016, loss after: 0.06136493830968285]
[epoch 201/1000, batch 11/100 -> loss before: 0.05957932514710081, loss after: 0.05542293652691834]
[epoch 201/1000, batch 21/100 -> loss before: 0.07588861529105638, loss after: 0.043992462053148856]
[epoch 201/1000, batch 31/100 -> loss before: 0.029010481714278967, loss after: 0.024755708406102785]
[epoch 201/1000, batch 41/100 -> loss before: 0.030644631821526623, loss after: 0.030044735549689373]
[epoch 201/1000, batch 51/100 -> loss before: 0.028355463879868408, loss after: 0.02501610558905218]
[epoch 201/1000, batch 61/100 -> loss before: 0.02265230071117296, loss after: 0.023218855442011667]
[epoch 201/1000, batch 71/100 -> loss before: 0.05024132128897894, loss after: 0.04605258104095352]
[epoch 201/1000, batch 81/100 -> loss before: 0.04303119182048653, loss after: 0.04356707079396306]
[epoch 201/1000, batch 91/100 -> loss before: 0.02100572181610586, loss after: 0.014770527610434268]
ENDING EPOCH 201/1000 [loss before: 0.033646070463132796, loss after: 0.025501999690898464; epoch time: 0.08734536170959473 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.04179479215503195, loss after: 0.03622577068757117]
[epoch 301/1000, batch 11/100 -> loss before: 0.01280083663783622, loss after: 0.011507774017928088]
[epoch 301/1000, batch 21/100 -> loss before: 0.050665544797477334, loss after: 0.04038614414664434]
[epoch 301/1000, batch 31/100 -> loss before: 0.021356670747238567, loss after: 0.018166015255037974]
[epoch 301/1000, batch 41/100 -> loss before: 0.039289253056955395, loss after: 0.03378616855018662]
[epoch 301/1000, batch 51/100 -> loss before: 0.0787840154076727, loss after: 0.05848570560105097]
[epoch 301/1000, batch 61/100 -> loss before: 0.010491173969254596, loss after: 0.008477820317110248]
[epoch 301/1000, batch 71/100 -> loss before: 0.037672183730575584, loss after: 0.0339033852684151]
[epoch 301/1000, batch 81/100 -> loss before: 0.009065700085209965, loss after: 0.0065989750396451925]
[epoch 301/1000, batch 91/100 -> loss before: 0.026670848204593183, loss after: 0.019418528285024484]
ENDING EPOCH 301/1000 [loss before: 0.04202605876532383, loss after: 0.020699945752699355; epoch time: 0.12143635749816895 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.0756199324033506, loss after: 0.06639810253900498]
[epoch 401/1000, batch 11/100 -> loss before: 0.10494553850160168, loss after: 0.08426180775191268]
[epoch 401/1000, batch 21/100 -> loss before: 0.0228004260630126, loss after: 0.01980399493293833]
[epoch 401/1000, batch 31/100 -> loss before: 0.007468916620526898, loss after: 0.006062530884362968]
[epoch 401/1000, batch 41/100 -> loss before: 0.012560439400947079, loss after: 0.01058622783149592]
[epoch 401/1000, batch 51/100 -> loss before: 0.01957170272814071, loss after: 0.0193841624665018]
[epoch 401/1000, batch 61/100 -> loss before: 0.008689972818115139, loss after: 0.00829316104411593]
[epoch 401/1000, batch 71/100 -> loss before: 0.009991294686624574, loss after: 0.009247731881126688]
[epoch 401/1000, batch 81/100 -> loss before: 0.037157081578135125, loss after: 0.036607663353505904]
[epoch 401/1000, batch 91/100 -> loss before: 0.01635972174006124, loss after: 0.015014421082801033]
ENDING EPOCH 401/1000 [loss before: 0.02795582371167833, loss after: 0.015154824395569238; epoch time: 0.1372668743133545 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.01828700803523085, loss after: 0.014746382709691646]
[epoch 501/1000, batch 11/100 -> loss before: 0.009672264642295786, loss after: 0.010344693726325207]
[epoch 501/1000, batch 21/100 -> loss before: 0.017619142291229052, loss after: 0.010315489092084495]
[epoch 501/1000, batch 31/100 -> loss before: 0.03967723497363575, loss after: 0.024853610586132984]
[epoch 501/1000, batch 41/100 -> loss before: 0.01057350761244403, loss after: 0.010072937618004539]
[epoch 501/1000, batch 51/100 -> loss before: 0.01721859415792213, loss after: 0.015620824263924343]
[epoch 501/1000, batch 61/100 -> loss before: 0.009665277697918891, loss after: 0.009383594975048568]
[epoch 501/1000, batch 71/100 -> loss before: 0.013085472474512966, loss after: 0.011010414227929873]
[epoch 501/1000, batch 81/100 -> loss before: 0.01039214970371509, loss after: 0.009444068374284253]
[epoch 501/1000, batch 91/100 -> loss before: 0.00818384028204826, loss after: 0.00823252578427586]
ENDING EPOCH 501/1000 [loss before: 0.014299911222807422, loss after: 0.013046963591576262; epoch time: 0.1089928150177002 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.011647078200989817, loss after: 0.009218412427262516]
[epoch 601/1000, batch 11/100 -> loss before: 0.007069753712903882, loss after: 0.006163121858360054]
[epoch 601/1000, batch 21/100 -> loss before: 0.04561600713762918, loss after: 0.023318485313329217]
[epoch 601/1000, batch 31/100 -> loss before: 0.014999615305036084, loss after: 0.013986794252438057]
[epoch 601/1000, batch 41/100 -> loss before: 0.017345165012164706, loss after: 0.014094826941447222]
[epoch 601/1000, batch 51/100 -> loss before: 0.012129349225804727, loss after: 0.014010676785701143]
[epoch 601/1000, batch 61/100 -> loss before: 0.03244883135236647, loss after: 0.03224323676298566]
[epoch 601/1000, batch 71/100 -> loss before: 0.018938296478789605, loss after: 0.015560684883479125]
[epoch 601/1000, batch 81/100 -> loss before: 0.00547889602662323, loss after: 0.005596593413472283]
[epoch 601/1000, batch 91/100 -> loss before: 0.007591095235502161, loss after: 0.00639101956528515]
ENDING EPOCH 601/1000 [loss before: 0.01216011266729763, loss after: 0.021400628536247888; epoch time: 0.0911564826965332 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.005358156645329138, loss after: 0.005327071036196957]
[epoch 701/1000, batch 11/100 -> loss before: 0.006333165083430849, loss after: 0.0054095516603543895]
[epoch 701/1000, batch 21/100 -> loss before: 0.009077933937893325, loss after: 0.007810453970784542]
[epoch 701/1000, batch 31/100 -> loss before: 0.00646691607286245, loss after: 0.005530848326720847]
[epoch 701/1000, batch 41/100 -> loss before: 0.028480070709089627, loss after: 0.008975551896740219]
[epoch 701/1000, batch 51/100 -> loss before: 0.008643880324468832, loss after: 0.006913265648183014]
[epoch 701/1000, batch 61/100 -> loss before: 0.013518329958640682, loss after: 0.016549839171820842]
[epoch 701/1000, batch 71/100 -> loss before: 0.007449221006872645, loss after: 0.009133069808863227]
[epoch 701/1000, batch 81/100 -> loss before: 0.014443632098559325, loss after: 0.012713428335140355]
[epoch 701/1000, batch 91/100 -> loss before: 0.016268453118710603, loss after: 0.01325391277661414]
ENDING EPOCH 701/1000 [loss before: 0.013707905712745844, loss after: 0.014518461447506426; epoch time: 0.10666918754577637 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.004517750276209832, loss after: 0.004168250684546289]
[epoch 801/1000, batch 11/100 -> loss before: 0.00328349831851011, loss after: 0.0030404615869938237]
[epoch 801/1000, batch 21/100 -> loss before: 0.008655859555864908, loss after: 0.006801589654028916]
[epoch 801/1000, batch 31/100 -> loss before: 0.007979004450958704, loss after: 0.007401977612029843]
[epoch 801/1000, batch 41/100 -> loss before: 0.01305891796873771, loss after: 0.009018325507350263]
[epoch 801/1000, batch 51/100 -> loss before: 0.006022703111571176, loss after: 0.005844822904672656]
[epoch 801/1000, batch 61/100 -> loss before: 0.016654250054508747, loss after: 0.01495853101229962]
[epoch 801/1000, batch 71/100 -> loss before: 0.032429364550003434, loss after: 0.03196021388475213]
[epoch 801/1000, batch 81/100 -> loss before: 0.012094446733600644, loss after: 0.01045105068634366]
[epoch 801/1000, batch 91/100 -> loss before: 0.050409930426824553, loss after: 0.03637456854186877]
ENDING EPOCH 801/1000 [loss before: 0.009650196234656704, loss after: 0.013432315352498805; epoch time: 0.09110903739929199 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.005736771095759664, loss after: 0.004846640909925194]
[epoch 901/1000, batch 11/100 -> loss before: 0.004395863085273513, loss after: 0.0037881974076472195]
[epoch 901/1000, batch 21/100 -> loss before: 0.005351369223421133, loss after: 0.003981573682866433]
[epoch 901/1000, batch 31/100 -> loss before: 0.00301412246571433, loss after: 0.0027174321273166456]
[epoch 901/1000, batch 41/100 -> loss before: 0.01025014845340145, loss after: 0.0088889249621125]
[epoch 901/1000, batch 51/100 -> loss before: 0.04999867830270135, loss after: 0.029501856701193162]
[epoch 901/1000, batch 61/100 -> loss before: 0.005152181424921186, loss after: 0.004293990596157656]
[epoch 901/1000, batch 71/100 -> loss before: 0.00946783984752116, loss after: 0.007267705438896011]
[epoch 901/1000, batch 81/100 -> loss before: 0.00706659128950376, loss after: 0.008248425748076896]
[epoch 901/1000, batch 91/100 -> loss before: 0.020187130041971417, loss after: 0.013682144701825244]
ENDING EPOCH 901/1000 [loss before: 0.010089361651388414, loss after: 0.010163106501025655; epoch time: 0.09138035774230957 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.00851301192983604, loss after: 0.009506200461125394]
[epoch 1000/1000, batch 11/100 -> loss before: 0.012399900347474574, loss after: 0.011048396033229883]
[epoch 1000/1000, batch 21/100 -> loss before: 0.006464858754279583, loss after: 0.004880874465949854]
[epoch 1000/1000, batch 31/100 -> loss before: 0.007145028428523201, loss after: 0.0066942195347184565]
[epoch 1000/1000, batch 41/100 -> loss before: 0.006528809472692254, loss after: 0.005991625843313518]
[epoch 1000/1000, batch 51/100 -> loss before: 0.00814645772157425, loss after: 0.007844867578248193]
[epoch 1000/1000, batch 61/100 -> loss before: 0.010254964351424176, loss after: 0.00949640081653772]
[epoch 1000/1000, batch 71/100 -> loss before: 0.00620578504218102, loss after: 0.005194867533579511]
[epoch 1000/1000, batch 81/100 -> loss before: 0.002689293990282532, loss after: 0.0035448070740311892]
[epoch 1000/1000, batch 91/100 -> loss before: 0.011564986438346619, loss after: 0.011192770514225448]
ENDING EPOCH 1000/1000 [loss before: 0.01612256473604758, loss after: 0.01147716271282748; epoch time: 0.1104130744934082 s]
FIT DONE. [time: 95.56873226165771 s]
LOSS TRAIN (MSE): 0.01147716271282748
LOSS TEST (MSE): 0.021845512648476607
R^2 TRAIN: 0.9594558542478465
R^2 TEST: 0.9212860449888378
EXPERIMENT DONE

EXPERIMENT 3113 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[64, 64, 64, 64, 64, 32, 32, 32, 32, 32, 16, 16, 16, 16, 16, 8, 8, 8, 8, 8], activation_name=sigmoid, targets_activation_name=linear, 
initialization_name=uniform, algo_name=sgd_simple, learning_rate=0.0001, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 25185]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 0.6815884323265685, loss after: 0.6745513997557354]
[epoch 1/1000, batch 11/100 -> loss before: 0.41917204067088953, loss after: 0.4172416301815395]
[epoch 1/1000, batch 21/100 -> loss before: 0.6903815393750629, loss after: 0.6855531157423944]
[epoch 1/1000, batch 31/100 -> loss before: 0.5311605502930552, loss after: 0.528838921900566]
[epoch 1/1000, batch 41/100 -> loss before: 0.49442405722966487, loss after: 0.49019700075486483]
[epoch 1/1000, batch 51/100 -> loss before: 0.5392647791238819, loss after: 0.5348363258622791]
[epoch 1/1000, batch 61/100 -> loss before: 0.6002510292683901, loss after: 0.5983408994730953]
[epoch 1/1000, batch 71/100 -> loss before: 0.5091619876082598, loss after: 0.5067020664732559]
[epoch 1/1000, batch 81/100 -> loss before: 0.5429007341367227, loss after: 0.5408039652622416]
[epoch 1/1000, batch 91/100 -> loss before: 0.33409222537246064, loss after: 0.3334696846491249]
ENDING EPOCH 1/1000 [loss before: 0.599648552700766, loss after: 0.35872322122805156; epoch time: 0.08926272392272949 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.28638361826025854, loss after: 0.2863325918042552]
[epoch 101/1000, batch 11/100 -> loss before: 0.22107400586971965, loss after: 0.22105506598576663]
[epoch 101/1000, batch 21/100 -> loss before: 0.24315819384711806, loss after: 0.24306731129013737]
[epoch 101/1000, batch 31/100 -> loss before: 0.3876489405035467, loss after: 0.3873009744268076]
[epoch 101/1000, batch 41/100 -> loss before: 0.6532178024379828, loss after: 0.6501730616832393]
[epoch 101/1000, batch 51/100 -> loss before: 0.2669344109377002, loss after: 0.26582457567076634]
[epoch 101/1000, batch 61/100 -> loss before: 0.5154995746817341, loss after: 0.5154786062646309]
[epoch 101/1000, batch 71/100 -> loss before: 0.146020939245444, loss after: 0.1459906628792664]
[epoch 101/1000, batch 81/100 -> loss before: 0.26662468108755333, loss after: 0.2665459405664941]
[epoch 101/1000, batch 91/100 -> loss before: 0.24559433420497218, loss after: 0.24491804425638897]
ENDING EPOCH 101/1000 [loss before: 0.2830787990337597, loss after: 0.2830786430388959; epoch time: 0.10870528221130371 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.08811173878525852, loss after: 0.0881110624543379]
[epoch 201/1000, batch 11/100 -> loss before: 0.3576977855416593, loss after: 0.35751579117110227]
[epoch 201/1000, batch 21/100 -> loss before: 0.19316636213110008, loss after: 0.19253185427954428]
[epoch 201/1000, batch 31/100 -> loss before: 0.46028261726736924, loss after: 0.4600758916939274]
[epoch 201/1000, batch 41/100 -> loss before: 0.3159344670223109, loss after: 0.3155138133355013]
[epoch 201/1000, batch 51/100 -> loss before: 0.28424692044376465, loss after: 0.2842101765615751]
[epoch 201/1000, batch 61/100 -> loss before: 0.4835575303478506, loss after: 0.48340107146988875]
[epoch 201/1000, batch 71/100 -> loss before: 0.4160250821329525, loss after: 0.41589902112514265]
[epoch 201/1000, batch 81/100 -> loss before: 0.1990286609870933, loss after: 0.19902391361485972]
[epoch 201/1000, batch 91/100 -> loss before: 0.1090563227809982, loss after: 0.10905506499611597]
ENDING EPOCH 201/1000 [loss before: 0.28307975791298307, loss after: 0.28307906354350926; epoch time: 0.12912726402282715 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.18857258640380542, loss after: 0.18854440929264518]
[epoch 301/1000, batch 11/100 -> loss before: 0.20124899792390324, loss after: 0.20119152980305924]
[epoch 301/1000, batch 21/100 -> loss before: 0.3059383995848841, loss after: 0.30552333885857164]
[epoch 301/1000, batch 31/100 -> loss before: 0.32392970932358967, loss after: 0.32319639085083046]
[epoch 301/1000, batch 41/100 -> loss before: 0.2625516733061085, loss after: 0.2622360417444836]
[epoch 301/1000, batch 51/100 -> loss before: 0.2824771828315594, loss after: 0.28247543340655223]
[epoch 301/1000, batch 61/100 -> loss before: 0.3113777768204832, loss after: 0.31076481542756174]
[epoch 301/1000, batch 71/100 -> loss before: 0.3111931946340939, loss after: 0.3109812380346722]
[epoch 301/1000, batch 81/100 -> loss before: 0.32250822963368697, loss after: 0.32250370515117927]
[epoch 301/1000, batch 91/100 -> loss before: 0.3149801390390526, loss after: 0.31345466409127637]
ENDING EPOCH 301/1000 [loss before: 0.2830788144974651, loss after: 0.28308061532840156; epoch time: 0.11653280258178711 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.28403512198221675, loss after: 0.2839929022835314]
[epoch 401/1000, batch 11/100 -> loss before: 0.2762269108844885, loss after: 0.27616620735357383]
[epoch 401/1000, batch 21/100 -> loss before: 0.34349523411437655, loss after: 0.342250878489747]
[epoch 401/1000, batch 31/100 -> loss before: 0.3760650426534212, loss after: 0.3725037111893543]
[epoch 401/1000, batch 41/100 -> loss before: 0.23539324327310576, loss after: 0.23538932108505653]
[epoch 401/1000, batch 51/100 -> loss before: 0.33007507232958505, loss after: 0.32998197163716037]
[epoch 401/1000, batch 61/100 -> loss before: 0.2603319833006693, loss after: 0.2592761554614762]
[epoch 401/1000, batch 71/100 -> loss before: 0.2656345399744342, loss after: 0.2656225282404993]
[epoch 401/1000, batch 81/100 -> loss before: 0.18853977880214884, loss after: 0.18844613509092895]
[epoch 401/1000, batch 91/100 -> loss before: 0.19327010635864889, loss after: 0.1932381694893538]
ENDING EPOCH 401/1000 [loss before: 0.2830797927368853, loss after: 0.28308023865450443; epoch time: 0.0911262035369873 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.2844942168481029, loss after: 0.2842353547464191]
[epoch 501/1000, batch 11/100 -> loss before: 0.5794810979604227, loss after: 0.5793007715990655]
[epoch 501/1000, batch 21/100 -> loss before: 0.3798718383738533, loss after: 0.3798134989486933]
[epoch 501/1000, batch 31/100 -> loss before: 0.24543709255273338, loss after: 0.24528838105574277]
[epoch 501/1000, batch 41/100 -> loss before: 0.3152428582474388, loss after: 0.31523576332445274]
[epoch 501/1000, batch 51/100 -> loss before: 0.17721108713274936, loss after: 0.17714327709258745]
[epoch 501/1000, batch 61/100 -> loss before: 0.2897009987766044, loss after: 0.28970067802189226]
[epoch 501/1000, batch 71/100 -> loss before: 0.14756479664455863, loss after: 0.14756345193536172]
[epoch 501/1000, batch 81/100 -> loss before: 0.23785843969403545, loss after: 0.23718395985545054]
[epoch 501/1000, batch 91/100 -> loss before: 0.21388734964379866, loss after: 0.21387343108788368]
ENDING EPOCH 501/1000 [loss before: 0.28307926195353383, loss after: 0.2830781872064542; epoch time: 0.11928915977478027 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.344001636248927, loss after: 0.34393949703442317]
[epoch 601/1000, batch 11/100 -> loss before: 0.3442764799723762, loss after: 0.34396879086488485]
[epoch 601/1000, batch 21/100 -> loss before: 0.29636934392309805, loss after: 0.29631642132720476]
[epoch 601/1000, batch 31/100 -> loss before: 0.1341917743779849, loss after: 0.13401094730924915]
[epoch 601/1000, batch 41/100 -> loss before: 0.3745397642729746, loss after: 0.3731949023442608]
[epoch 601/1000, batch 51/100 -> loss before: 0.2832937110498036, loss after: 0.2828163274366133]
[epoch 601/1000, batch 61/100 -> loss before: 0.13748737117596832, loss after: 0.13746851060241078]
[epoch 601/1000, batch 71/100 -> loss before: 0.26841814317447016, loss after: 0.2671151889061403]
[epoch 601/1000, batch 81/100 -> loss before: 0.3460915385526315, loss after: 0.34455335885606564]
[epoch 601/1000, batch 91/100 -> loss before: 0.34730884385383404, loss after: 0.3473086397983826]
ENDING EPOCH 601/1000 [loss before: 0.2830793775333706, loss after: 0.28308632079467283; epoch time: 0.08763837814331055 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.13959669914625705, loss after: 0.13946622318895852]
[epoch 701/1000, batch 11/100 -> loss before: 0.17567729353577485, loss after: 0.1744693748546163]
[epoch 701/1000, batch 21/100 -> loss before: 0.23239823381667674, loss after: 0.23223149591035233]
[epoch 701/1000, batch 31/100 -> loss before: 0.2082529972442674, loss after: 0.20817399570887232]
[epoch 701/1000, batch 41/100 -> loss before: 0.19792751314661675, loss after: 0.19789201053940939]
[epoch 701/1000, batch 51/100 -> loss before: 0.543120003838389, loss after: 0.5412815894831136]
[epoch 701/1000, batch 61/100 -> loss before: 0.13594552457434445, loss after: 0.13590077658260816]
[epoch 701/1000, batch 71/100 -> loss before: 0.3678708072738709, loss after: 0.3678614442936437]
[epoch 701/1000, batch 81/100 -> loss before: 0.2843848866642683, loss after: 0.28436877007580913]
[epoch 701/1000, batch 91/100 -> loss before: 0.3539006405877192, loss after: 0.3538926607500685]
ENDING EPOCH 701/1000 [loss before: 0.2830802498620273, loss after: 0.2830842194500765; epoch time: 0.09108567237854004 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.24641780880670866, loss after: 0.2446664516230387]
[epoch 801/1000, batch 11/100 -> loss before: 0.11753522146728863, loss after: 0.11750778653687606]
[epoch 801/1000, batch 21/100 -> loss before: 0.24290302598750446, loss after: 0.2427578754032565]
[epoch 801/1000, batch 31/100 -> loss before: 0.21587492629250193, loss after: 0.2157723051891567]
[epoch 801/1000, batch 41/100 -> loss before: 0.4678687659425546, loss after: 0.4675104963192728]
[epoch 801/1000, batch 51/100 -> loss before: 0.26720506868665117, loss after: 0.267080948418777]
[epoch 801/1000, batch 61/100 -> loss before: 0.27338178843025635, loss after: 0.2730023101070182]
[epoch 801/1000, batch 71/100 -> loss before: 0.32365480845583583, loss after: 0.3235264246069127]
[epoch 801/1000, batch 81/100 -> loss before: 0.2924541099409873, loss after: 0.29205940970008104]
[epoch 801/1000, batch 91/100 -> loss before: 0.2455727921137711, loss after: 0.2454681124520955]
ENDING EPOCH 801/1000 [loss before: 0.2830785074917095, loss after: 0.28307878969883277; epoch time: 0.08890557289123535 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.13685184371043646, loss after: 0.1365568553414712]
[epoch 901/1000, batch 11/100 -> loss before: 0.32519127947642756, loss after: 0.3244796698552257]
[epoch 901/1000, batch 21/100 -> loss before: 0.2568455616459362, loss after: 0.25621452849573956]
[epoch 901/1000, batch 31/100 -> loss before: 0.29276195265397237, loss after: 0.29228365799791306]
[epoch 901/1000, batch 41/100 -> loss before: 0.34728053990526914, loss after: 0.3466302089873846]
[epoch 901/1000, batch 51/100 -> loss before: 0.24413873783902046, loss after: 0.24259339676131772]
[epoch 901/1000, batch 61/100 -> loss before: 0.4075608232878604, loss after: 0.4075607693393928]
[epoch 901/1000, batch 71/100 -> loss before: 0.1767219098680483, loss after: 0.17634387912798383]
[epoch 901/1000, batch 81/100 -> loss before: 0.3916031079718579, loss after: 0.39129459287386587]
[epoch 901/1000, batch 91/100 -> loss before: 0.2111766649145032, loss after: 0.21101801430497846]
ENDING EPOCH 901/1000 [loss before: 0.2830793696258032, loss after: 0.2830852095682386; epoch time: 0.09242725372314453 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.2561670673005346, loss after: 0.25582344602493584]
[epoch 1000/1000, batch 11/100 -> loss before: 0.23209377005231172, loss after: 0.2319828412159472]
[epoch 1000/1000, batch 21/100 -> loss before: 0.31207287312961907, loss after: 0.3117001662273113]
[epoch 1000/1000, batch 31/100 -> loss before: 0.23628238800097107, loss after: 0.2362549838745598]
[epoch 1000/1000, batch 41/100 -> loss before: 0.2982314846030379, loss after: 0.2972332058697273]
[epoch 1000/1000, batch 51/100 -> loss before: 0.2963763081302042, loss after: 0.295856276359719]
[epoch 1000/1000, batch 61/100 -> loss before: 0.21205240108859574, loss after: 0.2117009503321164]
[epoch 1000/1000, batch 71/100 -> loss before: 0.34983913916087567, loss after: 0.34976045857646565]
[epoch 1000/1000, batch 81/100 -> loss before: 0.10212499372671861, loss after: 0.10212467383180754]
[epoch 1000/1000, batch 91/100 -> loss before: 0.35786392244160337, loss after: 0.357537234362974]
ENDING EPOCH 1000/1000 [loss before: 0.28308140024743433, loss after: 0.2830781742764106; epoch time: 0.08872842788696289 s]
FIT DONE. [time: 81.79948592185974 s]
LOSS TRAIN (MSE): 0.2830781742764106
LOSS TEST (MSE): 0.27768883838992436
R^2 TRAIN: -3.858863451000616e-09
R^2 TEST: -0.0005710135463750099
EXPERIMENT DONE

EXPERIMENT 2111 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 64, 32], activation_name=sigmoid, targets_activation_name=linear, 
initialization_name=uniform, algo_name=sgd_simple, learning_rate=0.001, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 10753]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 1.6197437009973044, loss after: 1.1387453225423487]
[epoch 1/1000, batch 11/100 -> loss before: 0.20752376731741223, loss after: 0.20007034270570126]
[epoch 1/1000, batch 21/100 -> loss before: 0.08664104651057859, loss after: 0.08168180375601389]
[epoch 1/1000, batch 31/100 -> loss before: 0.4489375168550217, loss after: 0.4487211919225194]
[epoch 1/1000, batch 41/100 -> loss before: 0.1675622019136645, loss after: 0.1675053950250891]
[epoch 1/1000, batch 51/100 -> loss before: 0.3793811142540551, loss after: 0.33561020113630957]
[epoch 1/1000, batch 61/100 -> loss before: 0.5252067577812566, loss after: 0.5136285978295853]
[epoch 1/1000, batch 71/100 -> loss before: 0.4636276475040678, loss after: 0.44091275048148876]
[epoch 1/1000, batch 81/100 -> loss before: 0.14755832413399245, loss after: 0.145772653256028]
[epoch 1/1000, batch 91/100 -> loss before: 0.41583742567396137, loss after: 0.4081488064980098]
ENDING EPOCH 1/1000 [loss before: 0.7227142221308361, loss after: 0.2850024107342763; epoch time: 0.029079198837280273 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.2711865328246855, loss after: 0.26714078737140323]
[epoch 101/1000, batch 11/100 -> loss before: 0.1303266289272662, loss after: 0.12607672197196132]
[epoch 101/1000, batch 21/100 -> loss before: 0.12197462836180953, loss after: 0.12005547143048871]
[epoch 101/1000, batch 31/100 -> loss before: 0.21255225470973124, loss after: 0.2083876744583284]
[epoch 101/1000, batch 41/100 -> loss before: 0.5387724380916513, loss after: 0.532084177514798]
[epoch 101/1000, batch 51/100 -> loss before: 0.19554079142845732, loss after: 0.19512801952440684]
[epoch 101/1000, batch 61/100 -> loss before: 0.2818566970228084, loss after: 0.26199094988618166]
[epoch 101/1000, batch 71/100 -> loss before: 0.23163428338959688, loss after: 0.23145891497452548]
[epoch 101/1000, batch 81/100 -> loss before: 0.306809070285168, loss after: 0.2946848674144598]
[epoch 101/1000, batch 91/100 -> loss before: 0.34445577234161917, loss after: 0.34362756753582496]
ENDING EPOCH 101/1000 [loss before: 0.26850747149938137, loss after: 0.2683344864636258; epoch time: 0.03666424751281738 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.17142557700615788, loss after: 0.16593359437007776]
[epoch 201/1000, batch 11/100 -> loss before: 0.20601884334892798, loss after: 0.181205287574302]
[epoch 201/1000, batch 21/100 -> loss before: 0.18277332935621052, loss after: 0.18196438173605148]
[epoch 201/1000, batch 31/100 -> loss before: 0.25489373912988683, loss after: 0.25464630013362066]
[epoch 201/1000, batch 41/100 -> loss before: 0.32316389276014335, loss after: 0.32310864331522776]
[epoch 201/1000, batch 51/100 -> loss before: 0.39685110873539586, loss after: 0.39683314931896124]
[epoch 201/1000, batch 61/100 -> loss before: 0.36264598295554207, loss after: 0.35637155362745326]
[epoch 201/1000, batch 71/100 -> loss before: 0.15109856816588318, loss after: 0.13476540651958804]
[epoch 201/1000, batch 81/100 -> loss before: 0.16945578231102576, loss after: 0.16935072958071892]
[epoch 201/1000, batch 91/100 -> loss before: 0.14036033010577456, loss after: 0.1398706970166035]
ENDING EPOCH 201/1000 [loss before: 0.2681488550689204, loss after: 0.26809442987189275; epoch time: 0.023736238479614258 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.20515314254617203, loss after: 0.19832324956423747]
[epoch 301/1000, batch 11/100 -> loss before: 0.5172100066928271, loss after: 0.46732702365514944]
[epoch 301/1000, batch 21/100 -> loss before: 0.1993183812362999, loss after: 0.17359992866783078]
[epoch 301/1000, batch 31/100 -> loss before: 0.19146419923735852, loss after: 0.18917774848808738]
[epoch 301/1000, batch 41/100 -> loss before: 0.09706094718920832, loss after: 0.09698789800056185]
[epoch 301/1000, batch 51/100 -> loss before: 0.33281196928938883, loss after: 0.32225898269541975]
[epoch 301/1000, batch 61/100 -> loss before: 0.2226266686629219, loss after: 0.21758711599900354]
[epoch 301/1000, batch 71/100 -> loss before: 0.3618229653150401, loss after: 0.32129771054662826]
[epoch 301/1000, batch 81/100 -> loss before: 0.14660387957501056, loss after: 0.14636947654533594]
[epoch 301/1000, batch 91/100 -> loss before: 0.3153510557874938, loss after: 0.28406731435999794]
ENDING EPOCH 301/1000 [loss before: 0.27005921690956847, loss after: 0.265963324785788; epoch time: 0.02241826057434082 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.3955953531841439, loss after: 0.3945845343987969]
[epoch 401/1000, batch 11/100 -> loss before: 0.347380314202736, loss after: 0.3436203664860257]
[epoch 401/1000, batch 21/100 -> loss before: 0.28364120648990204, loss after: 0.2781290346595394]
[epoch 401/1000, batch 31/100 -> loss before: 0.289247244552942, loss after: 0.27510733115389907]
[epoch 401/1000, batch 41/100 -> loss before: 0.1505746513737964, loss after: 0.14405173934279686]
[epoch 401/1000, batch 51/100 -> loss before: 0.3596762723759134, loss after: 0.3588620311514159]
[epoch 401/1000, batch 61/100 -> loss before: 0.1622154575824625, loss after: 0.1614152165711422]
[epoch 401/1000, batch 71/100 -> loss before: 0.26527823944151063, loss after: 0.25812901783128217]
[epoch 401/1000, batch 81/100 -> loss before: 0.40583513702507307, loss after: 0.389238932881339]
[epoch 401/1000, batch 91/100 -> loss before: 0.24436000390802953, loss after: 0.24070445828680653]
ENDING EPOCH 401/1000 [loss before: 0.26825656177436497, loss after: 0.2715095890270447; epoch time: 0.02147841453552246 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.2594684551496209, loss after: 0.23488935499408764]
[epoch 501/1000, batch 11/100 -> loss before: 0.32055820330820567, loss after: 0.318528242422056]
[epoch 501/1000, batch 21/100 -> loss before: 0.13845980957641704, loss after: 0.13843864690540789]
[epoch 501/1000, batch 31/100 -> loss before: 0.1747366772410778, loss after: 0.17468329130147559]
[epoch 501/1000, batch 41/100 -> loss before: 0.21438073636523405, loss after: 0.21403025510479604]
[epoch 501/1000, batch 51/100 -> loss before: 0.18581963904304438, loss after: 0.16616980072762136]
[epoch 501/1000, batch 61/100 -> loss before: 0.1688292404161273, loss after: 0.1609368374801151]
[epoch 501/1000, batch 71/100 -> loss before: 0.21108480187243422, loss after: 0.210947762357115]
[epoch 501/1000, batch 81/100 -> loss before: 0.22358691882462312, loss after: 0.22024241851435994]
[epoch 501/1000, batch 91/100 -> loss before: 0.37202092440103585, loss after: 0.3605131488787599]
ENDING EPOCH 501/1000 [loss before: 0.2679626541464397, loss after: 0.26328566319318625; epoch time: 0.02316594123840332 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.3068745083294252, loss after: 0.3027600339276413]
[epoch 601/1000, batch 11/100 -> loss before: 0.1779602635313146, loss after: 0.17693386999323024]
[epoch 601/1000, batch 21/100 -> loss before: 0.5151935373684086, loss after: 0.5104299416702721]
[epoch 601/1000, batch 31/100 -> loss before: 0.22950951535198677, loss after: 0.22387932685025042]
[epoch 601/1000, batch 41/100 -> loss before: 0.2097225469488791, loss after: 0.20534980057458868]
[epoch 601/1000, batch 51/100 -> loss before: 0.2527806895746167, loss after: 0.24694725766668396]
[epoch 601/1000, batch 61/100 -> loss before: 0.3866262731492656, loss after: 0.3842999383291491]
[epoch 601/1000, batch 71/100 -> loss before: 0.3431034024149303, loss after: 0.34202941293818834]
[epoch 601/1000, batch 81/100 -> loss before: 0.09386186116210864, loss after: 0.09357735374165212]
[epoch 601/1000, batch 91/100 -> loss before: 0.13632632312310236, loss after: 0.12750103639211074]
ENDING EPOCH 601/1000 [loss before: 0.2610949160130649, loss after: 0.26064081286012164; epoch time: 0.023606538772583008 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.26556374082155043, loss after: 0.25700082681828823]
[epoch 701/1000, batch 11/100 -> loss before: 0.2728289233218547, loss after: 0.26296715725960695]
[epoch 701/1000, batch 21/100 -> loss before: 0.2612005164265284, loss after: 0.2572715958777038]
[epoch 701/1000, batch 31/100 -> loss before: 0.18714470933262903, loss after: 0.18700298123413645]
[epoch 701/1000, batch 41/100 -> loss before: 0.14901245080637288, loss after: 0.14514916529996882]
[epoch 701/1000, batch 51/100 -> loss before: 0.3901605804912033, loss after: 0.3897641088697454]
[epoch 701/1000, batch 61/100 -> loss before: 0.12122474498759808, loss after: 0.12113694472871117]
[epoch 701/1000, batch 71/100 -> loss before: 0.2154391549643136, loss after: 0.21502791138308092]
[epoch 701/1000, batch 81/100 -> loss before: 0.27093174518476887, loss after: 0.2679094451215469]
[epoch 701/1000, batch 91/100 -> loss before: 0.3113847254053097, loss after: 0.3113241087411315]
ENDING EPOCH 701/1000 [loss before: 0.25809125760520896, loss after: 0.2589893698835161; epoch time: 0.024224281311035156 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.4552946521378895, loss after: 0.4189606159292477]
[epoch 801/1000, batch 11/100 -> loss before: 0.2849870089023363, loss after: 0.2808010724062887]
[epoch 801/1000, batch 21/100 -> loss before: 0.42267211666546, loss after: 0.4210774039928598]
[epoch 801/1000, batch 31/100 -> loss before: 0.2049568047414736, loss after: 0.20348882191548956]
[epoch 801/1000, batch 41/100 -> loss before: 0.29827783967336646, loss after: 0.29805200712272073]
[epoch 801/1000, batch 51/100 -> loss before: 0.26291337180106783, loss after: 0.26272685585010597]
[epoch 801/1000, batch 61/100 -> loss before: 0.23082582533552448, loss after: 0.226395079058822]
[epoch 801/1000, batch 71/100 -> loss before: 0.3149593453851647, loss after: 0.270695463202532]
[epoch 801/1000, batch 81/100 -> loss before: 0.33091144641810705, loss after: 0.32859531299054023]
[epoch 801/1000, batch 91/100 -> loss before: 0.12173036501489273, loss after: 0.12166977036306095]
ENDING EPOCH 801/1000 [loss before: 0.25270924233756786, loss after: 0.2523638072862471; epoch time: 0.021589994430541992 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.28218850508450755, loss after: 0.27955669619965934]
[epoch 901/1000, batch 11/100 -> loss before: 0.3880213313463736, loss after: 0.38582652196490974]
[epoch 901/1000, batch 21/100 -> loss before: 0.18115718956998964, loss after: 0.1770205741382591]
[epoch 901/1000, batch 31/100 -> loss before: 0.18724356570830392, loss after: 0.18409336333184423]
[epoch 901/1000, batch 41/100 -> loss before: 0.049643258635077146, loss after: 0.0495697046399681]
[epoch 901/1000, batch 51/100 -> loss before: 0.2543325684810388, loss after: 0.2475974483218561]
[epoch 901/1000, batch 61/100 -> loss before: 0.2956333175582319, loss after: 0.2954028159684594]
[epoch 901/1000, batch 71/100 -> loss before: 0.19506725602832736, loss after: 0.19485931077902807]
[epoch 901/1000, batch 81/100 -> loss before: 0.2087712149935533, loss after: 0.19592093325827503]
[epoch 901/1000, batch 91/100 -> loss before: 0.11553965068925276, loss after: 0.11532266495300925]
ENDING EPOCH 901/1000 [loss before: 0.24566293593694216, loss after: 0.2463112583578895; epoch time: 0.024675846099853516 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.09895805357726128, loss after: 0.09445306904480714]
[epoch 1000/1000, batch 11/100 -> loss before: 0.29279726917556764, loss after: 0.28331566268310443]
[epoch 1000/1000, batch 21/100 -> loss before: 0.1532103876476624, loss after: 0.1519326562689315]
[epoch 1000/1000, batch 31/100 -> loss before: 0.25459240847172526, loss after: 0.24535846499921746]
[epoch 1000/1000, batch 41/100 -> loss before: 0.2785594106701317, loss after: 0.2776823252010279]
[epoch 1000/1000, batch 51/100 -> loss before: 0.22797554267018066, loss after: 0.22789437478590918]
[epoch 1000/1000, batch 61/100 -> loss before: 0.20310473749892527, loss after: 0.18975496407838002]
[epoch 1000/1000, batch 71/100 -> loss before: 0.23986296353698155, loss after: 0.22945513134813528]
[epoch 1000/1000, batch 81/100 -> loss before: 0.3135435082844128, loss after: 0.3120775247994097]
[epoch 1000/1000, batch 91/100 -> loss before: 0.3268685656674507, loss after: 0.32376703129262374]
ENDING EPOCH 1000/1000 [loss before: 0.24302423776685575, loss after: 0.2411144093793177; epoch time: 0.023155689239501953 s]
FIT DONE. [time: 21.417224407196045 s]
LOSS TRAIN (MSE): 0.2411144093793177
LOSS TEST (MSE): 0.2326052687279589
R^2 TRAIN: 0.1482409022664174
R^2 TEST: 0.16187452532551838
EXPERIMENT DONE

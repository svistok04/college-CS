EXPERIMENT 3231 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 64, 32], activation_name=relu, targets_activation_name=linear, 
initialization_name=uniform, algo_name=rmsprop, learning_rate=0.0001, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 10753]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 20.679362556386955, loss after: 18.426228529104275]
[epoch 1/1000, batch 11/100 -> loss before: 12.508969520893057, loss after: 11.524707823758131]
[epoch 1/1000, batch 21/100 -> loss before: 5.017983944357577, loss after: 4.770874127345486]
[epoch 1/1000, batch 31/100 -> loss before: 2.7634341057204166, loss after: 2.6078412209682806]
[epoch 1/1000, batch 41/100 -> loss before: 1.5365383613579637, loss after: 1.4033227822377563]
[epoch 1/1000, batch 51/100 -> loss before: 2.4868936200351803, loss after: 2.2327191646623903]
[epoch 1/1000, batch 61/100 -> loss before: 0.5200797785004678, loss after: 0.48978290680590925]
[epoch 1/1000, batch 71/100 -> loss before: 0.4368734778164415, loss after: 0.40389584340421925]
[epoch 1/1000, batch 81/100 -> loss before: 0.09279805616516348, loss after: 0.09020104764028675]
[epoch 1/1000, batch 91/100 -> loss before: 0.4051000105216128, loss after: 0.37082118723180824]
ENDING EPOCH 1/1000 [loss before: 18.773492598911375, loss after: 0.2925860749968333; epoch time: 0.03748154640197754 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.18840937316197154, loss after: 0.17039321011279626]
[epoch 101/1000, batch 11/100 -> loss before: 0.10008455984522342, loss after: 0.08660533045257127]
[epoch 101/1000, batch 21/100 -> loss before: 0.09540522553738998, loss after: 0.08978234274336223]
[epoch 101/1000, batch 31/100 -> loss before: 0.10916455308517067, loss after: 0.10578679415041536]
[epoch 101/1000, batch 41/100 -> loss before: 0.41830310246308977, loss after: 0.3786143600462177]
[epoch 101/1000, batch 51/100 -> loss before: 0.11254057797031133, loss after: 0.07355409769742462]
[epoch 101/1000, batch 61/100 -> loss before: 0.2258309037859345, loss after: 0.21758865609216257]
[epoch 101/1000, batch 71/100 -> loss before: 0.2663811835799864, loss after: 0.26022153895172534]
[epoch 101/1000, batch 81/100 -> loss before: 0.30776120005096197, loss after: 0.2670122618331654]
[epoch 101/1000, batch 91/100 -> loss before: 0.09372717805300158, loss after: 0.0736308413467394]
ENDING EPOCH 101/1000 [loss before: 0.19451880614576458, loss after: 0.19214516959723807; epoch time: 0.033469438552856445 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.11099809771356503, loss after: 0.09507585824691808]
[epoch 201/1000, batch 11/100 -> loss before: 0.1497000590960588, loss after: 0.10582671736804761]
[epoch 201/1000, batch 21/100 -> loss before: 0.2759596580356528, loss after: 0.2236450730037871]
[epoch 201/1000, batch 31/100 -> loss before: 0.17959517874447567, loss after: 0.16531371639967196]
[epoch 201/1000, batch 41/100 -> loss before: 0.2501000948674235, loss after: 0.24344032162485493]
[epoch 201/1000, batch 51/100 -> loss before: 0.25581530019371546, loss after: 0.24468759444195448]
[epoch 201/1000, batch 61/100 -> loss before: 0.17443666705220198, loss after: 0.150765738170977]
[epoch 201/1000, batch 71/100 -> loss before: 0.12657715343364226, loss after: 0.10190407157831786]
[epoch 201/1000, batch 81/100 -> loss before: 0.10371591177885804, loss after: 0.07929138425462974]
[epoch 201/1000, batch 91/100 -> loss before: 0.15214792829635368, loss after: 0.12552315463076016]
ENDING EPOCH 201/1000 [loss before: 0.18055419653027296, loss after: 0.17872997775753754; epoch time: 0.03347516059875488 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.09074332398276579, loss after: 0.08495213184812925]
[epoch 301/1000, batch 11/100 -> loss before: 0.3614908453223285, loss after: 0.30014576564325274]
[epoch 301/1000, batch 21/100 -> loss before: 0.11424140731231366, loss after: 0.07181007349258042]
[epoch 301/1000, batch 31/100 -> loss before: 0.0804251505776653, loss after: 0.07280402734370091]
[epoch 301/1000, batch 41/100 -> loss before: 0.10714676048539536, loss after: 0.09539620670390234]
[epoch 301/1000, batch 51/100 -> loss before: 0.261300412222944, loss after: 0.2101476149892573]
[epoch 301/1000, batch 61/100 -> loss before: 0.14467013162545206, loss after: 0.12449035547077728]
[epoch 301/1000, batch 71/100 -> loss before: 0.28360017783983654, loss after: 0.1816279785428303]
[epoch 301/1000, batch 81/100 -> loss before: 0.1231526841957307, loss after: 0.10760237635182521]
[epoch 301/1000, batch 91/100 -> loss before: 0.11967860113044897, loss after: 0.05839094555315062]
ENDING EPOCH 301/1000 [loss before: 0.17586625137707487, loss after: 0.17067677946324658; epoch time: 0.0336604118347168 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.165894512514254, loss after: 0.13942141186738247]
[epoch 401/1000, batch 11/100 -> loss before: 0.2694575343470833, loss after: 0.2196079896140321]
[epoch 401/1000, batch 21/100 -> loss before: 0.15789544381927, loss after: 0.14213306853540802]
[epoch 401/1000, batch 31/100 -> loss before: 0.21274946787943155, loss after: 0.19250925658205337]
[epoch 401/1000, batch 41/100 -> loss before: 0.11320637350222751, loss after: 0.07740913881750683]
[epoch 401/1000, batch 51/100 -> loss before: 0.30588888920139684, loss after: 0.2570118871790025]
[epoch 401/1000, batch 61/100 -> loss before: 0.12589622103981873, loss after: 0.09209991955266769]
[epoch 401/1000, batch 71/100 -> loss before: 0.20742474726578783, loss after: 0.16259657074955913]
[epoch 401/1000, batch 81/100 -> loss before: 0.08553374411416517, loss after: 0.06562960978067023]
[epoch 401/1000, batch 91/100 -> loss before: 0.19410503109691518, loss after: 0.17201519359119272]
ENDING EPOCH 401/1000 [loss before: 0.17523271006570001, loss after: 0.17015118654260178; epoch time: 0.039888858795166016 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.17421015181686328, loss after: 0.12297846790718452]
[epoch 501/1000, batch 11/100 -> loss before: 0.09352736656874548, loss after: 0.08358867341640781]
[epoch 501/1000, batch 21/100 -> loss before: 0.11411261537521285, loss after: 0.1003689780602313]
[epoch 501/1000, batch 31/100 -> loss before: 0.10773172283781071, loss after: 0.08260734087431569]
[epoch 501/1000, batch 41/100 -> loss before: 0.1279422272720106, loss after: 0.09903745858390964]
[epoch 501/1000, batch 51/100 -> loss before: 0.094745449915381, loss after: 0.08044751561425985]
[epoch 501/1000, batch 61/100 -> loss before: 0.08262998723697895, loss after: 0.05002304369993715]
[epoch 501/1000, batch 71/100 -> loss before: 0.2317702523956715, loss after: 0.2060292118716372]
[epoch 501/1000, batch 81/100 -> loss before: 0.23783812461852832, loss after: 0.197918878682125]
[epoch 501/1000, batch 91/100 -> loss before: 0.2788681496932367, loss after: 0.228341771010536]
ENDING EPOCH 501/1000 [loss before: 0.15701667988081797, loss after: 0.1452755075506887; epoch time: 0.03389930725097656 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.08051539644125576, loss after: 0.047648483943351846]
[epoch 601/1000, batch 11/100 -> loss before: 0.11047239931450228, loss after: 0.09305344315248129]
[epoch 601/1000, batch 21/100 -> loss before: 0.1254721999458431, loss after: 0.1048392101877171]
[epoch 601/1000, batch 31/100 -> loss before: 0.09947136523335735, loss after: 0.0777028162521005]
[epoch 601/1000, batch 41/100 -> loss before: 0.09972226702135653, loss after: 0.07219093899627724]
[epoch 601/1000, batch 51/100 -> loss before: 0.14795150990401862, loss after: 0.09487962230830443]
[epoch 601/1000, batch 61/100 -> loss before: 0.26257671933946336, loss after: 0.15513712310853336]
[epoch 601/1000, batch 71/100 -> loss before: 0.06300515186382145, loss after: 0.053994053227896265]
[epoch 601/1000, batch 81/100 -> loss before: 0.027737980772292163, loss after: 0.018035676282470468]
[epoch 601/1000, batch 91/100 -> loss before: 0.0924469081313818, loss after: 0.07376296106286519]
ENDING EPOCH 601/1000 [loss before: 0.13126015634190943, loss after: 0.13728260645147863; epoch time: 0.036420345306396484 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.06058989129992283, loss after: 0.04265528030528666]
[epoch 701/1000, batch 11/100 -> loss before: 0.1425020712264291, loss after: 0.10272308681001747]
[epoch 701/1000, batch 21/100 -> loss before: 0.04847485829838437, loss after: 0.041010056814029645]
[epoch 701/1000, batch 31/100 -> loss before: 0.08040674026841792, loss after: 0.05195435215951403]
[epoch 701/1000, batch 41/100 -> loss before: 0.08927970100062319, loss after: 0.07286870242597834]
[epoch 701/1000, batch 51/100 -> loss before: 0.16891940527579735, loss after: 0.13866062064369997]
[epoch 701/1000, batch 61/100 -> loss before: 0.05626767285300481, loss after: 0.038202108858847846]
[epoch 701/1000, batch 71/100 -> loss before: 0.0727770293788817, loss after: 0.05454929984799604]
[epoch 701/1000, batch 81/100 -> loss before: 0.07011545735303341, loss after: 0.05787165872167649]
[epoch 701/1000, batch 91/100 -> loss before: 0.20049055071795782, loss after: 0.18377928468831511]
ENDING EPOCH 701/1000 [loss before: 0.12307588966440738, loss after: 0.12364908822577922; epoch time: 0.03346657752990723 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.38589630727839286, loss after: 0.25047305322816327]
[epoch 801/1000, batch 11/100 -> loss before: 0.13143282011914176, loss after: 0.09850966191634768]
[epoch 801/1000, batch 21/100 -> loss before: 0.1333231325603677, loss after: 0.1015557258141048]
[epoch 801/1000, batch 31/100 -> loss before: 0.054147820996022625, loss after: 0.030460110062148292]
[epoch 801/1000, batch 41/100 -> loss before: 0.06718074748273746, loss after: 0.05131944582523623]
[epoch 801/1000, batch 51/100 -> loss before: 0.20462762077847882, loss after: 0.16388072179122237]
[epoch 801/1000, batch 61/100 -> loss before: 0.11815903037680893, loss after: 0.09544961526390824]
[epoch 801/1000, batch 71/100 -> loss before: 0.06303312851178695, loss after: 0.03577265165614201]
[epoch 801/1000, batch 81/100 -> loss before: 0.0672984499005052, loss after: 0.0489728972392204]
[epoch 801/1000, batch 91/100 -> loss before: 0.07467346138384547, loss after: 0.035122792802112654]
ENDING EPOCH 801/1000 [loss before: 0.121155213642646, loss after: 0.10881777676199378; epoch time: 0.04194235801696777 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.05984484257339021, loss after: 0.04592681438628962]
[epoch 901/1000, batch 11/100 -> loss before: 0.10432188458734115, loss after: 0.0686989655045567]
[epoch 901/1000, batch 21/100 -> loss before: 0.1326383724664574, loss after: 0.09957823882134033]
[epoch 901/1000, batch 31/100 -> loss before: 0.13863275237168463, loss after: 0.10920469114982234]
[epoch 901/1000, batch 41/100 -> loss before: 0.04631569941947422, loss after: 0.022889041136863002]
[epoch 901/1000, batch 51/100 -> loss before: 0.12901871767974152, loss after: 0.10303882844854953]
[epoch 901/1000, batch 61/100 -> loss before: 0.15118793270812358, loss after: 0.11042250014732899]
[epoch 901/1000, batch 71/100 -> loss before: 0.05476407598857971, loss after: 0.03194417496367917]
[epoch 901/1000, batch 81/100 -> loss before: 0.12058884063305855, loss after: 0.055166900279953024]
[epoch 901/1000, batch 91/100 -> loss before: 0.016477635738072573, loss after: 0.011791073609916953]
ENDING EPOCH 901/1000 [loss before: 0.10929108946636588, loss after: 0.1004603941773754; epoch time: 0.04502272605895996 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.09028735148000476, loss after: 0.06277478200837842]
[epoch 1000/1000, batch 11/100 -> loss before: 0.04682448472000528, loss after: 0.034865006177845236]
[epoch 1000/1000, batch 21/100 -> loss before: 0.17010048893241686, loss after: 0.1493035274519141]
[epoch 1000/1000, batch 31/100 -> loss before: 0.10124082877116511, loss after: 0.08601736334968493]
[epoch 1000/1000, batch 41/100 -> loss before: 0.09853777243147435, loss after: 0.08171346501826217]
[epoch 1000/1000, batch 51/100 -> loss before: 0.15986356121595938, loss after: 0.13224700425325492]
[epoch 1000/1000, batch 61/100 -> loss before: 0.11818357804388328, loss after: 0.08856782700513963]
[epoch 1000/1000, batch 71/100 -> loss before: 0.10458985567235597, loss after: 0.06897885599611106]
[epoch 1000/1000, batch 81/100 -> loss before: 0.11406272769208663, loss after: 0.10379267984956612]
[epoch 1000/1000, batch 91/100 -> loss before: 0.1838288727880601, loss after: 0.12359820751499044]
ENDING EPOCH 1000/1000 [loss before: 0.0935678276579576, loss after: 0.09167790488893987; epoch time: 0.03827786445617676 s]
FIT DONE. [time: 32.57943415641785 s]
LOSS TRAIN (MSE): 0.09167790488893987
LOSS TEST (MSE): 0.09636685128357997
R^2 TRAIN: 0.6761392662042752
R^2 TEST: 0.6527700622749159
EXPERIMENT DONE

EXPERIMENT 3142 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 128, 64, 64, 32, 32], activation_name=sigmoid, targets_activation_name=linear, 
initialization_name=uniform, algo_name=adam, learning_rate=0.0001, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 32481]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 0.26392389365226554, loss after: 0.2638053848857781]
[epoch 1/1000, batch 11/100 -> loss before: 0.2784229045055993, loss after: 0.279146190539073]
[epoch 1/1000, batch 21/100 -> loss before: 0.2912415682655472, loss after: 0.29147161951278655]
[epoch 1/1000, batch 31/100 -> loss before: 0.34440570286021166, loss after: 0.3443111419081382]
[epoch 1/1000, batch 41/100 -> loss before: 0.3117845594407422, loss after: 0.31111779083644214]
[epoch 1/1000, batch 51/100 -> loss before: 0.17639373964872268, loss after: 0.17601209043936952]
[epoch 1/1000, batch 61/100 -> loss before: 0.24490810840748334, loss after: 0.2448595798381777]
[epoch 1/1000, batch 71/100 -> loss before: 0.32738563268874543, loss after: 0.3272295373722284]
[epoch 1/1000, batch 81/100 -> loss before: 0.3782255739727558, loss after: 0.3781198603006831]
[epoch 1/1000, batch 91/100 -> loss before: 0.332724134081572, loss after: 0.3328128956714532]
ENDING EPOCH 1/1000 [loss before: 0.2838936199301506, loss after: 0.2836153009994679; epoch time: 0.10173916816711426 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.2622206288914261, loss after: 0.2620834533269634]
[epoch 101/1000, batch 11/100 -> loss before: 0.2669272333228722, loss after: 0.2669171736204393]
[epoch 101/1000, batch 21/100 -> loss before: 0.18498728272434267, loss after: 0.18508275084601636]
[epoch 101/1000, batch 31/100 -> loss before: 0.1457022949675983, loss after: 0.14534231861602503]
[epoch 101/1000, batch 41/100 -> loss before: 0.257358624176249, loss after: 0.2571472644405632]
[epoch 101/1000, batch 51/100 -> loss before: 0.1609967791019325, loss after: 0.16104306199389057]
[epoch 101/1000, batch 61/100 -> loss before: 0.12374362380498143, loss after: 0.12374062211516024]
[epoch 101/1000, batch 71/100 -> loss before: 0.34112934101858794, loss after: 0.34116516086754917]
[epoch 101/1000, batch 81/100 -> loss before: 0.22906289713324096, loss after: 0.22892488036771366]
[epoch 101/1000, batch 91/100 -> loss before: 0.2719210755120841, loss after: 0.2717594057867284]
ENDING EPOCH 101/1000 [loss before: 0.23512773814390278, loss after: 0.2350727307501636; epoch time: 0.09667468070983887 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.5236104234191229, loss after: 0.523465964217865]
[epoch 201/1000, batch 11/100 -> loss before: 0.3716775221643188, loss after: 0.37166876469051424]
[epoch 201/1000, batch 21/100 -> loss before: 0.20102821221010375, loss after: 0.20103154516218963]
[epoch 201/1000, batch 31/100 -> loss before: 0.21447343319368978, loss after: 0.21453399518473124]
[epoch 201/1000, batch 41/100 -> loss before: 0.21805768409369558, loss after: 0.21791758205161532]
[epoch 201/1000, batch 51/100 -> loss before: 0.3876019801282815, loss after: 0.38764319941825576]
[epoch 201/1000, batch 61/100 -> loss before: 0.24129879470110277, loss after: 0.24143381571496603]
[epoch 201/1000, batch 71/100 -> loss before: 0.09080354876985242, loss after: 0.09091116574207132]
[epoch 201/1000, batch 81/100 -> loss before: 0.28668483123311717, loss after: 0.28627474101300143]
[epoch 201/1000, batch 91/100 -> loss before: 0.33246127545018755, loss after: 0.3320580578483948]
ENDING EPOCH 201/1000 [loss before: 0.23171301201664798, loss after: 0.23181766938261336; epoch time: 0.0970909595489502 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.11515817348447865, loss after: 0.11516078192227061]
[epoch 301/1000, batch 11/100 -> loss before: 0.04277055669916787, loss after: 0.04219433449817182]
[epoch 301/1000, batch 21/100 -> loss before: 0.30378577181924493, loss after: 0.30392423407327374]
[epoch 301/1000, batch 31/100 -> loss before: 0.17330766731796815, loss after: 0.1733327717534588]
[epoch 301/1000, batch 41/100 -> loss before: 0.28200275548991577, loss after: 0.2819864716674874]
[epoch 301/1000, batch 51/100 -> loss before: 0.22878848593679005, loss after: 0.22884998468842613]
[epoch 301/1000, batch 61/100 -> loss before: 0.1532851555278982, loss after: 0.15321838043714914]
[epoch 301/1000, batch 71/100 -> loss before: 0.03880933992107883, loss after: 0.038723833968576364]
[epoch 301/1000, batch 81/100 -> loss before: 0.0822651299254937, loss after: 0.08252803728591653]
[epoch 301/1000, batch 91/100 -> loss before: 0.3150604915480204, loss after: 0.31513010908388256]
ENDING EPOCH 301/1000 [loss before: 0.23104743754870669, loss after: 0.23091855069474224; epoch time: 0.13155460357666016 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.5159088934708302, loss after: 0.514945275258144]
[epoch 401/1000, batch 11/100 -> loss before: 0.23398842186832552, loss after: 0.23393363148844903]
[epoch 401/1000, batch 21/100 -> loss before: 0.14132924464708624, loss after: 0.14067318430747217]
[epoch 401/1000, batch 31/100 -> loss before: 0.1620717644982438, loss after: 0.16176842240714204]
[epoch 401/1000, batch 41/100 -> loss before: 0.19825069057663913, loss after: 0.19824092045711694]
[epoch 401/1000, batch 51/100 -> loss before: 0.33408095733727355, loss after: 0.3329888357064137]
[epoch 401/1000, batch 61/100 -> loss before: 0.2782968157475442, loss after: 0.278300640116096]
[epoch 401/1000, batch 71/100 -> loss before: 0.226460326250926, loss after: 0.22597071734733426]
[epoch 401/1000, batch 81/100 -> loss before: 0.44657637432971214, loss after: 0.44588267387794006]
[epoch 401/1000, batch 91/100 -> loss before: 0.08985540287737889, loss after: 0.08987711311038615]
ENDING EPOCH 401/1000 [loss before: 0.23048935180775487, loss after: 0.23041742748539223; epoch time: 0.12613511085510254 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.14095073888049875, loss after: 0.14088002955070528]
[epoch 501/1000, batch 11/100 -> loss before: 0.4140545121889813, loss after: 0.4136822604926119]
[epoch 501/1000, batch 21/100 -> loss before: 0.4863386656682417, loss after: 0.4862221961282357]
[epoch 501/1000, batch 31/100 -> loss before: 0.11246159821944164, loss after: 0.11234641484074046]
[epoch 501/1000, batch 41/100 -> loss before: 0.22081914025529098, loss after: 0.2203918692696222]
[epoch 501/1000, batch 51/100 -> loss before: 0.1595346265155037, loss after: 0.15958062962661898]
[epoch 501/1000, batch 61/100 -> loss before: 0.4689530985133604, loss after: 0.46833207001370675]
[epoch 501/1000, batch 71/100 -> loss before: 0.24188754353446176, loss after: 0.24182449852006765]
[epoch 501/1000, batch 81/100 -> loss before: 0.29531827198203053, loss after: 0.2952163567094443]
[epoch 501/1000, batch 91/100 -> loss before: 0.20746718759057256, loss after: 0.2074400646487816]
ENDING EPOCH 501/1000 [loss before: 0.2299548057329879, loss after: 0.229798378711152; epoch time: 0.10892963409423828 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.20611804812066956, loss after: 0.20588001265942765]
[epoch 601/1000, batch 11/100 -> loss before: 0.28961381503095646, loss after: 0.28987187097872746]
[epoch 601/1000, batch 21/100 -> loss before: 0.43881941624567966, loss after: 0.4378838477435954]
[epoch 601/1000, batch 31/100 -> loss before: 0.12279593211221769, loss after: 0.1223414755145839]
[epoch 601/1000, batch 41/100 -> loss before: 0.21427463302678396, loss after: 0.21363675631694257]
[epoch 601/1000, batch 51/100 -> loss before: 0.29016313999982, loss after: 0.2901212778852996]
[epoch 601/1000, batch 61/100 -> loss before: 0.18377345470409567, loss after: 0.18340495390122177]
[epoch 601/1000, batch 71/100 -> loss before: 0.20697935652518754, loss after: 0.2069538852945326]
[epoch 601/1000, batch 81/100 -> loss before: 0.22453594406457394, loss after: 0.2243877682815129]
[epoch 601/1000, batch 91/100 -> loss before: 0.511136207944117, loss after: 0.5111647992555841]
ENDING EPOCH 601/1000 [loss before: 0.2272395923547894, loss after: 0.22694005700578823; epoch time: 0.11534500122070312 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.1697016422698637, loss after: 0.170190297572203]
[epoch 701/1000, batch 11/100 -> loss before: 0.21631626165844212, loss after: 0.21505542452298262]
[epoch 701/1000, batch 21/100 -> loss before: 0.18414048344964085, loss after: 0.18278263301782488]
[epoch 701/1000, batch 31/100 -> loss before: 0.2916019206854181, loss after: 0.2917189034091434]
[epoch 701/1000, batch 41/100 -> loss before: 0.11213089584884199, loss after: 0.11152443607696905]
[epoch 701/1000, batch 51/100 -> loss before: 0.12595270043574697, loss after: 0.12578540968713398]
[epoch 701/1000, batch 61/100 -> loss before: 0.18999520042707732, loss after: 0.18998106621240216]
[epoch 701/1000, batch 71/100 -> loss before: 0.1375682814934354, loss after: 0.13590869490684976]
[epoch 701/1000, batch 81/100 -> loss before: 0.20129814639151186, loss after: 0.20171491168575476]
[epoch 701/1000, batch 91/100 -> loss before: 0.1970226065422933, loss after: 0.1976305951911695]
ENDING EPOCH 701/1000 [loss before: 0.19741882602643687, loss after: 0.19551577016591895; epoch time: 0.09835314750671387 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.12676276020599805, loss after: 0.12617602829392313]
[epoch 801/1000, batch 11/100 -> loss before: 0.11521600006610219, loss after: 0.11489436122267324]
[epoch 801/1000, batch 21/100 -> loss before: 0.15671614453547433, loss after: 0.15601168819201122]
[epoch 801/1000, batch 31/100 -> loss before: 0.09019061664805939, loss after: 0.08983836378385279]
[epoch 801/1000, batch 41/100 -> loss before: 0.23527378640786875, loss after: 0.23577395756159142]
[epoch 801/1000, batch 51/100 -> loss before: 0.2368729331692252, loss after: 0.23633732383463474]
[epoch 801/1000, batch 61/100 -> loss before: 0.1547030404975393, loss after: 0.15454944056132897]
[epoch 801/1000, batch 71/100 -> loss before: 0.19803487276274204, loss after: 0.19805035288472272]
[epoch 801/1000, batch 81/100 -> loss before: 0.058320167313497075, loss after: 0.05855781167270966]
[epoch 801/1000, batch 91/100 -> loss before: 0.18305288096380118, loss after: 0.18291635053894795]
ENDING EPOCH 801/1000 [loss before: 0.18031564430799288, loss after: 0.1801039428052082; epoch time: 0.10224723815917969 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.14053855970582185, loss after: 0.1405294610965816]
[epoch 901/1000, batch 11/100 -> loss before: 0.1202287769084667, loss after: 0.11928516522311465]
[epoch 901/1000, batch 21/100 -> loss before: 0.03166984387559128, loss after: 0.03166701747652939]
[epoch 901/1000, batch 31/100 -> loss before: 0.13708974717498404, loss after: 0.13610644295446378]
[epoch 901/1000, batch 41/100 -> loss before: 0.08708913267946156, loss after: 0.0864682910604002]
[epoch 901/1000, batch 51/100 -> loss before: 0.1904316591088258, loss after: 0.18954568698638102]
[epoch 901/1000, batch 61/100 -> loss before: 0.25500408554991716, loss after: 0.25391260402936333]
[epoch 901/1000, batch 71/100 -> loss before: 0.24480636050146254, loss after: 0.24474179644742944]
[epoch 901/1000, batch 81/100 -> loss before: 0.1381378463867091, loss after: 0.13791305719168837]
[epoch 901/1000, batch 91/100 -> loss before: 0.11568389415823457, loss after: 0.1166415347650206]
ENDING EPOCH 901/1000 [loss before: 0.1493798394303995, loss after: 0.1483912879602015; epoch time: 0.11282110214233398 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.14800491675095806, loss after: 0.14787106549174894]
[epoch 1000/1000, batch 11/100 -> loss before: 0.1591177364432223, loss after: 0.15919188347230817]
[epoch 1000/1000, batch 21/100 -> loss before: 0.13854065307000285, loss after: 0.13737139825012148]
[epoch 1000/1000, batch 31/100 -> loss before: 0.12628223274511913, loss after: 0.12596869816601938]
[epoch 1000/1000, batch 41/100 -> loss before: 0.04192371084366585, loss after: 0.04187271709866783]
[epoch 1000/1000, batch 51/100 -> loss before: 0.15187507465291378, loss after: 0.15194694649703083]
[epoch 1000/1000, batch 61/100 -> loss before: 0.18125179047087198, loss after: 0.18050294351699295]
[epoch 1000/1000, batch 71/100 -> loss before: 0.15814023897737967, loss after: 0.15770864239490281]
[epoch 1000/1000, batch 81/100 -> loss before: 0.2735862710966952, loss after: 0.2704725987264097]
[epoch 1000/1000, batch 91/100 -> loss before: 0.24878545694062026, loss after: 0.24841035647409523]
ENDING EPOCH 1000/1000 [loss before: 0.13519727165315956, loss after: 0.1345405045250477; epoch time: 0.11149883270263672 s]
FIT DONE. [time: 99.70533204078674 s]
LOSS TRAIN (MSE): 0.1345405045250477
LOSS TEST (MSE): 0.13169349555502663
R^2 TRAIN: 0.524723142686198
R^2 TEST: 0.5254807680100868
EXPERIMENT DONE

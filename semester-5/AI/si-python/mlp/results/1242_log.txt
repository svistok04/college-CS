EXPERIMENT 1242 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 128, 64, 64, 32, 32], activation_name=relu, targets_activation_name=linear, 
initialization_name=uniform, algo_name=adam, learning_rate=0.01, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 32481]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 0.87553713426397, loss after: 34.893227623600595]
[epoch 1/1000, batch 11/100 -> loss before: 0.14817288249483615, loss after: 0.35365637877228623]
[epoch 1/1000, batch 21/100 -> loss before: 0.46788974491227797, loss after: 0.8475792963880145]
[epoch 1/1000, batch 31/100 -> loss before: 0.5982780116186612, loss after: 0.6021784339640722]
[epoch 1/1000, batch 41/100 -> loss before: 0.4698955129841056, loss after: 0.4434675776697721]
[epoch 1/1000, batch 51/100 -> loss before: 0.23288635642885563, loss after: 0.15261615344601182]
[epoch 1/1000, batch 61/100 -> loss before: 0.22102590016794688, loss after: 0.21430450170079265]
[epoch 1/1000, batch 71/100 -> loss before: 0.5873958819916261, loss after: 0.5234923281882496]
[epoch 1/1000, batch 81/100 -> loss before: 0.673790643205461, loss after: 0.4052656221893617]
[epoch 1/1000, batch 91/100 -> loss before: 0.4803393977033738, loss after: 0.4373555701954156]
ENDING EPOCH 1/1000 [loss before: 1.102092538201909, loss after: 0.2665981047738494; epoch time: 0.09839200973510742 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.16607672183248434, loss after: 0.1580838258481768]
[epoch 101/1000, batch 11/100 -> loss before: 0.17255285356146882, loss after: 0.16998524693367317]
[epoch 101/1000, batch 21/100 -> loss before: 0.09337882861279995, loss after: 0.09456586759991407]
[epoch 101/1000, batch 31/100 -> loss before: 0.05309534085963459, loss after: 0.0525402007839054]
[epoch 101/1000, batch 41/100 -> loss before: 0.09634989946836511, loss after: 0.09575887678356225]
[epoch 101/1000, batch 51/100 -> loss before: 0.14240899997561834, loss after: 0.125550619555708]
[epoch 101/1000, batch 61/100 -> loss before: 0.06747840320444878, loss after: 0.06371670300699835]
[epoch 101/1000, batch 71/100 -> loss before: 0.20320266144446922, loss after: 0.18624480211252586]
[epoch 101/1000, batch 81/100 -> loss before: 0.14482874233540094, loss after: 0.14266881630494876]
[epoch 101/1000, batch 91/100 -> loss before: 0.0414504003949014, loss after: 0.03987399283633263]
ENDING EPOCH 101/1000 [loss before: 0.15760042027230994, loss after: 0.13302065494925888; epoch time: 0.09009957313537598 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.33546277526761126, loss after: 0.3331846703175557]
[epoch 201/1000, batch 11/100 -> loss before: 0.28015037662761383, loss after: 0.2802829833336548]
[epoch 201/1000, batch 21/100 -> loss before: 0.2918010695899141, loss after: 0.286768985570838]
[epoch 201/1000, batch 31/100 -> loss before: 0.19851483131261133, loss after: 0.18346052243662808]
[epoch 201/1000, batch 41/100 -> loss before: 0.17384767206650814, loss after: 0.17266939314662158]
[epoch 201/1000, batch 51/100 -> loss before: 0.22410148847695108, loss after: 0.22316895805808623]
[epoch 201/1000, batch 61/100 -> loss before: 0.11033078736949439, loss after: 0.11005154108607326]
[epoch 201/1000, batch 71/100 -> loss before: 0.030001122865443475, loss after: 0.029596079953836934]
[epoch 201/1000, batch 81/100 -> loss before: 0.3776705949924931, loss after: 0.3735276864693813]
[epoch 201/1000, batch 91/100 -> loss before: 0.19400721552451433, loss after: 0.19157012837604348]
ENDING EPOCH 201/1000 [loss before: 0.18058045695602937, loss after: 0.1747368179863327; epoch time: 0.09144973754882812 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.061179822579241, loss after: 0.059362179689375606]
[epoch 301/1000, batch 11/100 -> loss before: 0.04126197650085925, loss after: 0.04032484987567943]
[epoch 301/1000, batch 21/100 -> loss before: 0.23647160021927668, loss after: 0.2350582053811996]
[epoch 301/1000, batch 31/100 -> loss before: 0.07402641479284999, loss after: 0.06895599228285297]
[epoch 301/1000, batch 41/100 -> loss before: 0.17318873055885187, loss after: 0.16643277067625845]
[epoch 301/1000, batch 51/100 -> loss before: 0.06992871414673722, loss after: 0.06965093303455192]
[epoch 301/1000, batch 61/100 -> loss before: 0.1392830485378431, loss after: 0.13775399932620594]
[epoch 301/1000, batch 71/100 -> loss before: 0.06676663658186853, loss after: 0.06760773090522276]
[epoch 301/1000, batch 81/100 -> loss before: 0.04224950340367545, loss after: 0.04120099808723873]
[epoch 301/1000, batch 91/100 -> loss before: 0.25053143356233964, loss after: 0.25064208736942806]
ENDING EPOCH 301/1000 [loss before: 0.17055806217233743, loss after: 0.1678746540220363; epoch time: 0.09010028839111328 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.46165965629683436, loss after: 0.4611924077124872]
[epoch 401/1000, batch 11/100 -> loss before: 0.20026981910981417, loss after: 0.20017910880394818]
[epoch 401/1000, batch 21/100 -> loss before: 0.0400692675275334, loss after: 0.035899899794901685]
[epoch 401/1000, batch 31/100 -> loss before: 0.07086120656230833, loss after: 0.06891783986788183]
[epoch 401/1000, batch 41/100 -> loss before: 0.06888133628414236, loss after: 0.06424160781580009]
[epoch 401/1000, batch 51/100 -> loss before: 0.3936576810121447, loss after: 0.3916145083359823]
[epoch 401/1000, batch 61/100 -> loss before: 0.16037024992531812, loss after: 0.1577562308812596]
[epoch 401/1000, batch 71/100 -> loss before: 0.14558896274730543, loss after: 0.14541873973187186]
[epoch 401/1000, batch 81/100 -> loss before: 0.3288619756859911, loss after: 0.3270709816673427]
[epoch 401/1000, batch 91/100 -> loss before: 0.11066682950639022, loss after: 0.10965491867116033]
ENDING EPOCH 401/1000 [loss before: 0.16164301455175023, loss after: 0.16319268288134367; epoch time: 0.08724641799926758 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.1303804985193941, loss after: 0.12921985532075647]
[epoch 501/1000, batch 11/100 -> loss before: 0.3191280430289657, loss after: 0.3163634280317473]
[epoch 501/1000, batch 21/100 -> loss before: 0.3057328625827983, loss after: 0.3052916105610778]
[epoch 501/1000, batch 31/100 -> loss before: 0.043034529252133705, loss after: 0.03529369434379909]
[epoch 501/1000, batch 41/100 -> loss before: 0.21676061554803888, loss after: 0.2156744153063904]
[epoch 501/1000, batch 51/100 -> loss before: 0.18081302188073772, loss after: 0.17982923410808221]
[epoch 501/1000, batch 61/100 -> loss before: 0.25829561129507816, loss after: 0.24801373484142464]
[epoch 501/1000, batch 71/100 -> loss before: 0.12293780146610034, loss after: 0.12257374702223409]
[epoch 501/1000, batch 81/100 -> loss before: 0.2852608911229231, loss after: 0.28383609311763947]
[epoch 501/1000, batch 91/100 -> loss before: 0.20029746253869396, loss after: 0.19962105018686294]
ENDING EPOCH 501/1000 [loss before: 0.16402119374389484, loss after: 0.16396146919237026; epoch time: 0.08649373054504395 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.06898470060129147, loss after: 0.0684053485021398]
[epoch 601/1000, batch 11/100 -> loss before: 0.22326609338463488, loss after: 0.22358344205379818]
[epoch 601/1000, batch 21/100 -> loss before: 0.3693374143240231, loss after: 0.368651519609458]
[epoch 601/1000, batch 31/100 -> loss before: 0.11748396531293126, loss after: 0.11621635230091702]
[epoch 601/1000, batch 41/100 -> loss before: 0.14366936511665945, loss after: 0.1435524944301157]
[epoch 601/1000, batch 51/100 -> loss before: 0.04716354562902715, loss after: 0.045856755770839294]
[epoch 601/1000, batch 61/100 -> loss before: 0.24475223222432688, loss after: 0.2428286964382068]
[epoch 601/1000, batch 71/100 -> loss before: 0.0792262460172263, loss after: 0.07755668613958684]
[epoch 601/1000, batch 81/100 -> loss before: 0.08194140671447488, loss after: 0.08171147420760252]
[epoch 601/1000, batch 91/100 -> loss before: 0.2866846234042502, loss after: 0.2843672279917118]
ENDING EPOCH 601/1000 [loss before: 0.1632812384353432, loss after: 0.1611131927012675; epoch time: 0.09192705154418945 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.14981892180484446, loss after: 0.14913465757550204]
[epoch 701/1000, batch 11/100 -> loss before: 0.18105889293789076, loss after: 0.17735328454787885]
[epoch 701/1000, batch 21/100 -> loss before: 0.196206638393101, loss after: 0.19402439664714904]
[epoch 701/1000, batch 31/100 -> loss before: 0.28031897007446993, loss after: 0.2782014753095883]
[epoch 701/1000, batch 41/100 -> loss before: 0.11387846409872784, loss after: 0.11104993361679405]
[epoch 701/1000, batch 51/100 -> loss before: 0.019602621621341812, loss after: 0.018064043142947076]
[epoch 701/1000, batch 61/100 -> loss before: 0.10464133418932516, loss after: 0.1025332963714605]
[epoch 701/1000, batch 71/100 -> loss before: 0.006484638040509539, loss after: 0.005354387694564346]
[epoch 701/1000, batch 81/100 -> loss before: 0.14283589501350796, loss after: 0.14060056528377424]
[epoch 701/1000, batch 91/100 -> loss before: 0.2256706189778332, loss after: 0.226488283458272]
ENDING EPOCH 701/1000 [loss before: 0.16313179487252677, loss after: 0.1628094807991111; epoch time: 0.09405708312988281 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.13198823588090725, loss after: 0.13007835020511074]
[epoch 801/1000, batch 11/100 -> loss before: 0.10446008573422352, loss after: 0.10450875036493419]
[epoch 801/1000, batch 21/100 -> loss before: 0.12220923607295815, loss after: 0.12115514227754831]
[epoch 801/1000, batch 31/100 -> loss before: 0.09666688340177074, loss after: 0.09142682195833565]
[epoch 801/1000, batch 41/100 -> loss before: 0.2341446917507426, loss after: 0.23360366619024445]
[epoch 801/1000, batch 51/100 -> loss before: 0.14954741358690582, loss after: 0.14282115339398718]
[epoch 801/1000, batch 61/100 -> loss before: 0.2615533627459685, loss after: 0.24820797662773328]
[epoch 801/1000, batch 71/100 -> loss before: 0.21252164605074558, loss after: 0.20895759527980431]
[epoch 801/1000, batch 81/100 -> loss before: 0.026109661582744914, loss after: 0.025748008693651226]
[epoch 801/1000, batch 91/100 -> loss before: 0.2227928547317523, loss after: 0.222960218347587]
ENDING EPOCH 801/1000 [loss before: 0.1637549490532612, loss after: 0.1622445077127611; epoch time: 0.09011006355285645 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.15720739257462266, loss after: 0.1571117801016674]
[epoch 901/1000, batch 11/100 -> loss before: 0.16496163194146235, loss after: 0.1620272920421717]
[epoch 901/1000, batch 21/100 -> loss before: 0.026702975886971105, loss after: 0.027079622342929915]
[epoch 901/1000, batch 31/100 -> loss before: 0.14233132172222313, loss after: 0.1414468122803933]
[epoch 901/1000, batch 41/100 -> loss before: 0.1680579846302725, loss after: 0.1676384574272389]
[epoch 901/1000, batch 51/100 -> loss before: 0.2202642565327758, loss after: 0.2206916803289063]
[epoch 901/1000, batch 61/100 -> loss before: 0.26133644105589127, loss after: 0.2603082418719549]
[epoch 901/1000, batch 71/100 -> loss before: 0.33216740658469746, loss after: 0.3322909781101631]
[epoch 901/1000, batch 81/100 -> loss before: 0.10916314848616697, loss after: 0.10824445365851332]
[epoch 901/1000, batch 91/100 -> loss before: 0.1846468450954457, loss after: 0.1838285439587885]
ENDING EPOCH 901/1000 [loss before: 0.16361164240617074, loss after: 0.1621876416753065; epoch time: 0.08918190002441406 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.2529953831458736, loss after: 0.25333707166761066]
[epoch 1000/1000, batch 11/100 -> loss before: 0.10609266827267325, loss after: 0.10498134986334047]
[epoch 1000/1000, batch 21/100 -> loss before: 0.17489637251347528, loss after: 0.17373584699590278]
[epoch 1000/1000, batch 31/100 -> loss before: 0.19671247072667342, loss after: 0.19675129124724178]
[epoch 1000/1000, batch 41/100 -> loss before: 0.061101004277134455, loss after: 0.06100418646578931]
[epoch 1000/1000, batch 51/100 -> loss before: 0.14490171520557976, loss after: 0.14387619987823458]
[epoch 1000/1000, batch 61/100 -> loss before: 0.09444978900572007, loss after: 0.09355579275388495]
[epoch 1000/1000, batch 71/100 -> loss before: 0.05705291860428362, loss after: 0.05453428455139168]
[epoch 1000/1000, batch 81/100 -> loss before: 0.35945629278024605, loss after: 0.35643845190037166]
[epoch 1000/1000, batch 91/100 -> loss before: 0.3343478985826065, loss after: 0.3319032126335205]
ENDING EPOCH 1000/1000 [loss before: 0.1466322748326175, loss after: 0.14689728915803993; epoch time: 0.08779239654541016 s]
FIT DONE. [time: 85.55874276161194 s]
LOSS TRAIN (MSE): 0.14689728915803993
LOSS TEST (MSE): 0.14257159740711559
R^2 TRAIN: 0.4810716506124585
R^2 TEST: 0.48628468991521634
EXPERIMENT DONE

EXPERIMENT 2112 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 128, 64, 64, 32, 32], activation_name=sigmoid, targets_activation_name=linear, 
initialization_name=uniform, algo_name=sgd_simple, learning_rate=0.001, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 32481]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 0.26392389365226554, loss after: 0.26382396752347137]
[epoch 1/1000, batch 11/100 -> loss before: 0.35945734588602196, loss after: 0.2870186147106663]
[epoch 1/1000, batch 21/100 -> loss before: 0.30276680582797355, loss after: 0.28835279838045413]
[epoch 1/1000, batch 31/100 -> loss before: 0.3428802064198163, loss after: 0.3422376275454923]
[epoch 1/1000, batch 41/100 -> loss before: 0.2880607165547497, loss after: 0.28715697249546557]
[epoch 1/1000, batch 51/100 -> loss before: 0.17035164734805783, loss after: 0.1450957533997999]
[epoch 1/1000, batch 61/100 -> loss before: 0.25270321403941515, loss after: 0.24013268877488653]
[epoch 1/1000, batch 71/100 -> loss before: 0.3241005453491113, loss after: 0.32395822345813585]
[epoch 1/1000, batch 81/100 -> loss before: 0.37956366781908785, loss after: 0.37883186260942975]
[epoch 1/1000, batch 91/100 -> loss before: 0.3398552413519898, loss after: 0.3317264244360729]
ENDING EPOCH 1/1000 [loss before: 0.2838936199301506, loss after: 0.2885962726048705; epoch time: 0.048675537109375 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.31047186979722874, loss after: 0.2815946033328103]
[epoch 101/1000, batch 11/100 -> loss before: 0.24307488720518772, loss after: 0.24291490110948372]
[epoch 101/1000, batch 21/100 -> loss before: 0.2806498599207309, loss after: 0.27936520485994926]
[epoch 101/1000, batch 31/100 -> loss before: 0.14271932750894495, loss after: 0.1420271025227632]
[epoch 101/1000, batch 41/100 -> loss before: 0.3695526035165837, loss after: 0.3691602512845029]
[epoch 101/1000, batch 51/100 -> loss before: 0.16449572053945655, loss after: 0.16323973347826332]
[epoch 101/1000, batch 61/100 -> loss before: 0.16447053886454638, loss after: 0.16391654991956578]
[epoch 101/1000, batch 71/100 -> loss before: 0.37776217481423346, loss after: 0.3611638094407793]
[epoch 101/1000, batch 81/100 -> loss before: 0.3729104374726796, loss after: 0.29525990668956725]
[epoch 101/1000, batch 91/100 -> loss before: 0.3615384785135549, loss after: 0.3601527315997778]
ENDING EPOCH 101/1000 [loss before: 0.28309662844850103, loss after: 0.28407832270820765; epoch time: 0.05028820037841797 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.5774545152000597, loss after: 0.5651760935879311]
[epoch 201/1000, batch 11/100 -> loss before: 0.45814789647581133, loss after: 0.4579956377816604]
[epoch 201/1000, batch 21/100 -> loss before: 0.36225023414354124, loss after: 0.308992918652589]
[epoch 201/1000, batch 31/100 -> loss before: 0.27940074020902406, loss after: 0.27696718558702343]
[epoch 201/1000, batch 41/100 -> loss before: 0.2593757880572588, loss after: 0.23790027170696243]
[epoch 201/1000, batch 51/100 -> loss before: 0.3868402388781044, loss after: 0.3868028568941041]
[epoch 201/1000, batch 61/100 -> loss before: 0.31600558956273156, loss after: 0.3065679575139677]
[epoch 201/1000, batch 71/100 -> loss before: 0.18373811718040509, loss after: 0.17906476669272958]
[epoch 201/1000, batch 81/100 -> loss before: 0.27478543899802277, loss after: 0.26094195951866783]
[epoch 201/1000, batch 91/100 -> loss before: 0.455692594440111, loss after: 0.44859789013569584]
ENDING EPOCH 201/1000 [loss before: 0.28371172067867734, loss after: 0.2870403461438159; epoch time: 0.046814918518066406 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.14831279424906976, loss after: 0.147476465994054]
[epoch 301/1000, batch 11/100 -> loss before: 0.10221259749054408, loss after: 0.100782671750505]
[epoch 301/1000, batch 21/100 -> loss before: 0.4135023402777275, loss after: 0.38591394914808846]
[epoch 301/1000, batch 31/100 -> loss before: 0.28147047961218974, loss after: 0.27947290783298706]
[epoch 301/1000, batch 41/100 -> loss before: 0.32771241507247983, loss after: 0.32717729579857285]
[epoch 301/1000, batch 51/100 -> loss before: 0.32063778759326955, loss after: 0.31498196804283407]
[epoch 301/1000, batch 61/100 -> loss before: 0.17517340488702693, loss after: 0.17513911349590933]
[epoch 301/1000, batch 71/100 -> loss before: 0.1805143881042542, loss after: 0.17988603953079801]
[epoch 301/1000, batch 81/100 -> loss before: 0.26678490771868174, loss after: 0.25521822438503244]
[epoch 301/1000, batch 91/100 -> loss before: 0.36791937047953255, loss after: 0.3453492710569986]
ENDING EPOCH 301/1000 [loss before: 0.28355941439654353, loss after: 0.28640177709203785; epoch time: 0.04729151725769043 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.5355816532306299, loss after: 0.5161013296835266]
[epoch 401/1000, batch 11/100 -> loss before: 0.241752395687594, loss after: 0.2407365479347449]
[epoch 401/1000, batch 21/100 -> loss before: 0.20047908001647646, loss after: 0.17881575000579034]
[epoch 401/1000, batch 31/100 -> loss before: 0.28695578876881084, loss after: 0.2867536449794386]
[epoch 401/1000, batch 41/100 -> loss before: 0.20583947459478238, loss after: 0.20371621545399599]
[epoch 401/1000, batch 51/100 -> loss before: 0.30589863556314795, loss after: 0.30208313709757506]
[epoch 401/1000, batch 61/100 -> loss before: 0.2832449272797478, loss after: 0.28287682491464583]
[epoch 401/1000, batch 71/100 -> loss before: 0.2973933311404514, loss after: 0.2669226918949637]
[epoch 401/1000, batch 81/100 -> loss before: 0.4557954905895145, loss after: 0.43479578295094123]
[epoch 401/1000, batch 91/100 -> loss before: 0.1545529278509099, loss after: 0.15413375970738963]
ENDING EPOCH 401/1000 [loss before: 0.284263067765019, loss after: 0.2833770810407273; epoch time: 0.044220924377441406 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.2886203065392812, loss after: 0.28140212133770726]
[epoch 501/1000, batch 11/100 -> loss before: 0.3997132691029279, loss after: 0.39756200782674045]
[epoch 501/1000, batch 21/100 -> loss before: 0.6374739638531082, loss after: 0.6261327184327701]
[epoch 501/1000, batch 31/100 -> loss before: 0.11362809802600252, loss after: 0.1131917247418927]
[epoch 501/1000, batch 41/100 -> loss before: 0.29377809435492624, loss after: 0.25717464186604216]
[epoch 501/1000, batch 51/100 -> loss before: 0.21232297638886538, loss after: 0.21018442828907621]
[epoch 501/1000, batch 61/100 -> loss before: 0.4986677456342181, loss after: 0.4803588027697396]
[epoch 501/1000, batch 71/100 -> loss before: 0.2648138689072557, loss after: 0.26304840624911024]
[epoch 501/1000, batch 81/100 -> loss before: 0.5043010149202652, loss after: 0.5042794891968276]
[epoch 501/1000, batch 91/100 -> loss before: 0.2768724648665041, loss after: 0.27262809597080984]
ENDING EPOCH 501/1000 [loss before: 0.2830842631630251, loss after: 0.28613161216190575; epoch time: 0.05086827278137207 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.2693313167270237, loss after: 0.2687510954917772]
[epoch 601/1000, batch 11/100 -> loss before: 0.3940823262546469, loss after: 0.3632990189398472]
[epoch 601/1000, batch 21/100 -> loss before: 0.6119785961497862, loss after: 0.6091498308376296]
[epoch 601/1000, batch 31/100 -> loss before: 0.14721659450666916, loss after: 0.1424398921894689]
[epoch 601/1000, batch 41/100 -> loss before: 0.3504774216849512, loss after: 0.3497592191483058]
[epoch 601/1000, batch 51/100 -> loss before: 0.3091577623706282, loss after: 0.3081888859716709]
[epoch 601/1000, batch 61/100 -> loss before: 0.16920149745919527, loss after: 0.1668759952849868]
[epoch 601/1000, batch 71/100 -> loss before: 0.2118589866381695, loss after: 0.2084595617506829]
[epoch 601/1000, batch 81/100 -> loss before: 0.3148711170779027, loss after: 0.3110408882538672]
[epoch 601/1000, batch 91/100 -> loss before: 0.5272051243436318, loss after: 0.5231683180390083]
ENDING EPOCH 601/1000 [loss before: 0.283945474082749, loss after: 0.2878949419662809; epoch time: 0.04950451850891113 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.2754925317555878, loss after: 0.2573323185934132]
[epoch 701/1000, batch 11/100 -> loss before: 0.38274954893443286, loss after: 0.38000849326179914]
[epoch 701/1000, batch 21/100 -> loss before: 0.3535907282782191, loss after: 0.33126064326025206]
[epoch 701/1000, batch 31/100 -> loss before: 0.25530576948467515, loss after: 0.2547516320038897]
[epoch 701/1000, batch 41/100 -> loss before: 0.14622761466516265, loss after: 0.1386766431785516]
[epoch 701/1000, batch 51/100 -> loss before: 0.2950284654334247, loss after: 0.29253049117517926]
[epoch 701/1000, batch 61/100 -> loss before: 0.31453506085719507, loss after: 0.31450814300056296]
[epoch 701/1000, batch 71/100 -> loss before: 0.10176981611267574, loss after: 0.09909509262434335]
[epoch 701/1000, batch 81/100 -> loss before: 0.3166921377955379, loss after: 0.3107215771183386]
[epoch 701/1000, batch 91/100 -> loss before: 0.3197129974576004, loss after: 0.30913502213650174]
ENDING EPOCH 701/1000 [loss before: 0.2937287997667131, loss after: 0.28359689112592107; epoch time: 0.045571327209472656 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.25603366405658523, loss after: 0.253794355846565]
[epoch 801/1000, batch 11/100 -> loss before: 0.3018591252507078, loss after: 0.3008840235617264]
[epoch 801/1000, batch 21/100 -> loss before: 0.2259159152756899, loss after: 0.20487421842421866]
[epoch 801/1000, batch 31/100 -> loss before: 0.1782717707262232, loss after: 0.17456870889792106]
[epoch 801/1000, batch 41/100 -> loss before: 0.2675608546719158, loss after: 0.2648349685347661]
[epoch 801/1000, batch 51/100 -> loss before: 0.21240385892145924, loss after: 0.20840621439702267]
[epoch 801/1000, batch 61/100 -> loss before: 0.36918026557374745, loss after: 0.3682974305355201]
[epoch 801/1000, batch 71/100 -> loss before: 0.29047203606003236, loss after: 0.28481764676354654]
[epoch 801/1000, batch 81/100 -> loss before: 0.19009582739932895, loss after: 0.1801831598067604]
[epoch 801/1000, batch 91/100 -> loss before: 0.3294885296261737, loss after: 0.32946349077031895]
ENDING EPOCH 801/1000 [loss before: 0.28571322042755687, loss after: 0.2830865558413983; epoch time: 0.047547101974487305 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.22244877056034684, loss after: 0.21554222497691278]
[epoch 901/1000, batch 11/100 -> loss before: 0.2892404122409475, loss after: 0.28891919796793114]
[epoch 901/1000, batch 21/100 -> loss before: 0.11850300002579599, loss after: 0.11253110524071974]
[epoch 901/1000, batch 31/100 -> loss before: 0.21985784577476658, loss after: 0.20912508912795288]
[epoch 901/1000, batch 41/100 -> loss before: 0.29771396657534976, loss after: 0.2968940261117245]
[epoch 901/1000, batch 51/100 -> loss before: 0.2977557607413136, loss after: 0.29606392370441065]
[epoch 901/1000, batch 61/100 -> loss before: 0.31336862516340297, loss after: 0.3131536644580074]
[epoch 901/1000, batch 71/100 -> loss before: 0.39972522231601537, loss after: 0.38794668097171203]
[epoch 901/1000, batch 81/100 -> loss before: 0.20905728985481775, loss after: 0.19278844116710858]
[epoch 901/1000, batch 91/100 -> loss before: 0.45056998026020845, loss after: 0.41910814736709234]
ENDING EPOCH 901/1000 [loss before: 0.2859822475774676, loss after: 0.2835490468985198; epoch time: 0.0489044189453125 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.35788605719399263, loss after: 0.35769924520635815]
[epoch 1000/1000, batch 11/100 -> loss before: 0.27436305196938626, loss after: 0.2587555666851968]
[epoch 1000/1000, batch 21/100 -> loss before: 0.24123302135766353, loss after: 0.22256650140061413]
[epoch 1000/1000, batch 31/100 -> loss before: 0.3483002765243638, loss after: 0.34692952230975344]
[epoch 1000/1000, batch 41/100 -> loss before: 0.29166509927273043, loss after: 0.28268410973441865]
[epoch 1000/1000, batch 51/100 -> loss before: 0.19820323056074163, loss after: 0.19820307067033444]
[epoch 1000/1000, batch 61/100 -> loss before: 0.22877836804892793, loss after: 0.22267499350443262]
[epoch 1000/1000, batch 71/100 -> loss before: 0.2422002724963402, loss after: 0.24087944392578137]
[epoch 1000/1000, batch 81/100 -> loss before: 0.35393256971885206, loss after: 0.34043007128724473]
[epoch 1000/1000, batch 91/100 -> loss before: 0.4204845003680184, loss after: 0.41338927488766786]
ENDING EPOCH 1000/1000 [loss before: 0.2900272353956519, loss after: 0.2832235081756506; epoch time: 0.0464482307434082 s]
FIT DONE. [time: 40.792882204055786 s]
LOSS TRAIN (MSE): 0.2832235081756506
LOSS TEST (MSE): 0.27816272577613355
R^2 TRAIN: -0.0005134093878218504
R^2 TEST: -0.00227852899811376
EXPERIMENT DONE

EXPERIMENT 3211 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 64, 32], activation_name=relu, targets_activation_name=linear, 
initialization_name=uniform, algo_name=sgd_simple, learning_rate=0.0001, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 10753]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 20.679362556386955, loss after: 0.3975461021725875]
[epoch 1/1000, batch 11/100 -> loss before: 0.5034572715592565, loss after: 0.4671527679417021]
[epoch 1/1000, batch 21/100 -> loss before: 0.13872691470025703, loss after: 0.12526124863313404]
[epoch 1/1000, batch 31/100 -> loss before: 0.5275925692172809, loss after: 0.4746259486972895]
[epoch 1/1000, batch 41/100 -> loss before: 0.19443290087150894, loss after: 0.18519881997902674]
[epoch 1/1000, batch 51/100 -> loss before: 0.4976683712196489, loss after: 0.32909845017738126]
[epoch 1/1000, batch 61/100 -> loss before: 0.49000244748852256, loss after: 0.3744275767879687]
[epoch 1/1000, batch 71/100 -> loss before: 0.4431461864402638, loss after: 0.3643549355186256]
[epoch 1/1000, batch 81/100 -> loss before: 0.0987943869731771, loss after: 0.09609112975083497]
[epoch 1/1000, batch 91/100 -> loss before: 0.38811373292542406, loss after: 0.3593837745704797]
ENDING EPOCH 1/1000 [loss before: 18.773492598911375, loss after: 0.2852617137711075; epoch time: 0.022379159927368164 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.28174654353806133, loss after: 0.2622600058966299]
[epoch 101/1000, batch 11/100 -> loss before: 0.11053641441747883, loss after: 0.09736006454741002]
[epoch 101/1000, batch 21/100 -> loss before: 0.11994533437770785, loss after: 0.1141367879365716]
[epoch 101/1000, batch 31/100 -> loss before: 0.15610594591105292, loss after: 0.15223968283031553]
[epoch 101/1000, batch 41/100 -> loss before: 0.46912204237450883, loss after: 0.4392407774926754]
[epoch 101/1000, batch 51/100 -> loss before: 0.15050231829416988, loss after: 0.10345437754154094]
[epoch 101/1000, batch 61/100 -> loss before: 0.24817535832843704, loss after: 0.24451656137363323]
[epoch 101/1000, batch 71/100 -> loss before: 0.259264248816493, loss after: 0.255914350394186]
[epoch 101/1000, batch 81/100 -> loss before: 0.30709160886539166, loss after: 0.2682641586184765]
[epoch 101/1000, batch 91/100 -> loss before: 0.17274992928523825, loss after: 0.1579126067647359]
ENDING EPOCH 101/1000 [loss before: 0.2328445273588527, loss after: 0.2257292608179871; epoch time: 0.02185988426208496 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.12787655735010678, loss after: 0.11871865624696462]
[epoch 201/1000, batch 11/100 -> loss before: 0.18569994485616176, loss after: 0.13874844231639932]
[epoch 201/1000, batch 21/100 -> loss before: 0.23828405334095049, loss after: 0.22927042014728016]
[epoch 201/1000, batch 31/100 -> loss before: 0.2322954442189143, loss after: 0.22205974319614813]
[epoch 201/1000, batch 41/100 -> loss before: 0.25803631498328244, loss after: 0.2541937904266103]
[epoch 201/1000, batch 51/100 -> loss before: 0.2803749472367699, loss after: 0.2727985137807162]
[epoch 201/1000, batch 61/100 -> loss before: 0.21895828687092372, loss after: 0.20493972426837992]
[epoch 201/1000, batch 71/100 -> loss before: 0.13750890457782167, loss after: 0.11727394417877006]
[epoch 201/1000, batch 81/100 -> loss before: 0.11794649487225492, loss after: 0.10672706249177186]
[epoch 201/1000, batch 91/100 -> loss before: 0.17819645420972105, loss after: 0.13817591307545637]
ENDING EPOCH 201/1000 [loss before: 0.21140613260730293, loss after: 0.20990528192412403; epoch time: 0.020242929458618164 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.11533192081863645, loss after: 0.1138578420289782]
[epoch 301/1000, batch 11/100 -> loss before: 0.4343534088391725, loss after: 0.34348793640423503]
[epoch 301/1000, batch 21/100 -> loss before: 0.18122246212952703, loss after: 0.12126124900963484]
[epoch 301/1000, batch 31/100 -> loss before: 0.1302978096306824, loss after: 0.11639098006795012]
[epoch 301/1000, batch 41/100 -> loss before: 0.11096657781376255, loss after: 0.10671696525857957]
[epoch 301/1000, batch 51/100 -> loss before: 0.31323356881838327, loss after: 0.26529775157043534]
[epoch 301/1000, batch 61/100 -> loss before: 0.1641546608262768, loss after: 0.15962975548028951]
[epoch 301/1000, batch 71/100 -> loss before: 0.28953568129203167, loss after: 0.19356857910715536]
[epoch 301/1000, batch 81/100 -> loss before: 0.13094337021414332, loss after: 0.11727773353411057]
[epoch 301/1000, batch 91/100 -> loss before: 0.22908772935127883, loss after: 0.11911310825812933]
ENDING EPOCH 301/1000 [loss before: 0.20084662568052808, loss after: 0.207780251859295; epoch time: 0.02243947982788086 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.22535282014943014, loss after: 0.2149970530412558]
[epoch 401/1000, batch 11/100 -> loss before: 0.2572482664263589, loss after: 0.221520043851184]
[epoch 401/1000, batch 21/100 -> loss before: 0.18750295335828027, loss after: 0.16590333646142041]
[epoch 401/1000, batch 31/100 -> loss before: 0.24653766365936777, loss after: 0.23429573174920856]
[epoch 401/1000, batch 41/100 -> loss before: 0.1486260060371814, loss after: 0.13412622321277828]
[epoch 401/1000, batch 51/100 -> loss before: 0.34279787276239554, loss after: 0.32705148179608784]
[epoch 401/1000, batch 61/100 -> loss before: 0.13758494620960565, loss after: 0.12362226924617178]
[epoch 401/1000, batch 71/100 -> loss before: 0.2453741653378879, loss after: 0.2277950393028502]
[epoch 401/1000, batch 81/100 -> loss before: 0.1492399222025334, loss after: 0.13295229723774213]
[epoch 401/1000, batch 91/100 -> loss before: 0.2167986185085713, loss after: 0.19906963149509468]
ENDING EPOCH 401/1000 [loss before: 0.199522849045675, loss after: 0.20109328541888966; epoch time: 0.02072286605834961 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.21949742914503548, loss after: 0.18791737850912843]
[epoch 501/1000, batch 11/100 -> loss before: 0.15186837938337497, loss after: 0.1462522608679451]
[epoch 501/1000, batch 21/100 -> loss before: 0.12159735246802657, loss after: 0.11560540535726616]
[epoch 501/1000, batch 31/100 -> loss before: 0.13200781993320354, loss after: 0.12184021379216499]
[epoch 501/1000, batch 41/100 -> loss before: 0.22902943149305366, loss after: 0.17978790975211129]
[epoch 501/1000, batch 51/100 -> loss before: 0.09893383547830352, loss after: 0.0849591040125125]
[epoch 501/1000, batch 61/100 -> loss before: 0.12143796757897825, loss after: 0.07613803198381877]
[epoch 501/1000, batch 71/100 -> loss before: 0.24014627937674607, loss after: 0.21682112066547649]
[epoch 501/1000, batch 81/100 -> loss before: 0.28154149809751716, loss after: 0.27064917426185237]
[epoch 501/1000, batch 91/100 -> loss before: 0.36354702765432795, loss after: 0.323617800830083]
ENDING EPOCH 501/1000 [loss before: 0.19878324722766258, loss after: 0.18966668216825133; epoch time: 0.02112126350402832 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.19411943890309905, loss after: 0.16839343302802917]
[epoch 601/1000, batch 11/100 -> loss before: 0.16653843676258745, loss after: 0.15216463249426002]
[epoch 601/1000, batch 21/100 -> loss before: 0.27463661182797894, loss after: 0.26268155706415836]
[epoch 601/1000, batch 31/100 -> loss before: 0.0742300195619897, loss after: 0.07184514152922825]
[epoch 601/1000, batch 41/100 -> loss before: 0.10607652888188215, loss after: 0.09582072342935452]
[epoch 601/1000, batch 51/100 -> loss before: 0.25085996510262143, loss after: 0.18427949018704975]
[epoch 601/1000, batch 61/100 -> loss before: 0.2990023223822728, loss after: 0.24852247271170608]
[epoch 601/1000, batch 71/100 -> loss before: 0.13118125419428434, loss after: 0.126986640708504]
[epoch 601/1000, batch 81/100 -> loss before: 0.03512472195078874, loss after: 0.029991992868415484]
[epoch 601/1000, batch 91/100 -> loss before: 0.06897548449870525, loss after: 0.059937471022751244]
ENDING EPOCH 601/1000 [loss before: 0.18785161541388334, loss after: 0.18871678068195638; epoch time: 0.021015405654907227 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.13048374567079515, loss after: 0.12048877235213318]
[epoch 701/1000, batch 11/100 -> loss before: 0.23733646918705129, loss after: 0.2067301047583901]
[epoch 701/1000, batch 21/100 -> loss before: 0.15376499028636223, loss after: 0.1454729941603416]
[epoch 701/1000, batch 31/100 -> loss before: 0.13515583563322361, loss after: 0.11494428258453104]
[epoch 701/1000, batch 41/100 -> loss before: 0.1360469633125571, loss after: 0.12639864138447082]
[epoch 701/1000, batch 51/100 -> loss before: 0.25226679436436966, loss after: 0.23700452568187144]
[epoch 701/1000, batch 61/100 -> loss before: 0.061887321790079684, loss after: 0.05631646317477009]
[epoch 701/1000, batch 71/100 -> loss before: 0.1936606898552265, loss after: 0.18516782971978163]
[epoch 701/1000, batch 81/100 -> loss before: 0.1438068096684391, loss after: 0.1352164324569663]
[epoch 701/1000, batch 91/100 -> loss before: 0.2824202476846378, loss after: 0.28035345898149233]
ENDING EPOCH 701/1000 [loss before: 0.19469929708787634, loss after: 0.19074009905587883; epoch time: 0.021918058395385742 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.34801514048044546, loss after: 0.30501150743446037]
[epoch 801/1000, batch 11/100 -> loss before: 0.17008932731805843, loss after: 0.16431120908281072]
[epoch 801/1000, batch 21/100 -> loss before: 0.29558300455943315, loss after: 0.2725970219620255]
[epoch 801/1000, batch 31/100 -> loss before: 0.07646360022680469, loss after: 0.07312876038549392]
[epoch 801/1000, batch 41/100 -> loss before: 0.1920110835250844, loss after: 0.1759246177164298]
[epoch 801/1000, batch 51/100 -> loss before: 0.217646325609485, loss after: 0.1857099358907103]
[epoch 801/1000, batch 61/100 -> loss before: 0.2124609245315901, loss after: 0.20723359185774096]
[epoch 801/1000, batch 71/100 -> loss before: 0.12826833373328814, loss after: 0.11913778212044272]
[epoch 801/1000, batch 81/100 -> loss before: 0.19907311415328982, loss after: 0.1900747186377822]
[epoch 801/1000, batch 91/100 -> loss before: 0.11824461902049847, loss after: 0.10426857084873195]
ENDING EPOCH 801/1000 [loss before: 0.18888171867935302, loss after: 0.1865930194906019; epoch time: 0.029746294021606445 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.22098641580471287, loss after: 0.1922328102749487]
[epoch 901/1000, batch 11/100 -> loss before: 0.1886488664896551, loss after: 0.15326937948468797]
[epoch 901/1000, batch 21/100 -> loss before: 0.09590949567519323, loss after: 0.07643158678220087]
[epoch 901/1000, batch 31/100 -> loss before: 0.159211186197249, loss after: 0.15305824466386916]
[epoch 901/1000, batch 41/100 -> loss before: 0.05456487495526073, loss after: 0.048932977154446326]
[epoch 901/1000, batch 51/100 -> loss before: 0.18983579163903513, loss after: 0.1707254626659836]
[epoch 901/1000, batch 61/100 -> loss before: 0.29234747046523424, loss after: 0.26463170238116746]
[epoch 901/1000, batch 71/100 -> loss before: 0.10292730681563608, loss after: 0.09585975524311596]
[epoch 901/1000, batch 81/100 -> loss before: 0.24797018446860192, loss after: 0.2249789940166115]
[epoch 901/1000, batch 91/100 -> loss before: 0.08335751441559001, loss after: 0.0815008442471555]
ENDING EPOCH 901/1000 [loss before: 0.18798795247082103, loss after: 0.18366993449809113; epoch time: 0.022053003311157227 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.08959592551811484, loss after: 0.0828108895859069]
[epoch 1000/1000, batch 11/100 -> loss before: 0.21680969315488388, loss after: 0.19775046127903292]
[epoch 1000/1000, batch 21/100 -> loss before: 0.18441741817881696, loss after: 0.17426791725107943]
[epoch 1000/1000, batch 31/100 -> loss before: 0.21615464409619686, loss after: 0.21147518593399775]
[epoch 1000/1000, batch 41/100 -> loss before: 0.20418295626586533, loss after: 0.1854479411724595]
[epoch 1000/1000, batch 51/100 -> loss before: 0.2816582286543391, loss after: 0.2783668141531032]
[epoch 1000/1000, batch 61/100 -> loss before: 0.11124052910287788, loss after: 0.10768524301158071]
[epoch 1000/1000, batch 71/100 -> loss before: 0.21971800017937415, loss after: 0.21767521679765892]
[epoch 1000/1000, batch 81/100 -> loss before: 0.22553222602836556, loss after: 0.20122005482931765]
[epoch 1000/1000, batch 91/100 -> loss before: 0.2750023900021216, loss after: 0.21603502990824283]
ENDING EPOCH 1000/1000 [loss before: 0.1889686064142376, loss after: 0.18254848084694278; epoch time: 0.021657943725585938 s]
FIT DONE. [time: 19.82594609260559 s]
LOSS TRAIN (MSE): 0.18254848084694278
LOSS TEST (MSE): 0.18473854960003408
R^2 TRAIN: 0.3551304970155569
R^2 TEST: 0.3343483343221755
EXPERIMENT DONE

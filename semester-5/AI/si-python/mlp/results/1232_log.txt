EXPERIMENT 1232 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 128, 64, 64, 32, 32], activation_name=relu, targets_activation_name=linear, 
initialization_name=uniform, algo_name=rmsprop, learning_rate=0.01, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 32481]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 0.87553713426397, loss after: 1622.809864702127]
[epoch 1/1000, batch 11/100 -> loss before: 0.5795004405004648, loss after: 0.19434815297428432]
[epoch 1/1000, batch 21/100 -> loss before: 0.29450282536261196, loss after: 0.23648838765411187]
[epoch 1/1000, batch 31/100 -> loss before: 0.33005471051347546, loss after: 0.3041404708406791]
[epoch 1/1000, batch 41/100 -> loss before: 1.361162899166745, loss after: 0.503442483467248]
[epoch 1/1000, batch 51/100 -> loss before: 0.477134567711276, loss after: 0.9411425703406534]
[epoch 1/1000, batch 61/100 -> loss before: 0.37159639780342657, loss after: 0.23913564590829406]
[epoch 1/1000, batch 71/100 -> loss before: 0.41290725456629856, loss after: 0.3370593183300489]
[epoch 1/1000, batch 81/100 -> loss before: 0.37922535663318013, loss after: 0.35215667228473885]
[epoch 1/1000, batch 91/100 -> loss before: 0.42314675656936707, loss after: 0.33581709739696447]
ENDING EPOCH 1/1000 [loss before: 1.102092538201909, loss after: 0.2964302639176807; epoch time: 0.06650233268737793 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.1341508549697186, loss after: 0.17690639295075755]
[epoch 101/1000, batch 11/100 -> loss before: 0.13603986180093025, loss after: 0.10577241495962011]
[epoch 101/1000, batch 21/100 -> loss before: 0.061654163000751896, loss after: 0.04995812977979762]
[epoch 101/1000, batch 31/100 -> loss before: 0.03098689104057145, loss after: 0.014953994636290513]
[epoch 101/1000, batch 41/100 -> loss before: 0.023459873661453814, loss after: 0.00666420860831019]
[epoch 101/1000, batch 51/100 -> loss before: 0.1269911587367725, loss after: 0.047051821051377424]
[epoch 101/1000, batch 61/100 -> loss before: 0.03232565746914079, loss after: 0.026852144252092026]
[epoch 101/1000, batch 71/100 -> loss before: 0.20178655507802584, loss after: 0.16550788311015402]
[epoch 101/1000, batch 81/100 -> loss before: 0.13879867006857383, loss after: 0.12093834857306666]
[epoch 101/1000, batch 91/100 -> loss before: 0.07562875780408337, loss after: 0.013557545799658033]
ENDING EPOCH 101/1000 [loss before: 0.09291932005497017, loss after: 0.10704086036868458; epoch time: 0.09096503257751465 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.3846388543896233, loss after: 0.38142811647328023]
[epoch 201/1000, batch 11/100 -> loss before: 0.315939455565897, loss after: 0.2922715267718886]
[epoch 201/1000, batch 21/100 -> loss before: 0.21192650725440804, loss after: 0.19822872639372055]
[epoch 201/1000, batch 31/100 -> loss before: 0.12678785767083897, loss after: 0.09637051879882076]
[epoch 201/1000, batch 41/100 -> loss before: 0.04701196751641401, loss after: 0.03555712082990918]
[epoch 201/1000, batch 51/100 -> loss before: 0.12119421828775734, loss after: 0.11182283050577366]
[epoch 201/1000, batch 61/100 -> loss before: 0.067990386460605, loss after: 0.06672686543793753]
[epoch 201/1000, batch 71/100 -> loss before: 0.02114637966498858, loss after: 0.020565680476340588]
[epoch 201/1000, batch 81/100 -> loss before: 0.26577243473251794, loss after: 0.21269109552594584]
[epoch 201/1000, batch 91/100 -> loss before: 0.13118657495302422, loss after: 0.10762610509217863]
ENDING EPOCH 201/1000 [loss before: 0.09457177689971316, loss after: 0.11119942406849175; epoch time: 0.07018375396728516 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.046174641721746845, loss after: 0.038327449418349036]
[epoch 301/1000, batch 11/100 -> loss before: 0.02013814794853746, loss after: 0.013675145962628319]
[epoch 301/1000, batch 21/100 -> loss before: 0.0555104593900073, loss after: 0.03792498632715397]
[epoch 301/1000, batch 31/100 -> loss before: 0.02681568572445741, loss after: 0.01492627524378598]
[epoch 301/1000, batch 41/100 -> loss before: 0.06837738129846493, loss after: 0.05025881207721169]
[epoch 301/1000, batch 51/100 -> loss before: 0.06769986613992858, loss after: 0.04933183338948617]
[epoch 301/1000, batch 61/100 -> loss before: 0.05877026192254645, loss after: 0.04800188980762576]
[epoch 301/1000, batch 71/100 -> loss before: 0.023540016269155174, loss after: 0.014573680130704625]
[epoch 301/1000, batch 81/100 -> loss before: 0.05770436441384204, loss after: 0.028535172066343713]
[epoch 301/1000, batch 91/100 -> loss before: 0.07383275842719503, loss after: 0.06501472941990578]
ENDING EPOCH 301/1000 [loss before: 0.07568007894822643, loss after: 0.08508485614241823; epoch time: 0.07056641578674316 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.31684534187598923, loss after: 0.3277384359129341]
[epoch 401/1000, batch 11/100 -> loss before: 0.09162912005808234, loss after: 0.04851844143392824]
[epoch 401/1000, batch 21/100 -> loss before: 0.017860141775784877, loss after: 0.013431851953338004]
[epoch 401/1000, batch 31/100 -> loss before: 0.07496329565162477, loss after: 0.070489855951507]
[epoch 401/1000, batch 41/100 -> loss before: 0.03232185275337368, loss after: 0.02126001805376884]
[epoch 401/1000, batch 51/100 -> loss before: 0.13560253555549745, loss after: 0.11319333385481782]
[epoch 401/1000, batch 61/100 -> loss before: 0.031101323549341742, loss after: 0.011392048518711551]
[epoch 401/1000, batch 71/100 -> loss before: 0.08416889882718333, loss after: 0.06286614504636508]
[epoch 401/1000, batch 81/100 -> loss before: 0.1793153480445837, loss after: 0.20158370319681868]
[epoch 401/1000, batch 91/100 -> loss before: 0.0649803801337941, loss after: 0.045299370036548735]
ENDING EPOCH 401/1000 [loss before: 0.07413349370129318, loss after: 0.08888242729905146; epoch time: 0.07069659233093262 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.10402334069612937, loss after: 0.023122398240755414]
[epoch 501/1000, batch 11/100 -> loss before: 0.13159089081997075, loss after: 0.09723595101626598]
[epoch 501/1000, batch 21/100 -> loss before: 0.13757686578553274, loss after: 0.11160380528049192]
[epoch 501/1000, batch 31/100 -> loss before: 0.07961983171863854, loss after: 0.03441266357515963]
[epoch 501/1000, batch 41/100 -> loss before: 0.05367285039308058, loss after: 0.03145736827757075]
[epoch 501/1000, batch 51/100 -> loss before: 0.08767929529929844, loss after: 0.0745918069124945]
[epoch 501/1000, batch 61/100 -> loss before: 0.032166067812417515, loss after: 0.01243014686881124]
[epoch 501/1000, batch 71/100 -> loss before: 0.020836770304829843, loss after: 0.011200820319110825]
[epoch 501/1000, batch 81/100 -> loss before: 0.11081860134542362, loss after: 0.06016507079034752]
[epoch 501/1000, batch 91/100 -> loss before: 0.11529550374892424, loss after: 0.05005299613033467]
ENDING EPOCH 501/1000 [loss before: 0.10601573671111182, loss after: 0.05906180874930355; epoch time: 0.07169604301452637 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.043962969049663556, loss after: 0.032328953037363]
[epoch 601/1000, batch 11/100 -> loss before: 0.03616048022789626, loss after: 0.05081693718728288]
[epoch 601/1000, batch 21/100 -> loss before: 0.20816707701096065, loss after: 0.17528967067597195]
[epoch 601/1000, batch 31/100 -> loss before: 0.06762047975829935, loss after: 0.040216569846799013]
[epoch 601/1000, batch 41/100 -> loss before: 0.1804737414339341, loss after: 0.08284742464681406]
[epoch 601/1000, batch 51/100 -> loss before: 0.08624926934305413, loss after: 0.03695871543898868]
[epoch 601/1000, batch 61/100 -> loss before: 0.06346505181776889, loss after: 0.06237257247894037]
[epoch 601/1000, batch 71/100 -> loss before: 0.034731178434873014, loss after: 0.022606116751364484]
[epoch 601/1000, batch 81/100 -> loss before: 0.027288348212022952, loss after: 0.018034367711297017]
[epoch 601/1000, batch 91/100 -> loss before: 0.10200846830493408, loss after: 0.044573607908145574]
ENDING EPOCH 601/1000 [loss before: 0.05792058382236372, loss after: 0.05535165691335259; epoch time: 0.06916308403015137 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.08145006117908012, loss after: 0.050851787299745224]
[epoch 701/1000, batch 11/100 -> loss before: 0.01888449477914645, loss after: 0.029680883099053184]
[epoch 701/1000, batch 21/100 -> loss before: 0.032079565382273426, loss after: 0.013032946926098011]
[epoch 701/1000, batch 31/100 -> loss before: 0.051181347995378566, loss after: 0.0417614446389202]
[epoch 701/1000, batch 41/100 -> loss before: 0.029506557214696593, loss after: 0.018267411974701463]
[epoch 701/1000, batch 51/100 -> loss before: 0.038959329656488385, loss after: 0.009913517393651768]
[epoch 701/1000, batch 61/100 -> loss before: 0.12164652473739675, loss after: 0.034226828119200164]
[epoch 701/1000, batch 71/100 -> loss before: 0.04917257897430179, loss after: 0.06399900054399414]
[epoch 701/1000, batch 81/100 -> loss before: 0.01753640458597453, loss after: 0.015703476891482885]
[epoch 701/1000, batch 91/100 -> loss before: 0.02471989519581926, loss after: 0.007692849560342824]
ENDING EPOCH 701/1000 [loss before: 0.05702448459338835, loss after: 0.05196788724127184; epoch time: 0.07094287872314453 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.030149595267890128, loss after: 0.015054545336529973]
[epoch 801/1000, batch 11/100 -> loss before: 0.01737860109473131, loss after: 0.013775237199907048]
[epoch 801/1000, batch 21/100 -> loss before: 0.03966846829150339, loss after: 0.036566586138683695]
[epoch 801/1000, batch 31/100 -> loss before: 0.037594296016968606, loss after: 0.012693549384832728]
[epoch 801/1000, batch 41/100 -> loss before: 0.1838141485132653, loss after: 0.17385498188652942]
[epoch 801/1000, batch 51/100 -> loss before: 0.04572958018655723, loss after: 0.032263676230364836]
[epoch 801/1000, batch 61/100 -> loss before: 0.14177701210876736, loss after: 0.11582731191038147]
[epoch 801/1000, batch 71/100 -> loss before: 0.1090914964186486, loss after: 0.09688078177711686]
[epoch 801/1000, batch 81/100 -> loss before: 0.09073628720359142, loss after: 0.08692972491861076]
[epoch 801/1000, batch 91/100 -> loss before: 0.18343633040663476, loss after: 0.17071106377203218]
ENDING EPOCH 801/1000 [loss before: 0.07387986546771252, loss after: 0.0886122873091488; epoch time: 0.06926774978637695 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.037457571891343654, loss after: 0.06398413687818802]
[epoch 901/1000, batch 11/100 -> loss before: 0.05422984343209851, loss after: 0.0515067367842349]
[epoch 901/1000, batch 21/100 -> loss before: 0.030521996454212986, loss after: 0.018327103695629243]
[epoch 901/1000, batch 31/100 -> loss before: 0.026505643037549077, loss after: 0.024230904264112837]
[epoch 901/1000, batch 41/100 -> loss before: 0.05137180023042078, loss after: 0.05408050173421539]
[epoch 901/1000, batch 51/100 -> loss before: 0.07307110274528356, loss after: 0.0692937604430586]
[epoch 901/1000, batch 61/100 -> loss before: 0.073248804140125, loss after: 0.05629908807569558]
[epoch 901/1000, batch 71/100 -> loss before: 0.06567524126124255, loss after: 0.037420414233723324]
[epoch 901/1000, batch 81/100 -> loss before: 0.07610181740756489, loss after: 0.024716925812519084]
[epoch 901/1000, batch 91/100 -> loss before: 0.08918223564091851, loss after: 0.08141022459046754]
ENDING EPOCH 901/1000 [loss before: 0.0689278224847554, loss after: 0.09129167183958183; epoch time: 0.06822395324707031 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.11503655553634691, loss after: 0.07267157665390717]
[epoch 1000/1000, batch 11/100 -> loss before: 0.06823673311059858, loss after: 0.04828301259623486]
[epoch 1000/1000, batch 21/100 -> loss before: 0.01971211962425422, loss after: 0.004588666156643887]
[epoch 1000/1000, batch 31/100 -> loss before: 0.11994413005572153, loss after: 0.07475282300122235]
[epoch 1000/1000, batch 41/100 -> loss before: 0.04930264346815226, loss after: 0.022299552648948416]
[epoch 1000/1000, batch 51/100 -> loss before: 0.10072642319671037, loss after: 0.16677237856527202]
[epoch 1000/1000, batch 61/100 -> loss before: 0.08117226423054037, loss after: 0.045550719912052215]
[epoch 1000/1000, batch 71/100 -> loss before: 0.01819901177198852, loss after: 0.013300873126314875]
[epoch 1000/1000, batch 81/100 -> loss before: 0.06268802376069454, loss after: 0.05273143217440642]
[epoch 1000/1000, batch 91/100 -> loss before: 0.10620341366639932, loss after: 0.05822166801232662]
ENDING EPOCH 1000/1000 [loss before: 0.06622166253629405, loss after: 0.0597348656812743; epoch time: 0.06988525390625 s]
FIT DONE. [time: 66.93625473976135 s]
LOSS TRAIN (MSE): 0.0597348656812743
LOSS TEST (MSE): 0.06031342412624157
R^2 TRAIN: 0.788981025949902
R^2 TEST: 0.7826781074156578
EXPERIMENT DONE

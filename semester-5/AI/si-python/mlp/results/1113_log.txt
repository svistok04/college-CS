EXPERIMENT 1113 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[64, 64, 64, 64, 64, 32, 32, 32, 32, 32, 16, 16, 16, 16, 16, 8, 8, 8, 8, 8], activation_name=sigmoid, targets_activation_name=linear, 
initialization_name=uniform, algo_name=sgd_simple, learning_rate=0.01, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 25185]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 0.6815884323265685, loss after: 0.23124737357428668]
[epoch 1/1000, batch 11/100 -> loss before: 0.28720822916089583, loss after: 0.28529739975871043]
[epoch 1/1000, batch 21/100 -> loss before: 0.46601528450439866, loss after: 0.36404812711787954]
[epoch 1/1000, batch 31/100 -> loss before: 0.38340785546373357, loss after: 0.3708983260179149]
[epoch 1/1000, batch 41/100 -> loss before: 0.252259467755846, loss after: 0.20473824678662225]
[epoch 1/1000, batch 51/100 -> loss before: 0.30504560675843184, loss after: 0.23737257994222113]
[epoch 1/1000, batch 61/100 -> loss before: 0.4975312668823622, loss after: 0.46986644839603964]
[epoch 1/1000, batch 71/100 -> loss before: 0.36078817341515024, loss after: 0.3398511501900106]
[epoch 1/1000, batch 81/100 -> loss before: 0.39856580625977894, loss after: 0.3970264236190256]
[epoch 1/1000, batch 91/100 -> loss before: 0.3057876203500544, loss after: 0.29204875939706393]
ENDING EPOCH 1/1000 [loss before: 0.599648552700766, loss after: 0.3241284239622803; epoch time: 0.09601378440856934 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.30037703750058303, loss after: 0.29252494991001704]
[epoch 101/1000, batch 11/100 -> loss before: 0.21976197385777424, loss after: 0.2197578421432202]
[epoch 101/1000, batch 21/100 -> loss before: 0.23904767683788997, loss after: 0.23804918419552729]
[epoch 101/1000, batch 31/100 -> loss before: 0.3951858719243036, loss after: 0.38094833414418544]
[epoch 101/1000, batch 41/100 -> loss before: 0.6931494572132515, loss after: 0.5802417812457156]
[epoch 101/1000, batch 51/100 -> loss before: 0.24923872800017768, loss after: 0.22255508601206841]
[epoch 101/1000, batch 61/100 -> loss before: 0.5140616745252709, loss after: 0.5140505454842603]
[epoch 101/1000, batch 71/100 -> loss before: 0.14399380005018922, loss after: 0.1439557752612717]
[epoch 101/1000, batch 81/100 -> loss before: 0.2641951690855924, loss after: 0.2628254896085698]
[epoch 101/1000, batch 91/100 -> loss before: 0.2472264341238009, loss after: 0.22542832912028662]
ENDING EPOCH 101/1000 [loss before: 0.28826706898951476, loss after: 0.28307965337004076; epoch time: 0.09347796440124512 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.0917408804347425, loss after: 0.09029005805729315]
[epoch 201/1000, batch 11/100 -> loss before: 0.3539986921523147, loss after: 0.35044815709198285]
[epoch 201/1000, batch 21/100 -> loss before: 0.17452703718735213, loss after: 0.16441216051952118]
[epoch 201/1000, batch 31/100 -> loss before: 0.46844424769565174, loss after: 0.45953430190982203]
[epoch 201/1000, batch 41/100 -> loss before: 0.35519890554685213, loss after: 0.32814549780800245]
[epoch 201/1000, batch 51/100 -> loss before: 0.28239576540809413, loss after: 0.2821146895379062]
[epoch 201/1000, batch 61/100 -> loss before: 0.5126436216994381, loss after: 0.4968732729361731]
[epoch 201/1000, batch 71/100 -> loss before: 0.4072323068735427, loss after: 0.4072312652471301]
[epoch 201/1000, batch 81/100 -> loss before: 0.20506478101318887, loss after: 0.2025524543782668]
[epoch 201/1000, batch 91/100 -> loss before: 0.10952223449289308, loss after: 0.1093039273639543]
ENDING EPOCH 201/1000 [loss before: 0.28610561712007043, loss after: 0.2843321318245657; epoch time: 0.08884549140930176 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.20137888205401935, loss after: 0.19576507916493444]
[epoch 301/1000, batch 11/100 -> loss before: 0.20403091852242233, loss after: 0.2014503777733653]
[epoch 301/1000, batch 21/100 -> loss before: 0.31672445458335813, loss after: 0.3016211917305024]
[epoch 301/1000, batch 31/100 -> loss before: 0.3384338681476791, loss after: 0.3134824608941849]
[epoch 301/1000, batch 41/100 -> loss before: 0.24776883150757928, loss after: 0.24501672759757492]
[epoch 301/1000, batch 51/100 -> loss before: 0.28491263369281006, loss after: 0.28394109943224943]
[epoch 301/1000, batch 61/100 -> loss before: 0.3129334376081783, loss after: 0.29609257865400124]
[epoch 301/1000, batch 71/100 -> loss before: 0.3165051383946423, loss after: 0.3088683054654506]
[epoch 301/1000, batch 81/100 -> loss before: 0.3235401710712295, loss after: 0.32302822781723806]
[epoch 301/1000, batch 91/100 -> loss before: 0.3276170042396078, loss after: 0.2823777058786139]
ENDING EPOCH 301/1000 [loss before: 0.28891500624931166, loss after: 0.2909849336136331; epoch time: 0.09899020195007324 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.3090758118532953, loss after: 0.2986158441884611]
[epoch 401/1000, batch 11/100 -> loss before: 0.2776869382104635, loss after: 0.27555823097128335]
[epoch 401/1000, batch 21/100 -> loss before: 0.33751504455914266, loss after: 0.3072963340159215]
[epoch 401/1000, batch 31/100 -> loss before: 0.415301315456137, loss after: 0.30776596322716515]
[epoch 401/1000, batch 41/100 -> loss before: 0.24656951591147017, loss after: 0.24229029529795937]
[epoch 401/1000, batch 51/100 -> loss before: 0.3290613815372635, loss after: 0.3270121997011475]
[epoch 401/1000, batch 61/100 -> loss before: 0.3081193998490583, loss after: 0.26273269154248247]
[epoch 401/1000, batch 71/100 -> loss before: 0.2782059422063966, loss after: 0.27319586871936313]
[epoch 401/1000, batch 81/100 -> loss before: 0.19956473472993247, loss after: 0.19300371360531815]
[epoch 401/1000, batch 91/100 -> loss before: 0.19137617337667656, loss after: 0.1912509983947054]
ENDING EPOCH 401/1000 [loss before: 0.29613903453225954, loss after: 0.28321274250185585; epoch time: 0.08543086051940918 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.27796738627709755, loss after: 0.2736934830743942]
[epoch 501/1000, batch 11/100 -> loss before: 0.5709078127009392, loss after: 0.5694215350484748]
[epoch 501/1000, batch 21/100 -> loss before: 0.3849074334035373, loss after: 0.38153515108764174]
[epoch 501/1000, batch 31/100 -> loss before: 0.25277840541383756, loss after: 0.24621655163684716]
[epoch 501/1000, batch 41/100 -> loss before: 0.3179177104696577, loss after: 0.31674391314755135]
[epoch 501/1000, batch 51/100 -> loss before: 0.17873291200113028, loss after: 0.17641691237902102]
[epoch 501/1000, batch 61/100 -> loss before: 0.29069792574821735, loss after: 0.2903205054688799]
[epoch 501/1000, batch 71/100 -> loss before: 0.1489900146364192, loss after: 0.14842754318402335]
[epoch 501/1000, batch 81/100 -> loss before: 0.24594813787214273, loss after: 0.22552122461796661]
[epoch 501/1000, batch 91/100 -> loss before: 0.21581166907081747, loss after: 0.2147394863834713]
ENDING EPOCH 501/1000 [loss before: 0.2838638472137529, loss after: 0.28362314586480486; epoch time: 0.08566451072692871 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.36454988609103406, loss after: 0.3553877726940542]
[epoch 601/1000, batch 11/100 -> loss before: 0.3800949793916462, loss after: 0.3589999818147278]
[epoch 601/1000, batch 21/100 -> loss before: 0.2941455417585684, loss after: 0.2936040278295847]
[epoch 601/1000, batch 31/100 -> loss before: 0.16164620420757508, loss after: 0.14688997968055037]
[epoch 601/1000, batch 41/100 -> loss before: 0.3274629708227884, loss after: 0.3102298443899555]
[epoch 601/1000, batch 51/100 -> loss before: 0.29611458331843654, loss after: 0.27912484061766796]
[epoch 601/1000, batch 61/100 -> loss before: 0.13843381324121162, loss after: 0.1376006469130892]
[epoch 601/1000, batch 71/100 -> loss before: 0.24507997164756992, loss after: 0.22018300986025477]
[epoch 601/1000, batch 81/100 -> loss before: 0.34971084200109154, loss after: 0.3088449169114765]
[epoch 601/1000, batch 91/100 -> loss before: 0.3532044580135721, loss after: 0.35102862904980936]
ENDING EPOCH 601/1000 [loss before: 0.29132147177130435, loss after: 0.285844630141668; epoch time: 0.0891563892364502 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.14244085025740277, loss after: 0.13805687323133894]
[epoch 701/1000, batch 11/100 -> loss before: 0.1135241364396518, loss after: 0.1053872901343919]
[epoch 701/1000, batch 21/100 -> loss before: 0.2242996838210642, loss after: 0.22300017543050635]
[epoch 701/1000, batch 31/100 -> loss before: 0.20842417579492975, loss after: 0.2063385055726837]
[epoch 701/1000, batch 41/100 -> loss before: 0.19879035168857198, loss after: 0.19756490490950138]
[epoch 701/1000, batch 51/100 -> loss before: 0.5722754036337617, loss after: 0.5145095414838932]
[epoch 701/1000, batch 61/100 -> loss before: 0.13816213020426849, loss after: 0.13620347160797586]
[epoch 701/1000, batch 71/100 -> loss before: 0.3719982807115049, loss after: 0.3702449238395163]
[epoch 701/1000, batch 81/100 -> loss before: 0.28552812341848127, loss after: 0.2846962269193036]
[epoch 701/1000, batch 91/100 -> loss before: 0.35342334725457153, loss after: 0.35339405653492323]
ENDING EPOCH 701/1000 [loss before: 0.283233116222805, loss after: 0.2835856498307414; epoch time: 0.08563375473022461 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.22166244412767128, loss after: 0.18598981615237314]
[epoch 801/1000, batch 11/100 -> loss before: 0.12061272611895495, loss after: 0.11878661297350024]
[epoch 801/1000, batch 21/100 -> loss before: 0.23701719248329695, loss after: 0.23546279903168496]
[epoch 801/1000, batch 31/100 -> loss before: 0.21153327439135067, loss after: 0.21050029679416976]
[epoch 801/1000, batch 41/100 -> loss before: 0.5055007051063714, loss after: 0.482589507370371]
[epoch 801/1000, batch 51/100 -> loss before: 0.26455824217813173, loss after: 0.26235645045203154]
[epoch 801/1000, batch 61/100 -> loss before: 0.2621069074306904, loss after: 0.2565392323890537]
[epoch 801/1000, batch 71/100 -> loss before: 0.3302469856854495, loss after: 0.3245575450001508]
[epoch 801/1000, batch 81/100 -> loss before: 0.30604044956205917, loss after: 0.2909920567687818]
[epoch 801/1000, batch 91/100 -> loss before: 0.23920494024651484, loss after: 0.23886041200418892]
ENDING EPOCH 801/1000 [loss before: 0.2845199655653561, loss after: 0.283079963319334; epoch time: 0.09078192710876465 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.12738468983721368, loss after: 0.12332105580979705]
[epoch 901/1000, batch 11/100 -> loss before: 0.330944963406828, loss after: 0.31070844545855425]
[epoch 901/1000, batch 21/100 -> loss before: 0.2430707061221628, loss after: 0.23201417705077937]
[epoch 901/1000, batch 31/100 -> loss before: 0.27796686734096604, loss after: 0.27117551152997554]
[epoch 901/1000, batch 41/100 -> loss before: 0.3452989026609716, loss after: 0.3294469699419756]
[epoch 901/1000, batch 51/100 -> loss before: 0.2850679867469267, loss after: 0.23074627907136228]
[epoch 901/1000, batch 61/100 -> loss before: 0.4142929810761161, loss after: 0.41183493114828995]
[epoch 901/1000, batch 71/100 -> loss before: 0.1580684113600708, loss after: 0.155240576439904]
[epoch 901/1000, batch 81/100 -> loss before: 0.39241344366510095, loss after: 0.38425462759776075]
[epoch 901/1000, batch 91/100 -> loss before: 0.20256447773141656, loss after: 0.20166375020814203]
ENDING EPOCH 901/1000 [loss before: 0.28460739413252156, loss after: 0.29477920259767304; epoch time: 0.08971619606018066 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.2840599468284115, loss after: 0.2651528396606137]
[epoch 1000/1000, batch 11/100 -> loss before: 0.2281168612106567, loss after: 0.2267427243674935]
[epoch 1000/1000, batch 21/100 -> loss before: 0.32980185116678357, loss after: 0.3138576293637708]
[epoch 1000/1000, batch 31/100 -> loss before: 0.2491134095066047, loss after: 0.24374140027719388]
[epoch 1000/1000, batch 41/100 -> loss before: 0.29629777472210755, loss after: 0.2715971265617808]
[epoch 1000/1000, batch 51/100 -> loss before: 0.31697628723043025, loss after: 0.29623684682816587]
[epoch 1000/1000, batch 61/100 -> loss before: 0.23468600948776527, loss after: 0.21749615184227458]
[epoch 1000/1000, batch 71/100 -> loss before: 0.3443689215047771, loss after: 0.3443595192737424]
[epoch 1000/1000, batch 81/100 -> loss before: 0.10582307648101837, loss after: 0.10446765149137123]
[epoch 1000/1000, batch 91/100 -> loss before: 0.35902229762847976, loss after: 0.35028650753748647]
ENDING EPOCH 1000/1000 [loss before: 0.2886544376480148, loss after: 0.2834316246909798; epoch time: 0.09429240226745605 s]
FIT DONE. [time: 78.82860684394836 s]
LOSS TRAIN (MSE): 0.2834316246909798
LOSS TEST (MSE): 0.27851770605903015
R^2 TRAIN: -0.001248600352876883
R^2 TEST: -0.0035575972656978205
EXPERIMENT DONE

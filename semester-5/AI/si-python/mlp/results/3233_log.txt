EXPERIMENT 3233 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[64, 64, 64, 64, 64, 32, 32, 32, 32, 32, 16, 16, 16, 16, 16, 8, 8, 8, 8, 8], activation_name=relu, targets_activation_name=linear, 
initialization_name=uniform, algo_name=rmsprop, learning_rate=0.0001, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 25185]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 0.18318931763552243, loss after: 0.18219263272198574]
[epoch 1/1000, batch 11/100 -> loss before: 0.32524644143724674, loss after: 0.32030573130303963]
[epoch 1/1000, batch 21/100 -> loss before: 0.35492565814878607, loss after: 0.3549256216927602]
[epoch 1/1000, batch 31/100 -> loss before: 0.35650458575924315, loss after: 0.34519733639049466]
[epoch 1/1000, batch 41/100 -> loss before: 0.22761581778709558, loss after: 0.21218586783939153]
[epoch 1/1000, batch 51/100 -> loss before: 0.23638172644100694, loss after: 0.23627638494356384]
[epoch 1/1000, batch 61/100 -> loss before: 0.4593625388655515, loss after: 0.45816939304745574]
[epoch 1/1000, batch 71/100 -> loss before: 0.3378951095935254, loss after: 0.33789508748871444]
[epoch 1/1000, batch 81/100 -> loss before: 0.3732017689417423, loss after: 0.37155955226293785]
[epoch 1/1000, batch 91/100 -> loss before: 0.3310161648108267, loss after: 0.32314095742255666]
ENDING EPOCH 1/1000 [loss before: 0.2899884218128069, loss after: 0.27870355425067744; epoch time: 0.1265261173248291 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.07010213030167366, loss after: 0.06685151977572121]
[epoch 101/1000, batch 11/100 -> loss before: 0.10260428958658578, loss after: 0.09587335372654521]
[epoch 101/1000, batch 21/100 -> loss before: 0.07208235426958116, loss after: 0.06147359795998912]
[epoch 101/1000, batch 31/100 -> loss before: 0.17823748310241744, loss after: 0.16199716742141976]
[epoch 101/1000, batch 41/100 -> loss before: 0.34854567936166825, loss after: 0.314187931087624]
[epoch 101/1000, batch 51/100 -> loss before: 0.1914750469823394, loss after: 0.17035968350397035]
[epoch 101/1000, batch 61/100 -> loss before: 0.384385330807874, loss after: 0.3774653693843821]
[epoch 101/1000, batch 71/100 -> loss before: 0.09912177914654223, loss after: 0.08667440801809986]
[epoch 101/1000, batch 81/100 -> loss before: 0.20604158521085547, loss after: 0.19672772024434454]
[epoch 101/1000, batch 91/100 -> loss before: 0.18404654242927126, loss after: 0.1476160111714302]
ENDING EPOCH 101/1000 [loss before: 0.16548308109833834, loss after: 0.1506952413306528; epoch time: 0.11694979667663574 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.04316089622275843, loss after: 0.028923387567920907]
[epoch 201/1000, batch 11/100 -> loss before: 0.09832395311585138, loss after: 0.07003665855641009]
[epoch 201/1000, batch 21/100 -> loss before: 0.16085795180890658, loss after: 0.07805746643638753]
[epoch 201/1000, batch 31/100 -> loss before: 0.1704726520689166, loss after: 0.13711755990003696]
[epoch 201/1000, batch 41/100 -> loss before: 0.20245568275613754, loss after: 0.1521863524699289]
[epoch 201/1000, batch 51/100 -> loss before: 0.13358641868929116, loss after: 0.10027745483026625]
[epoch 201/1000, batch 61/100 -> loss before: 0.17879067452780906, loss after: 0.1568159312923832]
[epoch 201/1000, batch 71/100 -> loss before: 0.27821243053273204, loss after: 0.2548106728818371]
[epoch 201/1000, batch 81/100 -> loss before: 0.04763119611516514, loss after: 0.039158568635893565]
[epoch 201/1000, batch 91/100 -> loss before: 0.06541031192331011, loss after: 0.055966004256540455]
ENDING EPOCH 201/1000 [loss before: 0.14161965004407107, loss after: 0.12679885482975656; epoch time: 0.12032628059387207 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.05668719864073638, loss after: 0.034168860759534826]
[epoch 301/1000, batch 11/100 -> loss before: 0.035824681772570116, loss after: 0.019579108628721698]
[epoch 301/1000, batch 21/100 -> loss before: 0.10403097019830396, loss after: 0.05959113894926049]
[epoch 301/1000, batch 31/100 -> loss before: 0.15340711774758875, loss after: 0.10546937475093794]
[epoch 301/1000, batch 41/100 -> loss before: 0.09043032928350414, loss after: 0.033220291849696965]
[epoch 301/1000, batch 51/100 -> loss before: 0.08366541925716145, loss after: 0.0948249046881112]
[epoch 301/1000, batch 61/100 -> loss before: 0.09966163308913789, loss after: 0.08119205842752614]
[epoch 301/1000, batch 71/100 -> loss before: 0.08874718319524064, loss after: 0.0715082364013804]
[epoch 301/1000, batch 81/100 -> loss before: 0.10369162813551414, loss after: 0.06956383300786463]
[epoch 301/1000, batch 91/100 -> loss before: 0.1341676970847277, loss after: 0.14201760308930728]
ENDING EPOCH 301/1000 [loss before: 0.07703845429052592, loss after: 0.08682055817257961; epoch time: 0.1189115047454834 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.017047270811376157, loss after: 0.012869159095930394]
[epoch 401/1000, batch 11/100 -> loss before: 0.052873662417098566, loss after: 0.032945648192869256]
[epoch 401/1000, batch 21/100 -> loss before: 0.1610390775521804, loss after: 0.13266612498111163]
[epoch 401/1000, batch 31/100 -> loss before: 0.007786006694461492, loss after: 0.004520415085176056]
[epoch 401/1000, batch 41/100 -> loss before: 0.09350480343457666, loss after: 0.05595321266830415]
[epoch 401/1000, batch 51/100 -> loss before: 0.03493565445156609, loss after: 0.019589781255459713]
[epoch 401/1000, batch 61/100 -> loss before: 0.17042352630440616, loss after: 0.11675442209280913]
[epoch 401/1000, batch 71/100 -> loss before: 0.08710610792765064, loss after: 0.05113314976139253]
[epoch 401/1000, batch 81/100 -> loss before: 0.0214284136214023, loss after: 0.010041403267142784]
[epoch 401/1000, batch 91/100 -> loss before: 0.039280549267711753, loss after: 0.020303925292299487]
ENDING EPOCH 401/1000 [loss before: 0.06493066775482237, loss after: 0.05089522560518264; epoch time: 0.12867116928100586 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.026080731938582312, loss after: 0.011546344308185543]
[epoch 501/1000, batch 11/100 -> loss before: 0.020466156096169506, loss after: 0.01388267542513755]
[epoch 501/1000, batch 21/100 -> loss before: 0.02409091404639237, loss after: 0.010735133513495535]
[epoch 501/1000, batch 31/100 -> loss before: 0.02996121042976954, loss after: 0.03640471284235534]
[epoch 501/1000, batch 41/100 -> loss before: 0.05318906530134389, loss after: 0.11017660476853408]
[epoch 501/1000, batch 51/100 -> loss before: 0.020770484665911366, loss after: 0.004167592267320078]
[epoch 501/1000, batch 61/100 -> loss before: 0.04044260419697056, loss after: 0.009863166933704365]
[epoch 501/1000, batch 71/100 -> loss before: 0.07629060022986942, loss after: 0.027757935798417177]
[epoch 501/1000, batch 81/100 -> loss before: 0.017691226157321036, loss after: 0.00511423554729576]
[epoch 501/1000, batch 91/100 -> loss before: 0.026992849263209363, loss after: 0.025001474658380735]
ENDING EPOCH 501/1000 [loss before: 0.05445893785975251, loss after: 0.0566143071760351; epoch time: 0.1256866455078125 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.04498576838987278, loss after: 0.006295288468902813]
[epoch 601/1000, batch 11/100 -> loss before: 0.09020177286728603, loss after: 0.06149119842435432]
[epoch 601/1000, batch 21/100 -> loss before: 0.048403337329029766, loss after: 0.019000228870771026]
[epoch 601/1000, batch 31/100 -> loss before: 0.016344781579196412, loss after: 0.00679132203916618]
[epoch 601/1000, batch 41/100 -> loss before: 0.015658157973201827, loss after: 0.011265495958795882]
[epoch 601/1000, batch 51/100 -> loss before: 0.012909161375568102, loss after: 0.030144630276199052]
[epoch 601/1000, batch 61/100 -> loss before: 0.013556587919054142, loss after: 0.006499356811666981]
[epoch 601/1000, batch 71/100 -> loss before: 0.05934215464372057, loss after: 0.015448889869897292]
[epoch 601/1000, batch 81/100 -> loss before: 0.0328419889265356, loss after: 0.009999389389091768]
[epoch 601/1000, batch 91/100 -> loss before: 0.04826468543161103, loss after: 0.01287557783313643]
ENDING EPOCH 601/1000 [loss before: 0.03687536397385895, loss after: 0.025759104498649196; epoch time: 0.12219691276550293 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.02536845348942754, loss after: 0.02816420465992877]
[epoch 701/1000, batch 11/100 -> loss before: 0.07654413319423849, loss after: 0.021439037425037683]
[epoch 701/1000, batch 21/100 -> loss before: 0.0412294370640134, loss after: 0.008421154010002497]
[epoch 701/1000, batch 31/100 -> loss before: 0.04233217835940384, loss after: 0.034214203888796355]
[epoch 701/1000, batch 41/100 -> loss before: 0.010586193530428663, loss after: 0.006953181262184162]
[epoch 701/1000, batch 51/100 -> loss before: 0.04856968008007552, loss after: 0.06471037139221558]
[epoch 701/1000, batch 61/100 -> loss before: 0.0242494731199226, loss after: 0.009365146505530771]
[epoch 701/1000, batch 71/100 -> loss before: 0.032521109889022994, loss after: 0.005826161918430481]
[epoch 701/1000, batch 81/100 -> loss before: 0.02166647176439871, loss after: 0.011911581876646052]
[epoch 701/1000, batch 91/100 -> loss before: 0.016169843981190278, loss after: 0.00708570600368028]
ENDING EPOCH 701/1000 [loss before: 0.028483955579186582, loss after: 0.024921143788823864; epoch time: 0.11419057846069336 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.03610676851209961, loss after: 0.014258808596728918]
[epoch 801/1000, batch 11/100 -> loss before: 0.01030142607375468, loss after: 0.005532468850358321]
[epoch 801/1000, batch 21/100 -> loss before: 0.023365623157210632, loss after: 0.06553527995861581]
[epoch 801/1000, batch 31/100 -> loss before: 0.011672229690312032, loss after: 0.0044184387230509214]
[epoch 801/1000, batch 41/100 -> loss before: 0.006459644995098443, loss after: 0.004077260449465545]
[epoch 801/1000, batch 51/100 -> loss before: 0.010056096018490038, loss after: 0.001357827859941825]
[epoch 801/1000, batch 61/100 -> loss before: 0.055407742337752974, loss after: 0.024767515726599583]
[epoch 801/1000, batch 71/100 -> loss before: 0.009363800489386747, loss after: 0.004662943192497801]
[epoch 801/1000, batch 81/100 -> loss before: 0.020231484537684526, loss after: 0.006887099637024985]
[epoch 801/1000, batch 91/100 -> loss before: 0.020380187845916137, loss after: 0.00475755193687059]
ENDING EPOCH 801/1000 [loss before: 0.02601644596488761, loss after: 0.025801191198835567; epoch time: 0.11569380760192871 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.010993157533168742, loss after: 0.010690428472938412]
[epoch 901/1000, batch 11/100 -> loss before: 0.024961183309597762, loss after: 0.01451273505489888]
[epoch 901/1000, batch 21/100 -> loss before: 0.009630381526561604, loss after: 0.00352773218355996]
[epoch 901/1000, batch 31/100 -> loss before: 0.014375173239624492, loss after: 0.006667997248336724]
[epoch 901/1000, batch 41/100 -> loss before: 0.008011666375052356, loss after: 0.003017528721368804]
[epoch 901/1000, batch 51/100 -> loss before: 0.021954740378694937, loss after: 0.01252667158896128]
[epoch 901/1000, batch 61/100 -> loss before: 0.025025699437589137, loss after: 0.011757669492162007]
[epoch 901/1000, batch 71/100 -> loss before: 0.027017635499323827, loss after: 0.015213809384094145]
[epoch 901/1000, batch 81/100 -> loss before: 0.042753295055037534, loss after: 0.01174272665107048]
[epoch 901/1000, batch 91/100 -> loss before: 0.029495670863407108, loss after: 0.018571783856079264]
ENDING EPOCH 901/1000 [loss before: 0.018474280886952722, loss after: 0.03645606171376638; epoch time: 0.11712431907653809 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.06765394189787495, loss after: 0.04077166023516116]
[epoch 1000/1000, batch 11/100 -> loss before: 0.012667726784246682, loss after: 0.006380197155804057]
[epoch 1000/1000, batch 21/100 -> loss before: 0.011728546054920611, loss after: 0.009295226345177088]
[epoch 1000/1000, batch 31/100 -> loss before: 0.011499552254030482, loss after: 0.005923149919641232]
[epoch 1000/1000, batch 41/100 -> loss before: 0.05226129270378228, loss after: 0.030276586976712316]
[epoch 1000/1000, batch 51/100 -> loss before: 0.00895736725203106, loss after: 0.004209382076612499]
[epoch 1000/1000, batch 61/100 -> loss before: 0.016254093907830204, loss after: 0.008545408773298404]
[epoch 1000/1000, batch 71/100 -> loss before: 0.020179429049325116, loss after: 0.004429239664769258]
[epoch 1000/1000, batch 81/100 -> loss before: 0.0159296526832715, loss after: 0.006077690922511212]
[epoch 1000/1000, batch 91/100 -> loss before: 0.02738492382981674, loss after: 0.02417830424196323]
ENDING EPOCH 1000/1000 [loss before: 0.07205501926515324, loss after: 0.04237098370195926; epoch time: 0.11697196960449219 s]
FIT DONE. [time: 116.63228034973145 s]
LOSS TRAIN (MSE): 0.04237098370195926
LOSS TEST (MSE): 0.06205783172017286
R^2 TRAIN: 0.8503205555364006
R^2 TEST: 0.7763926416964813
EXPERIMENT DONE

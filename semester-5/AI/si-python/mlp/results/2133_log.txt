EXPERIMENT 2133 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[64, 64, 64, 64, 64, 32, 32, 32, 32, 32, 16, 16, 16, 16, 16, 8, 8, 8, 8, 8], activation_name=sigmoid, targets_activation_name=linear, 
initialization_name=uniform, algo_name=rmsprop, learning_rate=0.001, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 25185]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 0.6815884323265685, loss after: 0.6370198110038092]
[epoch 1/1000, batch 11/100 -> loss before: 0.3482053813803284, loss after: 0.34526971458999617]
[epoch 1/1000, batch 21/100 -> loss before: 0.5341166550021407, loss after: 0.525288820529582]
[epoch 1/1000, batch 31/100 -> loss before: 0.40873271038294057, loss after: 0.4064009344058608]
[epoch 1/1000, batch 41/100 -> loss before: 0.2898926983431025, loss after: 0.2839819225707063]
[epoch 1/1000, batch 51/100 -> loss before: 0.31977315203664974, loss after: 0.31242417761773644]
[epoch 1/1000, batch 61/100 -> loss before: 0.4758650821473652, loss after: 0.47492255801334887]
[epoch 1/1000, batch 71/100 -> loss before: 0.3526534813404693, loss after: 0.35082920565742093]
[epoch 1/1000, batch 81/100 -> loss before: 0.4071017310274927, loss after: 0.40601153452453287]
[epoch 1/1000, batch 91/100 -> loss before: 0.2935919280112627, loss after: 0.2931899562637995]
ENDING EPOCH 1/1000 [loss before: 0.599648552700766, loss after: 0.283586381330157; epoch time: 0.12964987754821777 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.2898188834177708, loss after: 0.2888352569867541]
[epoch 101/1000, batch 11/100 -> loss before: 0.21979386155484035, loss after: 0.21978924335820088]
[epoch 101/1000, batch 21/100 -> loss before: 0.2427591565113257, loss after: 0.24211317053832726]
[epoch 101/1000, batch 31/100 -> loss before: 0.3907120457120209, loss after: 0.3873477911474587]
[epoch 101/1000, batch 41/100 -> loss before: 0.6617088946559806, loss after: 0.6409630009492974]
[epoch 101/1000, batch 51/100 -> loss before: 0.25637437433231114, loss after: 0.24950304368624615]
[epoch 101/1000, batch 61/100 -> loss before: 0.5163333837234803, loss after: 0.5160944956371762]
[epoch 101/1000, batch 71/100 -> loss before: 0.1446676407334266, loss after: 0.14457545220477216]
[epoch 101/1000, batch 81/100 -> loss before: 0.2649023051430729, loss after: 0.26433485290537134]
[epoch 101/1000, batch 91/100 -> loss before: 0.24288776263006326, loss after: 0.23873928351754792]
ENDING EPOCH 101/1000 [loss before: 0.2836155620696351, loss after: 0.2830996624736066; epoch time: 0.16861867904663086 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.08833258792934204, loss after: 0.08830238390578518]
[epoch 201/1000, batch 11/100 -> loss before: 0.3561365412067712, loss after: 0.35490354551752173]
[epoch 201/1000, batch 21/100 -> loss before: 0.18094383159052324, loss after: 0.1776209881048741]
[epoch 201/1000, batch 31/100 -> loss before: 0.4640827891759117, loss after: 0.4622064952727761]
[epoch 201/1000, batch 41/100 -> loss before: 0.3266031846430145, loss after: 0.3219446393149601]
[epoch 201/1000, batch 51/100 -> loss before: 0.2845216604281421, loss after: 0.28409418143608944]
[epoch 201/1000, batch 61/100 -> loss before: 0.48844128048591323, loss after: 0.48675934114026165]
[epoch 201/1000, batch 71/100 -> loss before: 0.4108597352634142, loss after: 0.4104635703628622]
[epoch 201/1000, batch 81/100 -> loss before: 0.1987961078874741, loss after: 0.19878774547868905]
[epoch 201/1000, batch 91/100 -> loss before: 0.1090661812497252, loss after: 0.1090550374336993]
ENDING EPOCH 201/1000 [loss before: 0.2831939792455647, loss after: 0.2833538715478138; epoch time: 0.12973356246948242 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.18988929418299638, loss after: 0.1896017740759865]
[epoch 301/1000, batch 11/100 -> loss before: 0.2008744280462583, loss after: 0.2004400070517663]
[epoch 301/1000, batch 21/100 -> loss before: 0.31205546673567647, loss after: 0.30731481265053284]
[epoch 301/1000, batch 31/100 -> loss before: 0.3302036239704891, loss after: 0.32413021195914726]
[epoch 301/1000, batch 41/100 -> loss before: 0.25660723694426074, loss after: 0.25466885883425033]
[epoch 301/1000, batch 51/100 -> loss before: 0.2823898713257099, loss after: 0.282385948840414]
[epoch 301/1000, batch 61/100 -> loss before: 0.3125881079888114, loss after: 0.3081571953315354]
[epoch 301/1000, batch 71/100 -> loss before: 0.30927155550047203, loss after: 0.3079748821311753]
[epoch 301/1000, batch 81/100 -> loss before: 0.32290885872337016, loss after: 0.3228376816196479]
[epoch 301/1000, batch 91/100 -> loss before: 0.31964065658279517, loss after: 0.3081773049790483]
ENDING EPOCH 301/1000 [loss before: 0.28322588996320924, loss after: 0.2833066687960083; epoch time: 0.12881755828857422 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.2878533707706466, loss after: 0.28720961164735354]
[epoch 401/1000, batch 11/100 -> loss before: 0.2750193283797504, loss after: 0.2746654116774888]
[epoch 401/1000, batch 21/100 -> loss before: 0.3337263924839699, loss after: 0.32596550556077164]
[epoch 401/1000, batch 31/100 -> loss before: 0.3824788997322938, loss after: 0.3651273561462112]
[epoch 401/1000, batch 41/100 -> loss before: 0.23550267078906623, loss after: 0.23546804353438272]
[epoch 401/1000, batch 51/100 -> loss before: 0.3262259572208093, loss after: 0.32598892660257467]
[epoch 401/1000, batch 61/100 -> loss before: 0.25791064015754606, loss after: 0.25198612809012744]
[epoch 401/1000, batch 71/100 -> loss before: 0.2671229224249486, loss after: 0.26686941691509103]
[epoch 401/1000, batch 81/100 -> loss before: 0.19631095398578544, loss after: 0.1946807193394747]
[epoch 401/1000, batch 91/100 -> loss before: 0.19395930596210514, loss after: 0.1935639039013644]
ENDING EPOCH 401/1000 [loss before: 0.28393307850882377, loss after: 0.28337358379522276; epoch time: 0.1303091049194336 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.2840603672484595, loss after: 0.28212374925612627]
[epoch 501/1000, batch 11/100 -> loss before: 0.5775315777767311, loss after: 0.576406159518972]
[epoch 501/1000, batch 21/100 -> loss before: 0.38044792619243467, loss after: 0.3798845537551372]
[epoch 501/1000, batch 31/100 -> loss before: 0.2456005986649643, loss after: 0.24456920333185606]
[epoch 501/1000, batch 41/100 -> loss before: 0.3154025574567421, loss after: 0.3153354008276777]
[epoch 501/1000, batch 51/100 -> loss before: 0.17715369396658684, loss after: 0.17672651221956198]
[epoch 501/1000, batch 61/100 -> loss before: 0.28967861147691465, loss after: 0.28967861127568606]
[epoch 501/1000, batch 71/100 -> loss before: 0.147627958539234, loss after: 0.14761132903831398]
[epoch 501/1000, batch 81/100 -> loss before: 0.2415471618152098, loss after: 0.23667473229512254]
[epoch 501/1000, batch 91/100 -> loss before: 0.21422220895852825, loss after: 0.2140614007956026]
ENDING EPOCH 501/1000 [loss before: 0.2830852861552644, loss after: 0.28335918827195755; epoch time: 0.13025736808776855 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.34603618793353014, loss after: 0.3454329495044911]
[epoch 601/1000, batch 11/100 -> loss before: 0.3584867293122026, loss after: 0.35423795887937837]
[epoch 601/1000, batch 21/100 -> loss before: 0.298830258528723, loss after: 0.29816130673607977]
[epoch 601/1000, batch 31/100 -> loss before: 0.13920407751496558, loss after: 0.13759068960867124]
[epoch 601/1000, batch 41/100 -> loss before: 0.3644876234252431, loss after: 0.3577324476070226]
[epoch 601/1000, batch 51/100 -> loss before: 0.2889726306501236, loss after: 0.2851449258797055]
[epoch 601/1000, batch 61/100 -> loss before: 0.13628890604271876, loss after: 0.1362766434872238]
[epoch 601/1000, batch 71/100 -> loss before: 0.26572269007221644, loss after: 0.25754232046822495]
[epoch 601/1000, batch 81/100 -> loss before: 0.346291942122169, loss after: 0.33794077086377017]
[epoch 601/1000, batch 91/100 -> loss before: 0.3477349541724576, loss after: 0.3476901939288971]
ENDING EPOCH 601/1000 [loss before: 0.2832437398713761, loss after: 0.28406965051249033; epoch time: 0.1257474422454834 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.1395486032528916, loss after: 0.1385711149133568]
[epoch 701/1000, batch 11/100 -> loss before: 0.15831713819982435, loss after: 0.1527586074754879]
[epoch 701/1000, batch 21/100 -> loss before: 0.2264008382457084, loss after: 0.22582863244139967]
[epoch 701/1000, batch 31/100 -> loss before: 0.20561938147819606, loss after: 0.20526598336731944]
[epoch 701/1000, batch 41/100 -> loss before: 0.19575007321481863, loss after: 0.19572217995814417]
[epoch 701/1000, batch 51/100 -> loss before: 0.5447252285874044, loss after: 0.5340033493749436]
[epoch 701/1000, batch 61/100 -> loss before: 0.13750800219808498, loss after: 0.13696573985321264]
[epoch 701/1000, batch 71/100 -> loss before: 0.36819286058833733, loss after: 0.368080848717817]
[epoch 701/1000, batch 81/100 -> loss before: 0.2832917001208856, loss after: 0.28328731738874197]
[epoch 701/1000, batch 91/100 -> loss before: 0.35334807856034056, loss after: 0.35334748860709186]
ENDING EPOCH 701/1000 [loss before: 0.28308104063017425, loss after: 0.2830813619234808; epoch time: 0.13440418243408203 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.24205965261710216, loss after: 0.2312431081960761]
[epoch 801/1000, batch 11/100 -> loss before: 0.11756627714663452, loss after: 0.11737881662366947]
[epoch 801/1000, batch 21/100 -> loss before: 0.2393547975793348, loss after: 0.2385719621473948]
[epoch 801/1000, batch 31/100 -> loss before: 0.21381809038250704, loss after: 0.21337296260381441]
[epoch 801/1000, batch 41/100 -> loss before: 0.47530897770593616, loss after: 0.4721940133040511]
[epoch 801/1000, batch 51/100 -> loss before: 0.26598388829355357, loss after: 0.2652522146298991]
[epoch 801/1000, batch 61/100 -> loss before: 0.26803470713029987, loss after: 0.26588175405258835]
[epoch 801/1000, batch 71/100 -> loss before: 0.32424871571247205, loss after: 0.32309385711480265]
[epoch 801/1000, batch 81/100 -> loss before: 0.295896823183633, loss after: 0.29203151694207147]
[epoch 801/1000, batch 91/100 -> loss before: 0.24448728225209967, loss after: 0.24382373811021613]
ENDING EPOCH 801/1000 [loss before: 0.28312531147693665, loss after: 0.28307818150536; epoch time: 0.12717151641845703 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.13287260461380215, loss after: 0.1309200650645358]
[epoch 901/1000, batch 11/100 -> loss before: 0.3354531017150864, loss after: 0.3299131012477838]
[epoch 901/1000, batch 21/100 -> loss before: 0.2485863022706908, loss after: 0.24472637094480748]
[epoch 901/1000, batch 31/100 -> loss before: 0.2812630400394737, loss after: 0.27870507638906356]
[epoch 901/1000, batch 41/100 -> loss before: 0.340599043565165, loss after: 0.336857483412624]
[epoch 901/1000, batch 51/100 -> loss before: 0.25018264691437925, loss after: 0.239746512821757]
[epoch 901/1000, batch 61/100 -> loss before: 0.4085723594528335, loss after: 0.40845829735760697]
[epoch 901/1000, batch 71/100 -> loss before: 0.1734486249911844, loss after: 0.17093862833560755]
[epoch 901/1000, batch 81/100 -> loss before: 0.38728398419145404, loss after: 0.38552975507946974]
[epoch 901/1000, batch 91/100 -> loss before: 0.20895603192252973, loss after: 0.20820289505172124]
ENDING EPOCH 901/1000 [loss before: 0.2833246086998075, loss after: 0.28410329220257635; epoch time: 0.1304771900177002 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.26104899596211645, loss after: 0.2584903711059331]
[epoch 1000/1000, batch 11/100 -> loss before: 0.23056642658029508, loss after: 0.229909744579552]
[epoch 1000/1000, batch 21/100 -> loss before: 0.31975483798743987, loss after: 0.3159817075995675]
[epoch 1000/1000, batch 31/100 -> loss before: 0.23658894088434543, loss after: 0.236385568950291]
[epoch 1000/1000, batch 41/100 -> loss before: 0.29447801923043937, loss after: 0.2875442976185901]
[epoch 1000/1000, batch 51/100 -> loss before: 0.30474691013335276, loss after: 0.3002063252345027]
[epoch 1000/1000, batch 61/100 -> loss before: 0.21354784683778041, loss after: 0.21086500684702297]
[epoch 1000/1000, batch 71/100 -> loss before: 0.3478518773750646, loss after: 0.3475275767459745]
[epoch 1000/1000, batch 81/100 -> loss before: 0.10217810568918692, loss after: 0.10217088631267086]
[epoch 1000/1000, batch 91/100 -> loss before: 0.3517559797146818, loss after: 0.35035564011287434]
ENDING EPOCH 1000/1000 [loss before: 0.28336119139938165, loss after: 0.28315838797179504; epoch time: 0.131148099899292 s]
FIT DONE. [time: 121.28825235366821 s]
LOSS TRAIN (MSE): 0.28315838797179504
LOSS TEST (MSE): 0.27754380002332907
R^2 TRAIN: -0.0002833662053216557
R^2 TEST: -4.840995053445596e-05
EXPERIMENT DONE

EXPERIMENT 3132 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 128, 64, 64, 32, 32], activation_name=sigmoid, targets_activation_name=linear, 
initialization_name=uniform, algo_name=rmsprop, learning_rate=0.0001, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 32481]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 0.26392389365226554, loss after: 0.2636371735585876]
[epoch 1/1000, batch 11/100 -> loss before: 0.281059385085488, loss after: 0.27412333490594437]
[epoch 1/1000, batch 21/100 -> loss before: 0.28996016790365176, loss after: 0.28808782307686803]
[epoch 1/1000, batch 31/100 -> loss before: 0.3451101930566362, loss after: 0.344774732874473]
[epoch 1/1000, batch 41/100 -> loss before: 0.3027892030702866, loss after: 0.3017169920869299]
[epoch 1/1000, batch 51/100 -> loss before: 0.18040122272056366, loss after: 0.17481632773077105]
[epoch 1/1000, batch 61/100 -> loss before: 0.24784138132642863, loss after: 0.2454199189577698]
[epoch 1/1000, batch 71/100 -> loss before: 0.3256407240471174, loss after: 0.32549374191678393]
[epoch 1/1000, batch 81/100 -> loss before: 0.3774637696751175, loss after: 0.37745875914163796]
[epoch 1/1000, batch 91/100 -> loss before: 0.3344573126806459, loss after: 0.3330491272814972]
ENDING EPOCH 1/1000 [loss before: 0.2838936199301506, loss after: 0.28306788107597824; epoch time: 0.11213517189025879 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.269628087351777, loss after: 0.26550478486840684]
[epoch 101/1000, batch 11/100 -> loss before: 0.30513916510303163, loss after: 0.30164354293033585]
[epoch 101/1000, batch 21/100 -> loss before: 0.18936533287005616, loss after: 0.18829041141602315]
[epoch 101/1000, batch 31/100 -> loss before: 0.14597103143176077, loss after: 0.1453607058323817]
[epoch 101/1000, batch 41/100 -> loss before: 0.25946905973220846, loss after: 0.25814450538806116]
[epoch 101/1000, batch 51/100 -> loss before: 0.15566918747187916, loss after: 0.15557647808209807]
[epoch 101/1000, batch 61/100 -> loss before: 0.11757717764279227, loss after: 0.11736807407101284]
[epoch 101/1000, batch 71/100 -> loss before: 0.3582162663347283, loss after: 0.35269795086684036]
[epoch 101/1000, batch 81/100 -> loss before: 0.24776170375835357, loss after: 0.23826377920706668]
[epoch 101/1000, batch 91/100 -> loss before: 0.30145148055422544, loss after: 0.3006130310852956]
ENDING EPOCH 101/1000 [loss before: 0.24686294707296702, loss after: 0.24628706435810338; epoch time: 0.08779549598693848 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.5230413493207264, loss after: 0.521481445381789]
[epoch 201/1000, batch 11/100 -> loss before: 0.3717462825515815, loss after: 0.3717415568226684]
[epoch 201/1000, batch 21/100 -> loss before: 0.20572591049280078, loss after: 0.20106931691126886]
[epoch 201/1000, batch 31/100 -> loss before: 0.21498860989380666, loss after: 0.214606322589449]
[epoch 201/1000, batch 41/100 -> loss before: 0.21868319268178865, loss after: 0.21594753508605646]
[epoch 201/1000, batch 51/100 -> loss before: 0.3889886237701959, loss after: 0.3889030738431033]
[epoch 201/1000, batch 61/100 -> loss before: 0.24310382688442997, loss after: 0.2419501725630818]
[epoch 201/1000, batch 71/100 -> loss before: 0.09265105818742138, loss after: 0.09226452366420503]
[epoch 201/1000, batch 81/100 -> loss before: 0.2840508846700064, loss after: 0.278125210585091]
[epoch 201/1000, batch 91/100 -> loss before: 0.32877590970152826, loss after: 0.3277522564958493]
ENDING EPOCH 201/1000 [loss before: 0.23179317857640824, loss after: 0.23201999952828165; epoch time: 0.09501266479492188 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.11639660666650822, loss after: 0.11576622617200913]
[epoch 301/1000, batch 11/100 -> loss before: 0.03963860716705131, loss after: 0.03743635605537986]
[epoch 301/1000, batch 21/100 -> loss before: 0.3125006648575982, loss after: 0.3041057041954173]
[epoch 301/1000, batch 31/100 -> loss before: 0.17481696946357533, loss after: 0.17410259064345074]
[epoch 301/1000, batch 41/100 -> loss before: 0.2828924910507674, loss after: 0.2827719137948104]
[epoch 301/1000, batch 51/100 -> loss before: 0.23040579640542477, loss after: 0.2301334978674868]
[epoch 301/1000, batch 61/100 -> loss before: 0.15364748921893345, loss after: 0.15327706001503294]
[epoch 301/1000, batch 71/100 -> loss before: 0.03815516136128943, loss after: 0.03810703865781821]
[epoch 301/1000, batch 81/100 -> loss before: 0.08599510125344495, loss after: 0.08250526895981485]
[epoch 301/1000, batch 91/100 -> loss before: 0.3152430123853031, loss after: 0.31349767930461103]
ENDING EPOCH 301/1000 [loss before: 0.2310963711328729, loss after: 0.23117852998362332; epoch time: 0.09049463272094727 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.5093134437924993, loss after: 0.5059431080815345]
[epoch 401/1000, batch 11/100 -> loss before: 0.2338600487116409, loss after: 0.23378434540746101]
[epoch 401/1000, batch 21/100 -> loss before: 0.13326307845974314, loss after: 0.1275840951046948]
[epoch 401/1000, batch 31/100 -> loss before: 0.16126722849441594, loss after: 0.16068630396276978]
[epoch 401/1000, batch 41/100 -> loss before: 0.1983518663774199, loss after: 0.198342115416255]
[epoch 401/1000, batch 51/100 -> loss before: 0.32419398361729845, loss after: 0.32174895491950206]
[epoch 401/1000, batch 61/100 -> loss before: 0.2791421482824386, loss after: 0.27894919252532097]
[epoch 401/1000, batch 71/100 -> loss before: 0.22757463950112747, loss after: 0.22101921382046147]
[epoch 401/1000, batch 81/100 -> loss before: 0.44443042789430737, loss after: 0.4402395215615228]
[epoch 401/1000, batch 91/100 -> loss before: 0.09047721294506125, loss after: 0.09038414002186092]
ENDING EPOCH 401/1000 [loss before: 0.23114078270854554, loss after: 0.23057976949055342; epoch time: 0.10330486297607422 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.14139774815628098, loss after: 0.1410566076089414]
[epoch 501/1000, batch 11/100 -> loss before: 0.4124671657734467, loss after: 0.4106090401945271]
[epoch 501/1000, batch 21/100 -> loss before: 0.48642786717262, loss after: 0.485763386561319]
[epoch 501/1000, batch 31/100 -> loss before: 0.11194552570360661, loss after: 0.11193984058708402]
[epoch 501/1000, batch 41/100 -> loss before: 0.2212531658399722, loss after: 0.21444132373559696]
[epoch 501/1000, batch 51/100 -> loss before: 0.15968671832202092, loss after: 0.1593117745361543]
[epoch 501/1000, batch 61/100 -> loss before: 0.4666876014939113, loss after: 0.4632593267310778]
[epoch 501/1000, batch 71/100 -> loss before: 0.2423163890722119, loss after: 0.23998102247725642]
[epoch 501/1000, batch 81/100 -> loss before: 0.29596750900153157, loss after: 0.2952398828627082]
[epoch 501/1000, batch 91/100 -> loss before: 0.20778988778027702, loss after: 0.20746417968719721]
ENDING EPOCH 501/1000 [loss before: 0.23008336026346343, loss after: 0.23044280026110878; epoch time: 0.07882285118103027 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.22317766514361242, loss after: 0.22284753146224726]
[epoch 601/1000, batch 11/100 -> loss before: 0.3039133449319366, loss after: 0.29736318026680497]
[epoch 601/1000, batch 21/100 -> loss before: 0.43020826241655624, loss after: 0.4262152749761256]
[epoch 601/1000, batch 31/100 -> loss before: 0.11992984666461123, loss after: 0.11865098005533754]
[epoch 601/1000, batch 41/100 -> loss before: 0.21773416662808107, loss after: 0.21401088913989436]
[epoch 601/1000, batch 51/100 -> loss before: 0.2973300251687028, loss after: 0.29505166150714274]
[epoch 601/1000, batch 61/100 -> loss before: 0.1831847601353021, loss after: 0.1806304293574664]
[epoch 601/1000, batch 71/100 -> loss before: 0.20822312512342916, loss after: 0.20600563343932876]
[epoch 601/1000, batch 81/100 -> loss before: 0.22101201060816583, loss after: 0.22066881182518155]
[epoch 601/1000, batch 91/100 -> loss before: 0.5135503616026946, loss after: 0.5134187922565687]
ENDING EPOCH 601/1000 [loss before: 0.2282273789008687, loss after: 0.2285409381004634; epoch time: 0.07646489143371582 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.16959503075222473, loss after: 0.16621837785986326]
[epoch 701/1000, batch 11/100 -> loss before: 0.2358919684972328, loss after: 0.230099296622199]
[epoch 701/1000, batch 21/100 -> loss before: 0.19212952316997733, loss after: 0.18573840453901208]
[epoch 701/1000, batch 31/100 -> loss before: 0.28135762193831637, loss after: 0.28077547459605867]
[epoch 701/1000, batch 41/100 -> loss before: 0.11410150748023981, loss after: 0.11025354111953349]
[epoch 701/1000, batch 51/100 -> loss before: 0.13339031132990006, loss after: 0.12979924040904495]
[epoch 701/1000, batch 61/100 -> loss before: 0.20474493535536992, loss after: 0.20421031158097688]
[epoch 701/1000, batch 71/100 -> loss before: 0.12254543529474134, loss after: 0.11677898784350382]
[epoch 701/1000, batch 81/100 -> loss before: 0.20146163818863463, loss after: 0.1968161839105466]
[epoch 701/1000, batch 91/100 -> loss before: 0.24019529245086138, loss after: 0.23417303781492937]
ENDING EPOCH 701/1000 [loss before: 0.2101983634741727, loss after: 0.2064541764092818; epoch time: 0.07755923271179199 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.14165004956774724, loss after: 0.13485840580769307]
[epoch 801/1000, batch 11/100 -> loss before: 0.14334362872525666, loss after: 0.14029399497780898]
[epoch 801/1000, batch 21/100 -> loss before: 0.16526838231602806, loss after: 0.15988061955694746]
[epoch 801/1000, batch 31/100 -> loss before: 0.11249112237535204, loss after: 0.11028918439795868]
[epoch 801/1000, batch 41/100 -> loss before: 0.2510025651827222, loss after: 0.2485085537181872]
[epoch 801/1000, batch 51/100 -> loss before: 0.2467164199108444, loss after: 0.24284913521977525]
[epoch 801/1000, batch 61/100 -> loss before: 0.15601838261249562, loss after: 0.15510074526772077]
[epoch 801/1000, batch 71/100 -> loss before: 0.19413791019426557, loss after: 0.19401564368477647]
[epoch 801/1000, batch 81/100 -> loss before: 0.08230924419453504, loss after: 0.07870193655834982]
[epoch 801/1000, batch 91/100 -> loss before: 0.18584961178252038, loss after: 0.18401262461225165]
ENDING EPOCH 801/1000 [loss before: 0.1880830871084211, loss after: 0.18821333256678918; epoch time: 0.08008790016174316 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.137563376203753, loss after: 0.1357316407271486]
[epoch 901/1000, batch 11/100 -> loss before: 0.12630013490332925, loss after: 0.12440180295051981]
[epoch 901/1000, batch 21/100 -> loss before: 0.03671631586060514, loss after: 0.03318704323834065]
[epoch 901/1000, batch 31/100 -> loss before: 0.1326941035142511, loss after: 0.1304911747787554]
[epoch 901/1000, batch 41/100 -> loss before: 0.11166141895172485, loss after: 0.10972727056713194]
[epoch 901/1000, batch 51/100 -> loss before: 0.19017942719830289, loss after: 0.18232255906493222]
[epoch 901/1000, batch 61/100 -> loss before: 0.2515206062635899, loss after: 0.24609125624183412]
[epoch 901/1000, batch 71/100 -> loss before: 0.26403280083368413, loss after: 0.2607773642853207]
[epoch 901/1000, batch 81/100 -> loss before: 0.14743570813474902, loss after: 0.13725007927541175]
[epoch 901/1000, batch 91/100 -> loss before: 0.15213974390013837, loss after: 0.14438794907427352]
ENDING EPOCH 901/1000 [loss before: 0.15699099892821944, loss after: 0.15666872374017005; epoch time: 0.08761119842529297 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.14906044743247904, loss after: 0.14748328967666885]
[epoch 1000/1000, batch 11/100 -> loss before: 0.18545442926311573, loss after: 0.17152812749961815]
[epoch 1000/1000, batch 21/100 -> loss before: 0.15644795901972292, loss after: 0.14266149481391238]
[epoch 1000/1000, batch 31/100 -> loss before: 0.14287173947516915, loss after: 0.14031947238430284]
[epoch 1000/1000, batch 41/100 -> loss before: 0.045074974041423396, loss after: 0.04273907891588691]
[epoch 1000/1000, batch 51/100 -> loss before: 0.14355234516307197, loss after: 0.14174233078527318]
[epoch 1000/1000, batch 61/100 -> loss before: 0.17490328356769025, loss after: 0.16526176979634516]
[epoch 1000/1000, batch 71/100 -> loss before: 0.15965876108885296, loss after: 0.14995599389336264]
[epoch 1000/1000, batch 81/100 -> loss before: 0.2955703712067001, loss after: 0.28225464173597803]
[epoch 1000/1000, batch 91/100 -> loss before: 0.25004800409870725, loss after: 0.24345206781791212]
ENDING EPOCH 1000/1000 [loss before: 0.14683358640079913, loss after: 0.14601888626620316; epoch time: 0.09201836585998535 s]
FIT DONE. [time: 76.67345595359802 s]
LOSS TRAIN (MSE): 0.14601888626620316
LOSS TEST (MSE): 0.14239546354691734
R^2 TRAIN: 0.48417469060299023
R^2 TEST: 0.486919337083753
EXPERIMENT DONE

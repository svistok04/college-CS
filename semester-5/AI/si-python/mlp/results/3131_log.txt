EXPERIMENT 3131 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 64, 32], activation_name=sigmoid, targets_activation_name=linear, 
initialization_name=uniform, algo_name=rmsprop, learning_rate=0.0001, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 10753]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 1.6197437009973044, loss after: 1.545603287305155]
[epoch 1/1000, batch 11/100 -> loss before: 0.49833032233607144, loss after: 0.48588832520665254]
[epoch 1/1000, batch 21/100 -> loss before: 0.1901260586286288, loss after: 0.18556572032346388]
[epoch 1/1000, batch 31/100 -> loss before: 0.5276590646817343, loss after: 0.5238486838612187]
[epoch 1/1000, batch 41/100 -> loss before: 0.24412124930368378, loss after: 0.24014997931187748]
[epoch 1/1000, batch 51/100 -> loss before: 0.6330331924933036, loss after: 0.6131511410728275]
[epoch 1/1000, batch 61/100 -> loss before: 0.4918557222493722, loss after: 0.4917728005163634]
[epoch 1/1000, batch 71/100 -> loss before: 0.42918568623388464, loss after: 0.42572250482127333]
[epoch 1/1000, batch 81/100 -> loss before: 0.15387789593765322, loss after: 0.1525479154822141]
[epoch 1/1000, batch 91/100 -> loss before: 0.40788588511260154, loss after: 0.405887486839679]
ENDING EPOCH 1/1000 [loss before: 0.7227142221308361, loss after: 0.2842722940456602; epoch time: 0.041945457458496094 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.26662202190710166, loss after: 0.2647431176763994]
[epoch 101/1000, batch 11/100 -> loss before: 0.1237168887489662, loss after: 0.12291850847313932]
[epoch 101/1000, batch 21/100 -> loss before: 0.12449639556838901, loss after: 0.1241016209567948]
[epoch 101/1000, batch 31/100 -> loss before: 0.20914282547503354, loss after: 0.2086363769308867]
[epoch 101/1000, batch 41/100 -> loss before: 0.5310069330220435, loss after: 0.5291417772579541]
[epoch 101/1000, batch 51/100 -> loss before: 0.19996100027971903, loss after: 0.1992480359472562]
[epoch 101/1000, batch 61/100 -> loss before: 0.29338377490686474, loss after: 0.28560216970742147]
[epoch 101/1000, batch 71/100 -> loss before: 0.22982361705179644, loss after: 0.2298158182917648]
[epoch 101/1000, batch 81/100 -> loss before: 0.2869649175845148, loss after: 0.2848062201460328]
[epoch 101/1000, batch 91/100 -> loss before: 0.34180645494748074, loss after: 0.34114149112626563]
ENDING EPOCH 101/1000 [loss before: 0.26742938573952113, loss after: 0.2675799821999715; epoch time: 0.03608226776123047 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.1797189528869804, loss after: 0.17750722465062807]
[epoch 201/1000, batch 11/100 -> loss before: 0.2062792791469354, loss after: 0.19748975325259072]
[epoch 201/1000, batch 21/100 -> loss before: 0.1856440915296608, loss after: 0.18495332776911638]
[epoch 201/1000, batch 31/100 -> loss before: 0.2552221605962685, loss after: 0.2548837038786289]
[epoch 201/1000, batch 41/100 -> loss before: 0.3260383246648636, loss after: 0.3258994764697648]
[epoch 201/1000, batch 51/100 -> loss before: 0.3943346716944819, loss after: 0.3938516930071406]
[epoch 201/1000, batch 61/100 -> loss before: 0.3613282005899045, loss after: 0.35855324781944636]
[epoch 201/1000, batch 71/100 -> loss before: 0.14601119598914777, loss after: 0.1401252910212956]
[epoch 201/1000, batch 81/100 -> loss before: 0.17047063646239213, loss after: 0.1699989715431948]
[epoch 201/1000, batch 91/100 -> loss before: 0.13810497702177377, loss after: 0.13804151213453303]
ENDING EPOCH 201/1000 [loss before: 0.26541902218795566, loss after: 0.26530188786683145; epoch time: 0.03655052185058594 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.1888234422891114, loss after: 0.1877072318062603]
[epoch 301/1000, batch 11/100 -> loss before: 0.48580995684858497, loss after: 0.47159523707081413]
[epoch 301/1000, batch 21/100 -> loss before: 0.20061534916045135, loss after: 0.19264728257082905]
[epoch 301/1000, batch 31/100 -> loss before: 0.18813715930709177, loss after: 0.18687161004323724]
[epoch 301/1000, batch 41/100 -> loss before: 0.08536913042519259, loss after: 0.08523245731640199]
[epoch 301/1000, batch 51/100 -> loss before: 0.3015485174289093, loss after: 0.2974530778533445]
[epoch 301/1000, batch 61/100 -> loss before: 0.19226674805782448, loss after: 0.19074394440150177]
[epoch 301/1000, batch 71/100 -> loss before: 0.3048159121892204, loss after: 0.29425973962472907]
[epoch 301/1000, batch 81/100 -> loss before: 0.14510973125943294, loss after: 0.14484673939217846]
[epoch 301/1000, batch 91/100 -> loss before: 0.28404257539125255, loss after: 0.27110597563112276]
ENDING EPOCH 301/1000 [loss before: 0.2552900866043618, loss after: 0.25474416023550955; epoch time: 0.04379987716674805 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.4063672755217055, loss after: 0.4061436638596567]
[epoch 401/1000, batch 11/100 -> loss before: 0.2893625537487722, loss after: 0.2881182160822336]
[epoch 401/1000, batch 21/100 -> loss before: 0.19337514272326956, loss after: 0.1910112060361306]
[epoch 401/1000, batch 31/100 -> loss before: 0.4024029285076495, loss after: 0.39115606384776236]
[epoch 401/1000, batch 41/100 -> loss before: 0.12987659070989227, loss after: 0.12800676721837412]
[epoch 401/1000, batch 51/100 -> loss before: 0.3607627416455881, loss after: 0.3596345677071934]
[epoch 401/1000, batch 61/100 -> loss before: 0.16037821369359304, loss after: 0.15899208795652325]
[epoch 401/1000, batch 71/100 -> loss before: 0.2195360091905873, loss after: 0.2179410551505893]
[epoch 401/1000, batch 81/100 -> loss before: 0.29099859398102157, loss after: 0.287417908409592]
[epoch 401/1000, batch 91/100 -> loss before: 0.19755689116527997, loss after: 0.19737253690014236]
ENDING EPOCH 401/1000 [loss before: 0.23599804246403358, loss after: 0.23713490681116783; epoch time: 0.04784512519836426 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.24574315880529451, loss after: 0.23825860714415747]
[epoch 501/1000, batch 11/100 -> loss before: 0.2537348799969059, loss after: 0.25296260309824015]
[epoch 501/1000, batch 21/100 -> loss before: 0.1346593666153987, loss after: 0.133745343316742]
[epoch 501/1000, batch 31/100 -> loss before: 0.16780286945207476, loss after: 0.16771726189028724]
[epoch 501/1000, batch 41/100 -> loss before: 0.1977611675316562, loss after: 0.19514200382384467]
[epoch 501/1000, batch 51/100 -> loss before: 0.18860853144177475, loss after: 0.1819508132644071]
[epoch 501/1000, batch 61/100 -> loss before: 0.1429709070012902, loss after: 0.1391405838551198]
[epoch 501/1000, batch 71/100 -> loss before: 0.20437214013051208, loss after: 0.20414630908499412]
[epoch 501/1000, batch 81/100 -> loss before: 0.23942878689409555, loss after: 0.23885270599158437]
[epoch 501/1000, batch 91/100 -> loss before: 0.3878052397803656, loss after: 0.3818486433582531]
ENDING EPOCH 501/1000 [loss before: 0.23354510520015456, loss after: 0.23274133801916758; epoch time: 0.04975581169128418 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.31463046554138535, loss after: 0.31422924145927367]
[epoch 601/1000, batch 11/100 -> loss before: 0.1626045600944726, loss after: 0.16233986754445368]
[epoch 601/1000, batch 21/100 -> loss before: 0.5302366196884125, loss after: 0.5254433970745084]
[epoch 601/1000, batch 31/100 -> loss before: 0.11178661196938808, loss after: 0.11101464213885523]
[epoch 601/1000, batch 41/100 -> loss before: 0.12766596365783478, loss after: 0.12456897909343397]
[epoch 601/1000, batch 51/100 -> loss before: 0.2530613932426619, loss after: 0.24962577191999982]
[epoch 601/1000, batch 61/100 -> loss before: 0.37106790423148134, loss after: 0.3680462082795334]
[epoch 601/1000, batch 71/100 -> loss before: 0.3323074791625368, loss after: 0.33208754015228875]
[epoch 601/1000, batch 81/100 -> loss before: 0.0831308625029096, loss after: 0.0820162744949697]
[epoch 601/1000, batch 91/100 -> loss before: 0.09066350364249025, loss after: 0.08929459989095652]
ENDING EPOCH 601/1000 [loss before: 0.23203869158956877, loss after: 0.23187175760177364; epoch time: 0.05030965805053711 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.2096978106197686, loss after: 0.2067019558849656]
[epoch 701/1000, batch 11/100 -> loss before: 0.23408739248962843, loss after: 0.22940226032703123]
[epoch 701/1000, batch 21/100 -> loss before: 0.21002152793590997, loss after: 0.2082788114012573]
[epoch 701/1000, batch 31/100 -> loss before: 0.11207029701821573, loss after: 0.11193718485146906]
[epoch 701/1000, batch 41/100 -> loss before: 0.17909097741109634, loss after: 0.17749321198067158]
[epoch 701/1000, batch 51/100 -> loss before: 0.32919087015886206, loss after: 0.327099564150393]
[epoch 701/1000, batch 61/100 -> loss before: 0.07066440087533925, loss after: 0.07001136188372296]
[epoch 701/1000, batch 71/100 -> loss before: 0.18987385375517693, loss after: 0.18933922968084277]
[epoch 701/1000, batch 81/100 -> loss before: 0.2896477998305876, loss after: 0.2876392933546259]
[epoch 701/1000, batch 91/100 -> loss before: 0.24973127705784917, loss after: 0.2494829395718734]
ENDING EPOCH 701/1000 [loss before: 0.23053655854315627, loss after: 0.23023298549111135; epoch time: 0.044270992279052734 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.40065815694607554, loss after: 0.39055979655632]
[epoch 801/1000, batch 11/100 -> loss before: 0.18689077057661446, loss after: 0.18316610839155495]
[epoch 801/1000, batch 21/100 -> loss before: 0.40266669899050384, loss after: 0.4004258415257399]
[epoch 801/1000, batch 31/100 -> loss before: 0.1794627151929907, loss after: 0.17940961541460093]
[epoch 801/1000, batch 41/100 -> loss before: 0.22164677414627393, loss after: 0.22095120491706802]
[epoch 801/1000, batch 51/100 -> loss before: 0.26936102963174097, loss after: 0.26887670087788595]
[epoch 801/1000, batch 61/100 -> loss before: 0.22653490365756074, loss after: 0.2211174759568208]
[epoch 801/1000, batch 71/100 -> loss before: 0.18862388912840958, loss after: 0.17895055016425163]
[epoch 801/1000, batch 81/100 -> loss before: 0.2972855578649297, loss after: 0.2960901539990939]
[epoch 801/1000, batch 91/100 -> loss before: 0.12838631988171675, loss after: 0.1277290862825736]
ENDING EPOCH 801/1000 [loss before: 0.22521435674684828, loss after: 0.2251844936224175; epoch time: 0.046181678771972656 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.2299571940589304, loss after: 0.2281045881198695]
[epoch 901/1000, batch 11/100 -> loss before: 0.3183875527231462, loss after: 0.31741364820453144]
[epoch 901/1000, batch 21/100 -> loss before: 0.12949955064028287, loss after: 0.12653425299490645]
[epoch 901/1000, batch 31/100 -> loss before: 0.14555909550625795, loss after: 0.14471539773935072]
[epoch 901/1000, batch 41/100 -> loss before: 0.029665538147452004, loss after: 0.0295985096444081]
[epoch 901/1000, batch 51/100 -> loss before: 0.2682271062095981, loss after: 0.2648140046917877]
[epoch 901/1000, batch 61/100 -> loss before: 0.251466568539822, loss after: 0.25061650216893094]
[epoch 901/1000, batch 71/100 -> loss before: 0.11195192659665562, loss after: 0.11187659454246675]
[epoch 901/1000, batch 81/100 -> loss before: 0.19486535109759806, loss after: 0.19029769260401214]
[epoch 901/1000, batch 91/100 -> loss before: 0.06997967048253884, loss after: 0.06951691269409507]
ENDING EPOCH 901/1000 [loss before: 0.21474498274955123, loss after: 0.21468377588072668; epoch time: 0.0357515811920166 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.07876856592221468, loss after: 0.07842075643626237]
[epoch 1000/1000, batch 11/100 -> loss before: 0.24188109794652973, loss after: 0.23874182241117378]
[epoch 1000/1000, batch 21/100 -> loss before: 0.1738151107447244, loss after: 0.1727113699053838]
[epoch 1000/1000, batch 31/100 -> loss before: 0.18254341076295127, loss after: 0.17902710210580172]
[epoch 1000/1000, batch 41/100 -> loss before: 0.2551791930352715, loss after: 0.25337777806723294]
[epoch 1000/1000, batch 51/100 -> loss before: 0.24449699507375736, loss after: 0.24321605132918153]
[epoch 1000/1000, batch 61/100 -> loss before: 0.17198102060006923, loss after: 0.16873148919437136]
[epoch 1000/1000, batch 71/100 -> loss before: 0.18234284197365783, loss after: 0.18005988289756092]
[epoch 1000/1000, batch 81/100 -> loss before: 0.2914500566382676, loss after: 0.29068846327991904]
[epoch 1000/1000, batch 91/100 -> loss before: 0.28015606468242615, loss after: 0.2748338170332053]
ENDING EPOCH 1000/1000 [loss before: 0.20647708497156003, loss after: 0.2066536890977994; epoch time: 0.03681492805480957 s]
FIT DONE. [time: 38.32196092605591 s]
LOSS TRAIN (MSE): 0.2066536890977994
LOSS TEST (MSE): 0.19987375886636716
R^2 TRAIN: 0.269976604789525
R^2 TEST: 0.2798130070700706
EXPERIMENT DONE

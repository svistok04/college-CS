EXPERIMENT 1121 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 64, 32], activation_name=sigmoid, targets_activation_name=linear, 
initialization_name=uniform, algo_name=sgd_momentum, learning_rate=0.01, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 10753]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 1.6197437009973044, loss after: 1.1387453225423492]
[epoch 1/1000, batch 11/100 -> loss before: 0.1942807252819995, loss after: 0.23006181167561673]
[epoch 1/1000, batch 21/100 -> loss before: 0.2508538802039802, loss after: 0.30094163373313976]
[epoch 1/1000, batch 31/100 -> loss before: 0.49559096264878627, loss after: 0.4865684951557435]
[epoch 1/1000, batch 41/100 -> loss before: 0.20972273682974601, loss after: 0.1758499823027725]
[epoch 1/1000, batch 51/100 -> loss before: 0.32535695483763233, loss after: 0.2595358033029106]
[epoch 1/1000, batch 61/100 -> loss before: 0.4892342905483277, loss after: 0.4950282003860876]
[epoch 1/1000, batch 71/100 -> loss before: 0.5568423470653437, loss after: 0.5136106188915207]
[epoch 1/1000, batch 81/100 -> loss before: 0.15007757317506978, loss after: 0.1516992637206873]
[epoch 1/1000, batch 91/100 -> loss before: 0.46153853573728487, loss after: 0.4246172684229525]
ENDING EPOCH 1/1000 [loss before: 0.7227142221308361, loss after: 0.2942230476343876; epoch time: 0.032614946365356445 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.1662582801266964, loss after: 0.1661274770777002]
[epoch 101/1000, batch 11/100 -> loss before: 0.10885192045700554, loss after: 0.10919386227529246]
[epoch 101/1000, batch 21/100 -> loss before: 0.0956901548244651, loss after: 0.09611034910240687]
[epoch 101/1000, batch 31/100 -> loss before: 0.1845731758854861, loss after: 0.18441589730023744]
[epoch 101/1000, batch 41/100 -> loss before: 0.428052092757531, loss after: 0.42794506910226565]
[epoch 101/1000, batch 51/100 -> loss before: 0.18663125521113633, loss after: 0.18493044114073182]
[epoch 101/1000, batch 61/100 -> loss before: 0.2060665128729096, loss after: 0.20508611393440476]
[epoch 101/1000, batch 71/100 -> loss before: 0.24699827148648829, loss after: 0.24704870197324125]
[epoch 101/1000, batch 81/100 -> loss before: 0.2773917174912509, loss after: 0.2793176979282355]
[epoch 101/1000, batch 91/100 -> loss before: 0.27458944952874714, loss after: 0.2746566862758882]
ENDING EPOCH 101/1000 [loss before: 0.23583764406582455, loss after: 0.23628188651473717; epoch time: 0.03239750862121582 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.20033522283511154, loss after: 0.19902882970009111]
[epoch 201/1000, batch 11/100 -> loss before: 0.18399819662775121, loss after: 0.18075761358421133]
[epoch 201/1000, batch 21/100 -> loss before: 0.18177947003131717, loss after: 0.18085335108039835]
[epoch 201/1000, batch 31/100 -> loss before: 0.2169714792160764, loss after: 0.21652286620376854]
[epoch 201/1000, batch 41/100 -> loss before: 0.3845507302622978, loss after: 0.38470427324604584]
[epoch 201/1000, batch 51/100 -> loss before: 0.3702882458577778, loss after: 0.36965963557583886]
[epoch 201/1000, batch 61/100 -> loss before: 0.28020835316812287, loss after: 0.2770992920031071]
[epoch 201/1000, batch 71/100 -> loss before: 0.12464984900612563, loss after: 0.12403488666424316]
[epoch 201/1000, batch 81/100 -> loss before: 0.1271178093653643, loss after: 0.12384456562951862]
[epoch 201/1000, batch 91/100 -> loss before: 0.09913659619208073, loss after: 0.09912491480177851]
ENDING EPOCH 201/1000 [loss before: 0.2323580347796617, loss after: 0.23301739953748885; epoch time: 0.03869915008544922 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.17162608984347555, loss after: 0.17158054458936506]
[epoch 301/1000, batch 11/100 -> loss before: 0.4397863653266804, loss after: 0.43572688127649234]
[epoch 301/1000, batch 21/100 -> loss before: 0.23562866606974348, loss after: 0.23260611462716874]
[epoch 301/1000, batch 31/100 -> loss before: 0.1632150145523802, loss after: 0.16304563494596877]
[epoch 301/1000, batch 41/100 -> loss before: 0.0637702482219377, loss after: 0.06388738547272246]
[epoch 301/1000, batch 51/100 -> loss before: 0.2551790332492123, loss after: 0.2558023848972177]
[epoch 301/1000, batch 61/100 -> loss before: 0.14034586119401615, loss after: 0.1399350767640662]
[epoch 301/1000, batch 71/100 -> loss before: 0.3413906931597805, loss after: 0.3326740928862856]
[epoch 301/1000, batch 81/100 -> loss before: 0.1377585677290632, loss after: 0.13744582145665746]
[epoch 301/1000, batch 91/100 -> loss before: 0.25671506563171675, loss after: 0.25481139241143475]
ENDING EPOCH 301/1000 [loss before: 0.23344667647767292, loss after: 0.2315304419288748; epoch time: 0.03575754165649414 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.4011002562095466, loss after: 0.4009210563384594]
[epoch 401/1000, batch 11/100 -> loss before: 0.2981891776736054, loss after: 0.29948530267729523]
[epoch 401/1000, batch 21/100 -> loss before: 0.18071886490796002, loss after: 0.18102639845342608]
[epoch 401/1000, batch 31/100 -> loss before: 0.3746051305815903, loss after: 0.3666926208414961]
[epoch 401/1000, batch 41/100 -> loss before: 0.11733129202795942, loss after: 0.11780844163715512]
[epoch 401/1000, batch 51/100 -> loss before: 0.3532903948462941, loss after: 0.35255321046991217]
[epoch 401/1000, batch 61/100 -> loss before: 0.15960004903995484, loss after: 0.15952303137575316]
[epoch 401/1000, batch 71/100 -> loss before: 0.19273976727461664, loss after: 0.19091205322931923]
[epoch 401/1000, batch 81/100 -> loss before: 0.32483011421477775, loss after: 0.32649340844433167]
[epoch 401/1000, batch 91/100 -> loss before: 0.20023919046393973, loss after: 0.20055459513829005]
ENDING EPOCH 401/1000 [loss before: 0.23374308671913116, loss after: 0.2382371285543785; epoch time: 0.030969619750976562 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.23431459188985623, loss after: 0.23537063369794975]
[epoch 501/1000, batch 11/100 -> loss before: 0.2542061818611989, loss after: 0.25335920682251506]
[epoch 501/1000, batch 21/100 -> loss before: 0.12599716291422616, loss after: 0.12442440439049415]
[epoch 501/1000, batch 31/100 -> loss before: 0.17374047760888253, loss after: 0.1737652758768713]
[epoch 501/1000, batch 41/100 -> loss before: 0.1933881876475103, loss after: 0.189161767564385]
[epoch 501/1000, batch 51/100 -> loss before: 0.21327996880104644, loss after: 0.20314896856364534]
[epoch 501/1000, batch 61/100 -> loss before: 0.11805108135059943, loss after: 0.11135769325656886]
[epoch 501/1000, batch 71/100 -> loss before: 0.21122356337248188, loss after: 0.21114107554301134]
[epoch 501/1000, batch 81/100 -> loss before: 0.24323936718068723, loss after: 0.2420770021319508]
[epoch 501/1000, batch 91/100 -> loss before: 0.414211117576078, loss after: 0.41125600015842717]
ENDING EPOCH 501/1000 [loss before: 0.22704887187804837, loss after: 0.2275221639248598; epoch time: 0.04013228416442871 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.15992574937332654, loss after: 0.1605093300181824]
[epoch 601/1000, batch 11/100 -> loss before: 0.1330625264088854, loss after: 0.13435272877603577]
[epoch 601/1000, batch 21/100 -> loss before: 0.3178593241868648, loss after: 0.31412144797704067]
[epoch 601/1000, batch 31/100 -> loss before: 0.08640992774469841, loss after: 0.08638375160823877]
[epoch 601/1000, batch 41/100 -> loss before: 0.08954773453235419, loss after: 0.08794739673321358]
[epoch 601/1000, batch 51/100 -> loss before: 0.2831294643384207, loss after: 0.2924075546173263]
[epoch 601/1000, batch 61/100 -> loss before: 0.36964041797286107, loss after: 0.3592170211415978]
[epoch 601/1000, batch 71/100 -> loss before: 0.28981210883384695, loss after: 0.2864871632073295]
[epoch 601/1000, batch 81/100 -> loss before: 0.06452706389640464, loss after: 0.0673529354220272]
[epoch 601/1000, batch 91/100 -> loss before: 0.07096949865779163, loss after: 0.072414415773768]
ENDING EPOCH 601/1000 [loss before: 0.19786310864399478, loss after: 0.19865899966819422; epoch time: 0.04406380653381348 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.13470649274453877, loss after: 0.13437835779433063]
[epoch 701/1000, batch 11/100 -> loss before: 0.14465731459995873, loss after: 0.1365916714831062]
[epoch 701/1000, batch 21/100 -> loss before: 0.06326329390869175, loss after: 0.06062876760890136]
[epoch 701/1000, batch 31/100 -> loss before: 0.08099266540078584, loss after: 0.07851007591143191]
[epoch 701/1000, batch 41/100 -> loss before: 0.12009828492985122, loss after: 0.11798246769371341]
[epoch 701/1000, batch 51/100 -> loss before: 0.18266835777562412, loss after: 0.18067481265947866]
[epoch 701/1000, batch 61/100 -> loss before: 0.04363717309732221, loss after: 0.0414206556622396]
[epoch 701/1000, batch 71/100 -> loss before: 0.10008042390750482, loss after: 0.09254262454453606]
[epoch 701/1000, batch 81/100 -> loss before: 0.23022379209911273, loss after: 0.2243359801976931]
[epoch 701/1000, batch 91/100 -> loss before: 0.22856877699859535, loss after: 0.22749036587342567]
ENDING EPOCH 701/1000 [loss before: 0.17427780776873236, loss after: 0.16085754700084395; epoch time: 0.04252123832702637 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.4603924414326134, loss after: 0.4548076227817862]
[epoch 801/1000, batch 11/100 -> loss before: 0.1943735803941148, loss after: 0.17122270365239162]
[epoch 801/1000, batch 21/100 -> loss before: 0.29136965762576206, loss after: 0.27243598974169136]
[epoch 801/1000, batch 31/100 -> loss before: 0.04573105714059549, loss after: 0.04450479723469068]
[epoch 801/1000, batch 41/100 -> loss before: 0.06834600943145916, loss after: 0.06829335356745436]
[epoch 801/1000, batch 51/100 -> loss before: 0.1836010276188072, loss after: 0.18472981596117072]
[epoch 801/1000, batch 61/100 -> loss before: 0.09729227529009818, loss after: 0.09315558928001225]
[epoch 801/1000, batch 71/100 -> loss before: 0.010449836338789698, loss after: 0.010749856908878317]
[epoch 801/1000, batch 81/100 -> loss before: 0.12139995397393732, loss after: 0.11657266101265522]
[epoch 801/1000, batch 91/100 -> loss before: 0.04723372965027254, loss after: 0.03862698211621211]
ENDING EPOCH 801/1000 [loss before: 0.1469149844120671, loss after: 0.1410799679243241; epoch time: 0.037758588790893555 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.03338518549398441, loss after: 0.031865408578567275]
[epoch 901/1000, batch 11/100 -> loss before: 0.08828044220601411, loss after: 0.08586176398781188]
[epoch 901/1000, batch 21/100 -> loss before: 0.10252112395390438, loss after: 0.09519372289211099]
[epoch 901/1000, batch 31/100 -> loss before: 0.12022319619810266, loss after: 0.12286391252245259]
[epoch 901/1000, batch 41/100 -> loss before: 0.012104485571605855, loss after: 0.012331515122899508]
[epoch 901/1000, batch 51/100 -> loss before: 0.13550928822532124, loss after: 0.13456717426903925]
[epoch 901/1000, batch 61/100 -> loss before: 0.1401136129014567, loss after: 0.1366686680950096]
[epoch 901/1000, batch 71/100 -> loss before: 0.08506309722353304, loss after: 0.07848685071081477]
[epoch 901/1000, batch 81/100 -> loss before: 0.11509252973486632, loss after: 0.10618080076156525]
[epoch 901/1000, batch 91/100 -> loss before: 0.03419305009445141, loss after: 0.032289546256719856]
ENDING EPOCH 901/1000 [loss before: 0.10794169066656675, loss after: 0.10629374229936157; epoch time: 0.04094958305358887 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.04715326527525486, loss after: 0.04430592633445062]
[epoch 1000/1000, batch 11/100 -> loss before: 0.017186160573389897, loss after: 0.016513628558034052]
[epoch 1000/1000, batch 21/100 -> loss before: 0.12824673810584525, loss after: 0.12459053612071094]
[epoch 1000/1000, batch 31/100 -> loss before: 0.04833554768707491, loss after: 0.049139375670534204]
[epoch 1000/1000, batch 41/100 -> loss before: 0.17106439863408224, loss after: 0.1691739981638121]
[epoch 1000/1000, batch 51/100 -> loss before: 0.11775816522986285, loss after: 0.11713717366087113]
[epoch 1000/1000, batch 61/100 -> loss before: 0.12278670950743106, loss after: 0.12272640300878783]
[epoch 1000/1000, batch 71/100 -> loss before: 0.03129692554214506, loss after: 0.03216518285402111]
[epoch 1000/1000, batch 81/100 -> loss before: 0.20010337025881908, loss after: 0.2009107177159045]
[epoch 1000/1000, batch 91/100 -> loss before: 0.2681913648031683, loss after: 0.2642441884573768]
ENDING EPOCH 1000/1000 [loss before: 0.08870022372276133, loss after: 0.09365687256087728; epoch time: 0.0422055721282959 s]
FIT DONE. [time: 31.36523723602295 s]
LOSS TRAIN (MSE): 0.09365687256087728
LOSS TEST (MSE): 0.091752182393984
R^2 TRAIN: 0.6691483786707078
R^2 TEST: 0.6693976802764736
EXPERIMENT DONE

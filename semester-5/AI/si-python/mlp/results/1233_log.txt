EXPERIMENT 1233 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[64, 64, 64, 64, 64, 32, 32, 32, 32, 32, 16, 16, 16, 16, 16, 8, 8, 8, 8, 8], activation_name=relu, targets_activation_name=linear, 
initialization_name=uniform, algo_name=rmsprop, learning_rate=0.01, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 25185]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 0.18318931763552243, loss after: 79.46139857620807]
[epoch 1/1000, batch 11/100 -> loss before: 0.36946822208260366, loss after: 0.37101736110810407]
[epoch 1/1000, batch 21/100 -> loss before: 3.4659535235156937, loss after: 0.3572468110241988]
[epoch 1/1000, batch 31/100 -> loss before: 0.3971019643168914, loss after: 0.3885025872626723]
[epoch 1/1000, batch 41/100 -> loss before: 0.20685455455431473, loss after: 0.2056351179306461]
[epoch 1/1000, batch 51/100 -> loss before: 0.2644525637868771, loss after: 0.2549852125001964]
[epoch 1/1000, batch 61/100 -> loss before: 0.4707532476181089, loss after: 0.4690272273876208]
[epoch 1/1000, batch 71/100 -> loss before: 0.3442692706211289, loss after: 0.3416120548673315]
[epoch 1/1000, batch 81/100 -> loss before: 0.4023471239794321, loss after: 0.40073786179504556]
[epoch 1/1000, batch 91/100 -> loss before: 0.2950796597822941, loss after: 0.2934160980273239]
ENDING EPOCH 1/1000 [loss before: 0.2899884218128069, loss after: 0.2832738719978524; epoch time: 0.12186956405639648 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.28997003794386234, loss after: 0.2889362275135515]
[epoch 101/1000, batch 11/100 -> loss before: 0.2197856360447473, loss after: 0.21978183845224372]
[epoch 101/1000, batch 21/100 -> loss before: 0.24271314357803386, loss after: 0.2420583050095321]
[epoch 101/1000, batch 31/100 -> loss before: 0.39081562420751487, loss after: 0.3873645177552052]
[epoch 101/1000, batch 41/100 -> loss before: 0.6619978833869883, loss after: 0.6407413937041044]
[epoch 101/1000, batch 51/100 -> loss before: 0.256175648126478, loss after: 0.249132464290786]
[epoch 101/1000, batch 61/100 -> loss before: 0.5163238184927202, loss after: 0.5160802996438216]
[epoch 101/1000, batch 71/100 -> loss before: 0.14463446767334848, loss after: 0.1445445409898228]
[epoch 101/1000, batch 81/100 -> loss before: 0.26486727943176364, loss after: 0.2642931608749369]
[epoch 101/1000, batch 91/100 -> loss before: 0.24285295072793794, loss after: 0.2386017098726348]
ENDING EPOCH 101/1000 [loss before: 0.2836580421241363, loss after: 0.28310203036669507; epoch time: 0.11622762680053711 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.08839228446228362, loss after: 0.08835277686914896]
[epoch 201/1000, batch 11/100 -> loss before: 0.3559238062220767, loss after: 0.3546293175865606]
[epoch 201/1000, batch 21/100 -> loss before: 0.18019122478893718, loss after: 0.1767175110967554]
[epoch 201/1000, batch 31/100 -> loss before: 0.46422940426883547, loss after: 0.4622058980767454]
[epoch 201/1000, batch 41/100 -> loss before: 0.32767140818623985, loss after: 0.32253149233034406]
[epoch 201/1000, batch 51/100 -> loss before: 0.2844824416774157, loss after: 0.2840315068530169]
[epoch 201/1000, batch 61/100 -> loss before: 0.48881208535462595, loss after: 0.48696397062619134]
[epoch 201/1000, batch 71/100 -> loss before: 0.4106003755442848, loss after: 0.4102039455125651]
[epoch 201/1000, batch 81/100 -> loss before: 0.198763657271948, loss after: 0.19875764782675037]
[epoch 201/1000, batch 91/100 -> loss before: 0.10905790645266253, loss after: 0.10904698277908036]
ENDING EPOCH 201/1000 [loss before: 0.2832342456574453, loss after: 0.2834013704435829; epoch time: 0.11854910850524902 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.1900528017096079, loss after: 0.1897211321332504]
[epoch 301/1000, batch 11/100 -> loss before: 0.20090534533374646, loss after: 0.2004239810668802]
[epoch 301/1000, batch 21/100 -> loss before: 0.31245152528488607, loss after: 0.30719488409665213]
[epoch 301/1000, batch 31/100 -> loss before: 0.33110005043028484, loss after: 0.3243157876376547]
[epoch 301/1000, batch 41/100 -> loss before: 0.2560959535787627, loss after: 0.25403459870829115]
[epoch 301/1000, batch 51/100 -> loss before: 0.282370772235275, loss after: 0.2823688255899848]
[epoch 301/1000, batch 61/100 -> loss before: 0.31243213253094765, loss after: 0.3075753649637465]
[epoch 301/1000, batch 71/100 -> loss before: 0.3092799426861844, loss after: 0.307854256758651]
[epoch 301/1000, batch 81/100 -> loss before: 0.32299181775775515, loss after: 0.32290434727303496]
[epoch 301/1000, batch 91/100 -> loss before: 0.32024636947596374, loss after: 0.3075718692564528]
ENDING EPOCH 301/1000 [loss before: 0.2832621385465618, loss after: 0.2833730673881478; epoch time: 0.12410378456115723 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.28851032025619455, loss after: 0.2877156318400541]
[epoch 401/1000, batch 11/100 -> loss before: 0.27499951105080517, loss after: 0.27460418799238684]
[epoch 401/1000, batch 21/100 -> loss before: 0.3333620292581277, loss after: 0.3246681335586631]
[epoch 401/1000, batch 31/100 -> loss before: 0.3851225539589803, loss after: 0.36535034847613307]
[epoch 401/1000, batch 41/100 -> loss before: 0.23566942565657856, loss after: 0.23561351589208973]
[epoch 401/1000, batch 51/100 -> loss before: 0.3260637603086723, loss after: 0.32581353613404285]
[epoch 401/1000, batch 61/100 -> loss before: 0.2591767257799956, loss after: 0.2523827313117889]
[epoch 401/1000, batch 71/100 -> loss before: 0.26760535041455963, loss after: 0.2672583915626744]
[epoch 401/1000, batch 81/100 -> loss before: 0.19747368413087285, loss after: 0.1954757843672348]
[epoch 401/1000, batch 91/100 -> loss before: 0.19384729518988186, loss after: 0.19341979055610362]
ENDING EPOCH 401/1000 [loss before: 0.28417642789331876, loss after: 0.28337407884045684; epoch time: 0.12555956840515137 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.2836821920045874, loss after: 0.281513274785629]
[epoch 501/1000, batch 11/100 -> loss before: 0.5770731120925001, loss after: 0.5758408844378297]
[epoch 501/1000, batch 21/100 -> loss before: 0.3805677430323885, loss after: 0.37990723150312916]
[epoch 501/1000, batch 31/100 -> loss before: 0.24571506331982632, loss after: 0.24452222832726464]
[epoch 501/1000, batch 41/100 -> loss before: 0.31546357110045464, loss after: 0.315379617343244]
[epoch 501/1000, batch 51/100 -> loss before: 0.17716075402500558, loss after: 0.1766710032545092]
[epoch 501/1000, batch 61/100 -> loss before: 0.289679744527527, loss after: 0.2896796135940503]
[epoch 501/1000, batch 71/100 -> loss before: 0.14771093363378818, loss after: 0.14768186627677113]
[epoch 501/1000, batch 81/100 -> loss before: 0.24173297168715474, loss after: 0.2361375718213971]
[epoch 501/1000, batch 91/100 -> loss before: 0.2143358878305695, loss after: 0.21413585213583985]
ENDING EPOCH 501/1000 [loss before: 0.28309497178740195, loss after: 0.2834341519275182; epoch time: 0.1205289363861084 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.34685092490528724, loss after: 0.34605395793083193]
[epoch 601/1000, batch 11/100 -> loss before: 0.361387194175529, loss after: 0.355978661219239]
[epoch 601/1000, batch 21/100 -> loss before: 0.2988581885247293, loss after: 0.29807602907936814]
[epoch 601/1000, batch 31/100 -> loss before: 0.14081270303294374, loss after: 0.13875869663623636]
[epoch 601/1000, batch 41/100 -> loss before: 0.36299899941211383, loss after: 0.355219789462624]
[epoch 601/1000, batch 51/100 -> loss before: 0.28957321006440134, loss after: 0.2850399988355429]
[epoch 601/1000, batch 61/100 -> loss before: 0.13622202072729395, loss after: 0.13621578665891315]
[epoch 601/1000, batch 71/100 -> loss before: 0.2643597361785952, loss after: 0.25494990471229767]
[epoch 601/1000, batch 81/100 -> loss before: 0.34683783413864094, loss after: 0.3370402710005194]
[epoch 601/1000, batch 91/100 -> loss before: 0.3479120840234057, loss after: 0.3478388944560061]
ENDING EPOCH 601/1000 [loss before: 0.2833956139643689, loss after: 0.284322291570238; epoch time: 0.12461233139038086 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.13962299243371562, loss after: 0.1384577084118779]
[epoch 701/1000, batch 11/100 -> loss before: 0.154553383633731, loss after: 0.14828610384599278]
[epoch 701/1000, batch 21/100 -> loss before: 0.22571107483806746, loss after: 0.22511522322461888]
[epoch 701/1000, batch 31/100 -> loss before: 0.2055668070005588, loss after: 0.2051572492498567]
[epoch 701/1000, batch 41/100 -> loss before: 0.19551396991199205, loss after: 0.1955067020721732]
[epoch 701/1000, batch 51/100 -> loss before: 0.545098703513913, loss after: 0.5323586458445992]
[epoch 701/1000, batch 61/100 -> loss before: 0.13775796947595526, loss after: 0.13708178337729662]
[epoch 701/1000, batch 71/100 -> loss before: 0.3682814079663666, loss after: 0.3681369456494243]
[epoch 701/1000, batch 81/100 -> loss before: 0.28340384071062613, loss after: 0.283380247566072]
[epoch 701/1000, batch 91/100 -> loss before: 0.35334519620356936, loss after: 0.3533449357003503]
ENDING EPOCH 701/1000 [loss before: 0.2830798721123625, loss after: 0.2830794428904972; epoch time: 0.11725091934204102 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.24068922352276262, loss after: 0.22778380164248016]
[epoch 801/1000, batch 11/100 -> loss before: 0.11760844987330019, loss after: 0.11737871030862819]
[epoch 801/1000, batch 21/100 -> loss before: 0.23883052629195411, loss after: 0.23796507110085163]
[epoch 801/1000, batch 31/100 -> loss before: 0.21363929156281677, loss after: 0.21312388369709914]
[epoch 801/1000, batch 41/100 -> loss before: 0.4776984267856328, loss after: 0.4736635503686819]
[epoch 801/1000, batch 51/100 -> loss before: 0.265682042988, loss after: 0.2648380749576508]
[epoch 801/1000, batch 61/100 -> loss before: 0.26711977559857053, loss after: 0.26463526928044656]
[epoch 801/1000, batch 71/100 -> loss before: 0.3246767040629712, loss after: 0.32323195837470603]
[epoch 801/1000, batch 81/100 -> loss before: 0.296997966601177, loss after: 0.2922125128802875]
[epoch 801/1000, batch 91/100 -> loss before: 0.24416671124410444, loss after: 0.24341053925509099]
ENDING EPOCH 801/1000 [loss before: 0.28315679312562325, loss after: 0.2830781906569416; epoch time: 0.12283158302307129 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.1319745721868068, loss after: 0.12971838248441236]
[epoch 901/1000, batch 11/100 -> loss before: 0.33670774652725877, loss after: 0.329825128595654]
[epoch 901/1000, batch 21/100 -> loss before: 0.247785348787985, loss after: 0.24318479294560583]
[epoch 901/1000, batch 31/100 -> loss before: 0.28016184330915556, loss after: 0.27719727491994567]
[epoch 901/1000, batch 41/100 -> loss before: 0.3411446663015091, loss after: 0.33652693021015223]
[epoch 901/1000, batch 51/100 -> loss before: 0.2544983588961024, loss after: 0.24128583548857718]
[epoch 901/1000, batch 61/100 -> loss before: 0.40920382569657204, loss after: 0.40897490191074815]
[epoch 901/1000, batch 71/100 -> loss before: 0.17221428525719165, loss after: 0.16930840946196551]
[epoch 901/1000, batch 81/100 -> loss before: 0.3866967363818491, loss after: 0.38463344718494197]
[epoch 901/1000, batch 91/100 -> loss before: 0.20810289250387318, loss after: 0.2072687074339959]
ENDING EPOCH 901/1000 [loss before: 0.28344793555782793, loss after: 0.284666342415805; epoch time: 0.11688017845153809 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.26285397536642524, loss after: 0.25948338073267047]
[epoch 1000/1000, batch 11/100 -> loss before: 0.23019662522969106, loss after: 0.22943103601659884]
[epoch 1000/1000, batch 21/100 -> loss before: 0.3214198448314761, loss after: 0.31652449404247635]
[epoch 1000/1000, batch 31/100 -> loss before: 0.23696069922429466, loss after: 0.23666579703909277]
[epoch 1000/1000, batch 41/100 -> loss before: 0.2945698102948269, loss after: 0.2859640062156036]
[epoch 1000/1000, batch 51/100 -> loss before: 0.3060637886151148, loss after: 0.3002836974120309]
[epoch 1000/1000, batch 61/100 -> loss before: 0.21506176463273846, loss after: 0.21154281631113578]
[epoch 1000/1000, batch 71/100 -> loss before: 0.34756323946825, loss after: 0.3471945191610794]
[epoch 1000/1000, batch 81/100 -> loss before: 0.10230387883750842, loss after: 0.10227987873160686]
[epoch 1000/1000, batch 91/100 -> loss before: 0.3507114168530304, loss after: 0.3490765177946478]
ENDING EPOCH 1000/1000 [loss before: 0.28356450182327997, loss after: 0.28314874219488617; epoch time: 0.12633323669433594 s]
FIT DONE. [time: 115.59562373161316 s]
LOSS TRAIN (MSE): 0.28314874219488617
LOSS TEST (MSE): 0.27754818285403005
R^2 TRAIN: -0.00024929160041509135
R^2 TEST: -6.420220701142121e-05
EXPERIMENT DONE

EXPERIMENT 3241 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 64, 32], activation_name=relu, targets_activation_name=linear, 
initialization_name=uniform, algo_name=adam, learning_rate=0.0001, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 10753]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 20.679362556386955, loss after: 20.18314732357792]
[epoch 1/1000, batch 11/100 -> loss before: 17.009012224368917, loss after: 16.394126310653014]
[epoch 1/1000, batch 21/100 -> loss before: 8.064844123458403, loss after: 7.734310951224408]
[epoch 1/1000, batch 31/100 -> loss before: 4.847484763155068, loss after: 4.619933787641065]
[epoch 1/1000, batch 41/100 -> loss before: 3.701218932825184, loss after: 3.480514662926634]
[epoch 1/1000, batch 51/100 -> loss before: 4.6593529095954676, loss after: 4.469343031456744]
[epoch 1/1000, batch 61/100 -> loss before: 1.124415072497563, loss after: 1.062502211090758]
[epoch 1/1000, batch 71/100 -> loss before: 0.5042071733672895, loss after: 0.49103658716083565]
[epoch 1/1000, batch 81/100 -> loss before: 0.16082672740259601, loss after: 0.1545457532087115]
[epoch 1/1000, batch 91/100 -> loss before: 0.4353247021115337, loss after: 0.43219928618060327]
ENDING EPOCH 1/1000 [loss before: 18.773492598911375, loss after: 0.36630264764407733; epoch time: 0.041814565658569336 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.1598886414993344, loss after: 0.1604222294843955]
[epoch 101/1000, batch 11/100 -> loss before: 0.08977964719525705, loss after: 0.0889917121882107]
[epoch 101/1000, batch 21/100 -> loss before: 0.10838663968793272, loss after: 0.10288076277910616]
[epoch 101/1000, batch 31/100 -> loss before: 0.12194705684344771, loss after: 0.1220547813720152]
[epoch 101/1000, batch 41/100 -> loss before: 0.399639915638142, loss after: 0.39736220469015393]
[epoch 101/1000, batch 51/100 -> loss before: 0.07348870496355807, loss after: 0.07464348031124259]
[epoch 101/1000, batch 61/100 -> loss before: 0.21929309170623626, loss after: 0.21880016690469156]
[epoch 101/1000, batch 71/100 -> loss before: 0.279736510988534, loss after: 0.27806061799953496]
[epoch 101/1000, batch 81/100 -> loss before: 0.3125466813244478, loss after: 0.31498490974930565]
[epoch 101/1000, batch 91/100 -> loss before: 0.12144534295075757, loss after: 0.11759253420764393]
ENDING EPOCH 101/1000 [loss before: 0.19598566356266828, loss after: 0.20165119011726912; epoch time: 0.04004168510437012 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.12837510311099876, loss after: 0.1273159043789168]
[epoch 201/1000, batch 11/100 -> loss before: 0.18655048644145414, loss after: 0.1797984071735756]
[epoch 201/1000, batch 21/100 -> loss before: 0.2300011737102249, loss after: 0.228761583611263]
[epoch 201/1000, batch 31/100 -> loss before: 0.21266487560506114, loss after: 0.20637977485126938]
[epoch 201/1000, batch 41/100 -> loss before: 0.2883949968327829, loss after: 0.28458824579741215]
[epoch 201/1000, batch 51/100 -> loss before: 0.2557473095278313, loss after: 0.2528570128127591]
[epoch 201/1000, batch 61/100 -> loss before: 0.160621328980169, loss after: 0.16168060034049175]
[epoch 201/1000, batch 71/100 -> loss before: 0.10669204517547334, loss after: 0.10520589711629605]
[epoch 201/1000, batch 81/100 -> loss before: 0.16432454108466157, loss after: 0.15044414701808223]
[epoch 201/1000, batch 91/100 -> loss before: 0.1680583444636202, loss after: 0.16894246305128163]
ENDING EPOCH 201/1000 [loss before: 0.1830781195503153, loss after: 0.18173858567853085; epoch time: 0.04616093635559082 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.08744384890635018, loss after: 0.08712492750023616]
[epoch 301/1000, batch 11/100 -> loss before: 0.3563609984819643, loss after: 0.3487171604156161]
[epoch 301/1000, batch 21/100 -> loss before: 0.12999597715776073, loss after: 0.13049243799858254]
[epoch 301/1000, batch 31/100 -> loss before: 0.0834101840049102, loss after: 0.082583367840795]
[epoch 301/1000, batch 41/100 -> loss before: 0.10000901752121454, loss after: 0.10051807122516361]
[epoch 301/1000, batch 51/100 -> loss before: 0.26150161522063536, loss after: 0.25835270925530207]
[epoch 301/1000, batch 61/100 -> loss before: 0.14288117893179225, loss after: 0.14269312164967662]
[epoch 301/1000, batch 71/100 -> loss before: 0.24756183852722935, loss after: 0.23372567277142758]
[epoch 301/1000, batch 81/100 -> loss before: 0.16074652956382912, loss after: 0.15585956933548872]
[epoch 301/1000, batch 91/100 -> loss before: 0.1159433353226043, loss after: 0.11316918309312485]
ENDING EPOCH 301/1000 [loss before: 0.17339834319839753, loss after: 0.17444798599357608; epoch time: 0.03994488716125488 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.15951883966154012, loss after: 0.16014042945553345]
[epoch 401/1000, batch 11/100 -> loss before: 0.23702943025309547, loss after: 0.23725965352080247]
[epoch 401/1000, batch 21/100 -> loss before: 0.1625843460587439, loss after: 0.1607517517873133]
[epoch 401/1000, batch 31/100 -> loss before: 0.19750023235981415, loss after: 0.19652518840017036]
[epoch 401/1000, batch 41/100 -> loss before: 0.0896268392803932, loss after: 0.09035207667977846]
[epoch 401/1000, batch 51/100 -> loss before: 0.30839077439038687, loss after: 0.3042051416686752]
[epoch 401/1000, batch 61/100 -> loss before: 0.11354220592712816, loss after: 0.11261402690738531]
[epoch 401/1000, batch 71/100 -> loss before: 0.20168014092918965, loss after: 0.1961087272026266]
[epoch 401/1000, batch 81/100 -> loss before: 0.0725632324830007, loss after: 0.0730296340497173]
[epoch 401/1000, batch 91/100 -> loss before: 0.20023482491595135, loss after: 0.19816483242485816]
ENDING EPOCH 401/1000 [loss before: 0.16603214034080313, loss after: 0.17106306662358872; epoch time: 0.0425722599029541 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.11590145929350444, loss after: 0.11778060104403283]
[epoch 501/1000, batch 11/100 -> loss before: 0.10634877870878023, loss after: 0.10426383612639382]
[epoch 501/1000, batch 21/100 -> loss before: 0.11198794079479683, loss after: 0.11099809203998139]
[epoch 501/1000, batch 31/100 -> loss before: 0.09109928215644589, loss after: 0.08833219274103453]
[epoch 501/1000, batch 41/100 -> loss before: 0.18991342183141224, loss after: 0.18300353430328747]
[epoch 501/1000, batch 51/100 -> loss before: 0.11515055712372561, loss after: 0.11074461162661069]
[epoch 501/1000, batch 61/100 -> loss before: 0.10294862001644185, loss after: 0.09652990908503085]
[epoch 501/1000, batch 71/100 -> loss before: 0.25501907983505656, loss after: 0.25261235641538193]
[epoch 501/1000, batch 81/100 -> loss before: 0.23393962652685268, loss after: 0.22947037808430032]
[epoch 501/1000, batch 91/100 -> loss before: 0.3545518473115355, loss after: 0.3479838948724804]
ENDING EPOCH 501/1000 [loss before: 0.15791210285317708, loss after: 0.15939669087192362; epoch time: 0.04544639587402344 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.09520224979990019, loss after: 0.09485990762302318]
[epoch 601/1000, batch 11/100 -> loss before: 0.13980215567024643, loss after: 0.13696477251534417]
[epoch 601/1000, batch 21/100 -> loss before: 0.17213750140346545, loss after: 0.1678483594818743]
[epoch 601/1000, batch 31/100 -> loss before: 0.13012843629042511, loss after: 0.12584982603284384]
[epoch 601/1000, batch 41/100 -> loss before: 0.0928776926598376, loss after: 0.0897946512405284]
[epoch 601/1000, batch 51/100 -> loss before: 0.10884599778572412, loss after: 0.10858894149866596]
[epoch 601/1000, batch 61/100 -> loss before: 0.19465404542999068, loss after: 0.18953173674488405]
[epoch 601/1000, batch 71/100 -> loss before: 0.07230824180816103, loss after: 0.06890398536424089]
[epoch 601/1000, batch 81/100 -> loss before: 0.019066723787737255, loss after: 0.01964078429984652]
[epoch 601/1000, batch 91/100 -> loss before: 0.07578471895974451, loss after: 0.07566630009451218]
ENDING EPOCH 601/1000 [loss before: 0.14487604901594112, loss after: 0.14797255418412777; epoch time: 0.04333758354187012 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.06269022250640591, loss after: 0.06492947288293488]
[epoch 701/1000, batch 11/100 -> loss before: 0.14215700797090494, loss after: 0.13927908604522005]
[epoch 701/1000, batch 21/100 -> loss before: 0.09549272503319811, loss after: 0.09322169241728122]
[epoch 701/1000, batch 31/100 -> loss before: 0.09906612599240654, loss after: 0.0971025638808389]
[epoch 701/1000, batch 41/100 -> loss before: 0.10127269932128809, loss after: 0.09813419075974626]
[epoch 701/1000, batch 51/100 -> loss before: 0.1748475597617121, loss after: 0.17409248272040903]
[epoch 701/1000, batch 61/100 -> loss before: 0.05704878049003329, loss after: 0.05559922301260539]
[epoch 701/1000, batch 71/100 -> loss before: 0.12415560366183136, loss after: 0.11789498511575239]
[epoch 701/1000, batch 81/100 -> loss before: 0.09897233955603083, loss after: 0.09635088735045441]
[epoch 701/1000, batch 91/100 -> loss before: 0.24877430590231314, loss after: 0.24753330316547376]
ENDING EPOCH 701/1000 [loss before: 0.13490041083445037, loss after: 0.1402229788215115; epoch time: 0.06399130821228027 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.3019395482461339, loss after: 0.3002909910862706]
[epoch 801/1000, batch 11/100 -> loss before: 0.1638397175984589, loss after: 0.160549550371966]
[epoch 801/1000, batch 21/100 -> loss before: 0.1777304712333561, loss after: 0.17077896486613642]
[epoch 801/1000, batch 31/100 -> loss before: 0.06615989834853322, loss after: 0.06276419659502194]
[epoch 801/1000, batch 41/100 -> loss before: 0.06973589707753432, loss after: 0.06995519468358516]
[epoch 801/1000, batch 51/100 -> loss before: 0.20877585849865107, loss after: 0.20556833491614773]
[epoch 801/1000, batch 61/100 -> loss before: 0.1854884545066806, loss after: 0.17962720415562497]
[epoch 801/1000, batch 71/100 -> loss before: 0.04851870179834183, loss after: 0.047748928963335345]
[epoch 801/1000, batch 81/100 -> loss before: 0.10362981289593927, loss after: 0.10171440852951999]
[epoch 801/1000, batch 91/100 -> loss before: 0.0672838051773865, loss after: 0.0656474560176703]
ENDING EPOCH 801/1000 [loss before: 0.12788875145866782, loss after: 0.13266110072454365; epoch time: 0.04238748550415039 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.07819175927180025, loss after: 0.07568843189497132]
[epoch 901/1000, batch 11/100 -> loss before: 0.11963251344858239, loss after: 0.11365781499292185]
[epoch 901/1000, batch 21/100 -> loss before: 0.13703010886139494, loss after: 0.1362271951046853]
[epoch 901/1000, batch 31/100 -> loss before: 0.13353391804607173, loss after: 0.13242360680803378]
[epoch 901/1000, batch 41/100 -> loss before: 0.01720880549495442, loss after: 0.01835504663399965]
[epoch 901/1000, batch 51/100 -> loss before: 0.15693614639568576, loss after: 0.152823530635361]
[epoch 901/1000, batch 61/100 -> loss before: 0.15403558682570212, loss after: 0.1488642700896477]
[epoch 901/1000, batch 71/100 -> loss before: 0.020073758113989756, loss after: 0.02059470974532209]
[epoch 901/1000, batch 81/100 -> loss before: 0.12235079238946756, loss after: 0.12249595435519808]
[epoch 901/1000, batch 91/100 -> loss before: 0.018802898925742956, loss after: 0.018650175355077275]
ENDING EPOCH 901/1000 [loss before: 0.11983871559088397, loss after: 0.12186871436874651; epoch time: 0.04067683219909668 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.05731625532888609, loss after: 0.05725440244062148]
[epoch 1000/1000, batch 11/100 -> loss before: 0.07200213187383622, loss after: 0.06579155362957921]
[epoch 1000/1000, batch 21/100 -> loss before: 0.22426538988333858, loss after: 0.21443969146192227]
[epoch 1000/1000, batch 31/100 -> loss before: 0.08830640263234521, loss after: 0.08596069063138653]
[epoch 1000/1000, batch 41/100 -> loss before: 0.11997261292597834, loss after: 0.1164369017313018]
[epoch 1000/1000, batch 51/100 -> loss before: 0.19479571846503743, loss after: 0.1906785919743242]
[epoch 1000/1000, batch 61/100 -> loss before: 0.11805269560789744, loss after: 0.11771713943444173]
[epoch 1000/1000, batch 71/100 -> loss before: 0.08616573252832158, loss after: 0.08762445855362955]
[epoch 1000/1000, batch 81/100 -> loss before: 0.18748275994570934, loss after: 0.18538721066625113]
[epoch 1000/1000, batch 91/100 -> loss before: 0.22022764933484237, loss after: 0.21497247193583977]
ENDING EPOCH 1000/1000 [loss before: 0.12142223697981734, loss after: 0.11455573835344521; epoch time: 0.04225444793701172 s]
FIT DONE. [time: 41.480159282684326 s]
LOSS TRAIN (MSE): 0.11455573835344521
LOSS TEST (MSE): 0.12150758716520285
R^2 TRAIN: 0.595321189673766
R^2 TEST: 0.5621827281630027
EXPERIMENT DONE

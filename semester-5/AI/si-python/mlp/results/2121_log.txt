EXPERIMENT 2121 START
DATA SETTINGS: domain=4.71238898038469, noise_std=0.1, m_train=1000, m_test=10000
APPROXIMATOR: MLPApproximator(structure=[128, 64, 32], activation_name=sigmoid, targets_activation_name=linear, 
initialization_name=uniform, algo_name=sgd_momentum, learning_rate=0.001, n_epochs=1000, batch_size=10)
FIT [total of weights (params): 10753]
---
EPOCH 1/1000:
[epoch 1/1000, batch 1/100 -> loss before: 1.6197437009973044, loss after: 1.5672835831451044]
[epoch 1/1000, batch 11/100 -> loss before: 0.2551000631025198, loss after: 0.23080589154386658]
[epoch 1/1000, batch 21/100 -> loss before: 0.11144883679210538, loss after: 0.11950919507089415]
[epoch 1/1000, batch 31/100 -> loss before: 0.4899265213942862, loss after: 0.48321679532754463]
[epoch 1/1000, batch 41/100 -> loss before: 0.16750004864537343, loss after: 0.1674092287590687]
[epoch 1/1000, batch 51/100 -> loss before: 0.4484936076780291, loss after: 0.43726350814069387]
[epoch 1/1000, batch 61/100 -> loss before: 0.533163593817745, loss after: 0.5331087575306819]
[epoch 1/1000, batch 71/100 -> loss before: 0.48366635423864934, loss after: 0.4772123381653729]
[epoch 1/1000, batch 81/100 -> loss before: 0.14634183426279235, loss after: 0.146684230606214]
[epoch 1/1000, batch 91/100 -> loss before: 0.417029703241088, loss after: 0.4169819895198086]
ENDING EPOCH 1/1000 [loss before: 0.7227142221308361, loss after: 0.28298080126126124; epoch time: 0.03595447540283203 s]
---
EPOCH 101/1000:
[epoch 101/1000, batch 1/100 -> loss before: 0.27772638826382723, loss after: 0.2764807508291647]
[epoch 101/1000, batch 11/100 -> loss before: 0.1196910185070724, loss after: 0.12011664812387327]
[epoch 101/1000, batch 21/100 -> loss before: 0.11914595827437599, loss after: 0.11901715918998294]
[epoch 101/1000, batch 31/100 -> loss before: 0.20189071105807305, loss after: 0.20251706519974633]
[epoch 101/1000, batch 41/100 -> loss before: 0.5327312326640612, loss after: 0.5332635437700275]
[epoch 101/1000, batch 51/100 -> loss before: 0.21086613752560343, loss after: 0.20882987979202333]
[epoch 101/1000, batch 61/100 -> loss before: 0.2836718238145339, loss after: 0.28077473303909417]
[epoch 101/1000, batch 71/100 -> loss before: 0.23111995575802893, loss after: 0.2311378508497964]
[epoch 101/1000, batch 81/100 -> loss before: 0.2964026140477362, loss after: 0.2986278411374658]
[epoch 101/1000, batch 91/100 -> loss before: 0.3423817826851079, loss after: 0.3422977657738134]
ENDING EPOCH 101/1000 [loss before: 0.26771807801479186, loss after: 0.2683138317943933; epoch time: 0.027972698211669922 s]
---
EPOCH 201/1000:
[epoch 201/1000, batch 1/100 -> loss before: 0.18610067610485523, loss after: 0.18403572962290568]
[epoch 201/1000, batch 11/100 -> loss before: 0.22374164151401527, loss after: 0.22046640939554124]
[epoch 201/1000, batch 21/100 -> loss before: 0.1860841689298053, loss after: 0.18511728831616786]
[epoch 201/1000, batch 31/100 -> loss before: 0.25459392819624, loss after: 0.25454084345682876]
[epoch 201/1000, batch 41/100 -> loss before: 0.32324127068300357, loss after: 0.32317202180712995]
[epoch 201/1000, batch 51/100 -> loss before: 0.4021527641210077, loss after: 0.4007873474276522]
[epoch 201/1000, batch 61/100 -> loss before: 0.3788808219560736, loss after: 0.37662740573133713]
[epoch 201/1000, batch 71/100 -> loss before: 0.13933998431393352, loss after: 0.13944527825420833]
[epoch 201/1000, batch 81/100 -> loss before: 0.1764163045518893, loss after: 0.174508241915513]
[epoch 201/1000, batch 91/100 -> loss before: 0.14445470423724277, loss after: 0.14495823667552116]
ENDING EPOCH 201/1000 [loss before: 0.2668114497650617, loss after: 0.2674273657783457; epoch time: 0.032074928283691406 s]
---
EPOCH 301/1000:
[epoch 301/1000, batch 1/100 -> loss before: 0.19820401458460754, loss after: 0.1997103857553414]
[epoch 301/1000, batch 11/100 -> loss before: 0.5186410631552174, loss after: 0.5149773424180434]
[epoch 301/1000, batch 21/100 -> loss before: 0.18086251904707615, loss after: 0.1819458030132903]
[epoch 301/1000, batch 31/100 -> loss before: 0.1923636104729173, loss after: 0.19162177648086037]
[epoch 301/1000, batch 41/100 -> loss before: 0.09738232569948486, loss after: 0.09744669046082291]
[epoch 301/1000, batch 51/100 -> loss before: 0.3216366068942521, loss after: 0.3221609023929891]
[epoch 301/1000, batch 61/100 -> loss before: 0.21947733754602514, loss after: 0.2183145966403537]
[epoch 301/1000, batch 71/100 -> loss before: 0.36412338116581006, loss after: 0.3628714809885588]
[epoch 301/1000, batch 81/100 -> loss before: 0.14608440594719801, loss after: 0.14616156295279]
[epoch 301/1000, batch 91/100 -> loss before: 0.3042024397888702, loss after: 0.3012302176508367]
ENDING EPOCH 301/1000 [loss before: 0.26745441430139805, loss after: 0.2667593519893375; epoch time: 0.03483772277832031 s]
---
EPOCH 401/1000:
[epoch 401/1000, batch 1/100 -> loss before: 0.3972800677827081, loss after: 0.3974021075392077]
[epoch 401/1000, batch 11/100 -> loss before: 0.33909319645672137, loss after: 0.3401715943769357]
[epoch 401/1000, batch 21/100 -> loss before: 0.2780820858764409, loss after: 0.27786887538308286]
[epoch 401/1000, batch 31/100 -> loss before: 0.28601281915263344, loss after: 0.28340553751435876]
[epoch 401/1000, batch 41/100 -> loss before: 0.13632263126557365, loss after: 0.13683918050623595]
[epoch 401/1000, batch 51/100 -> loss before: 0.36121696222127525, loss after: 0.3608560642496613]
[epoch 401/1000, batch 61/100 -> loss before: 0.1610963968577491, loss after: 0.16143726577535183]
[epoch 401/1000, batch 71/100 -> loss before: 0.2727877183665647, loss after: 0.2711590977810869]
[epoch 401/1000, batch 81/100 -> loss before: 0.3953355519562659, loss after: 0.3976864252437594]
[epoch 401/1000, batch 91/100 -> loss before: 0.232865523123689, loss after: 0.2337044496769228]
ENDING EPOCH 401/1000 [loss before: 0.26992499918900925, loss after: 0.26797100803586715; epoch time: 0.032871246337890625 s]
---
EPOCH 501/1000:
[epoch 501/1000, batch 1/100 -> loss before: 0.22825299122685286, loss after: 0.23015087847948465]
[epoch 501/1000, batch 11/100 -> loss before: 0.32825834827981176, loss after: 0.32745920975295334]
[epoch 501/1000, batch 21/100 -> loss before: 0.14097896994137712, loss after: 0.14026108007962684]
[epoch 501/1000, batch 31/100 -> loss before: 0.17472713893825292, loss after: 0.17464502047855207]
[epoch 501/1000, batch 41/100 -> loss before: 0.22576190433074084, loss after: 0.2234004169666477]
[epoch 501/1000, batch 51/100 -> loss before: 0.20730956419957575, loss after: 0.2049918666190028]
[epoch 501/1000, batch 61/100 -> loss before: 0.204759468236105, loss after: 0.1975067302316345]
[epoch 501/1000, batch 71/100 -> loss before: 0.21071451515296896, loss after: 0.21069741255639948]
[epoch 501/1000, batch 81/100 -> loss before: 0.24119846002733997, loss after: 0.23850864504003746]
[epoch 501/1000, batch 91/100 -> loss before: 0.3663108217514348, loss after: 0.3677167215279319]
ENDING EPOCH 501/1000 [loss before: 0.2630456088714916, loss after: 0.2627007016880376; epoch time: 0.030614376068115234 s]
---
EPOCH 601/1000:
[epoch 601/1000, batch 1/100 -> loss before: 0.30210935272982276, loss after: 0.3023983119557743]
[epoch 601/1000, batch 11/100 -> loss before: 0.17836509248916527, loss after: 0.1778734103948802]
[epoch 601/1000, batch 21/100 -> loss before: 0.5194501977838402, loss after: 0.518659243571314]
[epoch 601/1000, batch 31/100 -> loss before: 0.21584924565259395, loss after: 0.21703092134385243]
[epoch 601/1000, batch 41/100 -> loss before: 0.2111508529419294, loss after: 0.21061264223476722]
[epoch 601/1000, batch 51/100 -> loss before: 0.24837839583826118, loss after: 0.24808700186386443]
[epoch 601/1000, batch 61/100 -> loss before: 0.39372342792743387, loss after: 0.3925379648609766]
[epoch 601/1000, batch 71/100 -> loss before: 0.33953174950373255, loss after: 0.33975701279463166]
[epoch 601/1000, batch 81/100 -> loss before: 0.09983003351312542, loss after: 0.09871155049521062]
[epoch 601/1000, batch 91/100 -> loss before: 0.1270299592109759, loss after: 0.1257407520929656]
ENDING EPOCH 601/1000 [loss before: 0.26040426791899474, loss after: 0.2635645069621243; epoch time: 0.03916192054748535 s]
---
EPOCH 701/1000:
[epoch 701/1000, batch 1/100 -> loss before: 0.24349081820835647, loss after: 0.24505533268958626]
[epoch 701/1000, batch 11/100 -> loss before: 0.27230184720940886, loss after: 0.2723534102634956]
[epoch 701/1000, batch 21/100 -> loss before: 0.2570730645372269, loss after: 0.2567057366282927]
[epoch 701/1000, batch 31/100 -> loss before: 0.1888299746622208, loss after: 0.18839141357789588]
[epoch 701/1000, batch 41/100 -> loss before: 0.15817746307044486, loss after: 0.15710078873298847]
[epoch 701/1000, batch 51/100 -> loss before: 0.39105956850121576, loss after: 0.39091006096586656]
[epoch 701/1000, batch 61/100 -> loss before: 0.12241373168814959, loss after: 0.12210821507675784]
[epoch 701/1000, batch 71/100 -> loss before: 0.21706382467136462, loss after: 0.2167424258400667]
[epoch 701/1000, batch 81/100 -> loss before: 0.26616360824504626, loss after: 0.26607701076002244]
[epoch 701/1000, batch 91/100 -> loss before: 0.3113583256602703, loss after: 0.3113965191709228]
ENDING EPOCH 701/1000 [loss before: 0.25847362524891765, loss after: 0.2580281765797126; epoch time: 0.03810930252075195 s]
---
EPOCH 801/1000:
[epoch 801/1000, batch 1/100 -> loss before: 0.4223690976536162, loss after: 0.4250722582962948]
[epoch 801/1000, batch 11/100 -> loss before: 0.29560904915899416, loss after: 0.29517376843834436]
[epoch 801/1000, batch 21/100 -> loss before: 0.42711936905199943, loss after: 0.4259157508545841]
[epoch 801/1000, batch 31/100 -> loss before: 0.19903768695270263, loss after: 0.19915348652741532]
[epoch 801/1000, batch 41/100 -> loss before: 0.2995305589755747, loss after: 0.29957215880437005]
[epoch 801/1000, batch 51/100 -> loss before: 0.2627137666995137, loss after: 0.2627156444569767]
[epoch 801/1000, batch 61/100 -> loss before: 0.2403063407617477, loss after: 0.23847574899515753]
[epoch 801/1000, batch 71/100 -> loss before: 0.2942374725390249, loss after: 0.2933135370618363]
[epoch 801/1000, batch 81/100 -> loss before: 0.3376426390626151, loss after: 0.33626174018764493]
[epoch 801/1000, batch 91/100 -> loss before: 0.1281313146367839, loss after: 0.1272396901728418]
ENDING EPOCH 801/1000 [loss before: 0.252705370822033, loss after: 0.25309558310298547; epoch time: 0.043177127838134766 s]
---
EPOCH 901/1000:
[epoch 901/1000, batch 1/100 -> loss before: 0.2829169838646569, loss after: 0.282368953864093]
[epoch 901/1000, batch 11/100 -> loss before: 0.38023397136720516, loss after: 0.38033887685018425]
[epoch 901/1000, batch 21/100 -> loss before: 0.17015630714157048, loss after: 0.17057509036069826]
[epoch 901/1000, batch 31/100 -> loss before: 0.1823188431310174, loss after: 0.18341390414721598]
[epoch 901/1000, batch 41/100 -> loss before: 0.05266819837044275, loss after: 0.052179381942960325]
[epoch 901/1000, batch 51/100 -> loss before: 0.24380716631954308, loss after: 0.2446433016297637]
[epoch 901/1000, batch 61/100 -> loss before: 0.29595270625769315, loss after: 0.29608819629561955]
[epoch 901/1000, batch 71/100 -> loss before: 0.19710038913597225, loss after: 0.19647227824865682]
[epoch 901/1000, batch 81/100 -> loss before: 0.19931750079753374, loss after: 0.1990231025843704]
[epoch 901/1000, batch 91/100 -> loss before: 0.11848178982536843, loss after: 0.11754855361088397]
ENDING EPOCH 901/1000 [loss before: 0.24580392501563608, loss after: 0.24989906551793076; epoch time: 0.02749776840209961 s]
---
EPOCH 1000/1000:
[epoch 1000/1000, batch 1/100 -> loss before: 0.08405962565780496, loss after: 0.08447867136893347]
[epoch 1000/1000, batch 11/100 -> loss before: 0.29216285979897966, loss after: 0.2928823201274179]
[epoch 1000/1000, batch 21/100 -> loss before: 0.15417869481366955, loss after: 0.15398973517540462]
[epoch 1000/1000, batch 31/100 -> loss before: 0.25633942036313, loss after: 0.255684192240545]
[epoch 1000/1000, batch 41/100 -> loss before: 0.28515948023305737, loss after: 0.2839172877365581]
[epoch 1000/1000, batch 51/100 -> loss before: 0.22739496826050107, loss after: 0.2274261883829475]
[epoch 1000/1000, batch 61/100 -> loss before: 0.17789121010042477, loss after: 0.17924088393754797]
[epoch 1000/1000, batch 71/100 -> loss before: 0.22539364565213957, loss after: 0.22528306851179614]
[epoch 1000/1000, batch 81/100 -> loss before: 0.31183227563179056, loss after: 0.3116192834476477]
[epoch 1000/1000, batch 91/100 -> loss before: 0.3323440460860859, loss after: 0.3308773173304339]
ENDING EPOCH 1000/1000 [loss before: 0.24100211265026122, loss after: 0.24256768918893243; epoch time: 0.03500080108642578 s]
FIT DONE. [time: 29.594393730163574 s]
LOSS TRAIN (MSE): 0.24256768918893243
LOSS TEST (MSE): 0.23453447706095254
R^2 TRAIN: 0.14310705604553675
R^2 TEST: 0.15492318385901316
EXPERIMENT DONE
